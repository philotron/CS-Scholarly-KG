{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtopics = [\n",
    "#'Passage Retrieval',\n",
    "#  'Chunking',\n",
    "#  'Text Error Correction',\n",
    "#  'Named Entity Recognition',\n",
    "#  'Text Normalization',\n",
    "#'Dialogue Systems & Conversational Agents',\n",
    "#  'Psycholinguistics',\n",
    "#  'Machine Translation',\n",
    "#  'Relation Extraction',\n",
    "#  'Captioning',\n",
    "#  'Emotion Analysis',\n",
    "#  'Opinion Mining',\n",
    "#  'Knowledge Representation',\n",
    "#  'Language Models',\n",
    "#  'Text Complexity',\n",
    "#  'Open Information Extraction',\n",
    "#  'Semantic Search',\n",
    "#  'Cross-Lingual Transfer',\n",
    "#  'Linguistic Theories',\n",
    "#  'Tagging',\n",
    "#  'Code Generation',\n",
    "#  'Fact & Claim Verification',\n",
    "#  'Commonsense Reasoning',\n",
    "#  'Aspect-based Sentiment Analysis',\n",
    "#  'Speech Recognition',\n",
    "#  'Coreference Resolution',\n",
    "#  'Speech & Audio in NLP',\n",
    "#  'Low-Resource NLP',\n",
    "#  'Machine Reading Comprehension',\n",
    "#  'Question Generation',\n",
    "#  'Term Extraction',\n",
    "#  'Event Extraction',\n",
    "#  'Text Classification',\n",
    "#  'Question Answering',\n",
    "#  'Cognitive Modeling',\n",
    "#  'Stylistic Analysis',\n",
    "#  'Discourse & Pragmatics',\n",
    "#  'Code-Switching',\n",
    "#  'Document Retrieval',\n",
    "#  'Data-to-Text Generation',\n",
    "#  'Programming Languages in NLP',\n",
    "#  'Semantic Similarity',\n",
    "#  'Word Sense Disambiguation',\n",
    "#  'Dialogue Response Generation',\n",
    "#  'Ethical NLP',\n",
    "#  'Text Segmentation',\n",
    "#  'Typology',\n",
    "#  'Argument Mining',\n",
    "#  'Morphology',\n",
    "#  'Textual Inference',\n",
    " 'Responsible & Trustworthy NLP',\n",
    " 'Text Clustering',\n",
    " 'Knowledge Graph Reasoning',\n",
    " 'Representation Learning',\n",
    " 'Structured Data in NLP',\n",
    " 'Intent Recognition',\n",
    " 'Summarization',\n",
    " 'Paraphrasing',\n",
    " 'Green & Sustainable NLP',\n",
    " 'Visual Data in NLP',\n",
    " 'Explainability & Interpretability in NLP',\n",
    " 'Numerical Reasoning',\n",
    " 'Semantic Parsing',\n",
    " 'Robustness in NLP',\n",
    " 'Indexing',\n",
    " 'Phonology',\n",
    " 'Phonetics',\n",
    " 'Syntactic Parsing',\n",
    " 'Topic Modeling',\n",
    " 'Polarity Analysis',\n",
    " 'Text Style Transfer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "\n",
    "class Neo4jApp:\n",
    "\n",
    "    def __init__(self):\n",
    "        uri = os.getenv(\"uri\", \"neo4j://0.0.0.0:7687\")\n",
    "        user = os.getenv(\"user\", \"neo4j\")\n",
    "        password = os.getenv(\"password\", \"neo4j-connect\")\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def insert_clusters(self, topic_name, df):\n",
    "        print(f\"Inserting clusters for topic {topic_name}...\")    \n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            session.execute_write(self._confirm_topic, topic_name)\n",
    "\n",
    "            # Calculate the highest cluster level from column names\n",
    "            cluster_level_cols = [col for col in df.columns if col.startswith('cluster_level_')]\n",
    "            highest_level = max(int(col.split('_')[-1]) for col in cluster_level_cols)\n",
    "            \n",
    "            # Execute the transaction to insert clusters and their relationships\n",
    "            session.execute_write(self._insert_clusters, topic_name, df, highest_level)\n",
    "\n",
    "    @staticmethod\n",
    "    def _confirm_topic(tx, topic_name):\n",
    "        topic_query = \"\"\"\n",
    "        MERGE (topic:FieldOfStudy {label: $topic_name})\n",
    "        \"\"\"\n",
    "        tx.run(topic_query, topic_name=topic_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def _insert_clusters(tx, topic_name, df, highest_level):\n",
    "        #print(f\"Inserting clusters for topic {topic_name}...\")\n",
    "        # Insert Cluster Nodes\n",
    "        for level in range(highest_level + 1):\n",
    "\n",
    "            cluster_col = f'cluster_level_{level}'\n",
    "            cluster_tag_col = f'cluster_tag_level_{level}'\n",
    "            clusters = df[[cluster_col, cluster_tag_col]].drop_duplicates().dropna()\n",
    "            for _, row in clusters.iterrows():\n",
    "                cluster_path = eval(row[cluster_col]) if isinstance(row[cluster_col], str) else row[cluster_col]\n",
    "\n",
    "                if isinstance(row[cluster_col], (str, int)):\n",
    "                    cluster_id = f\"{topic_name}_{row[cluster_col]}\"\n",
    "                else:  # it's assumed to be a tuple or list\n",
    "                    cluster_path = eval(row[cluster_col]) if isinstance(row[cluster_col], str) else row[cluster_col]\n",
    "                    cluster_id = f\"{topic_name}_\" + '_'.join(map(str, cluster_path))\n",
    "\n",
    "                cluster_tag = row[cluster_tag_col]\n",
    "                query = \"\"\"\n",
    "                MERGE (cluster:Cluster {id: $cluster_id})\n",
    "                ON CREATE SET cluster.level = $level, cluster.tag = $cluster_tag\n",
    "                ON MATCH SET cluster.level = $level, cluster.tag = $cluster_tag\n",
    "\n",
    "                // Link cluster to the topic if it's at the root level\n",
    "                WITH cluster\n",
    "                MATCH (topic:FieldOfStudy {label: $topic_name})\n",
    "                WHERE $level = 0\n",
    "                MERGE (topic)-[:HAS_CLUSTER]->(cluster)\n",
    "                \n",
    "                // Always create a relationship from cluster to topic\n",
    "\n",
    "                MERGE (cluster)-[:HAS_FIELD_OF_STUDY]->(topic)\n",
    "                \"\"\"\n",
    "                tx.run(query, cluster_id=cluster_id, level=level, cluster_tag=cluster_tag, topic_name=topic_name)\n",
    "\n",
    "        # Insert Relationships Between Cluster Nodes\n",
    "        for level in range(highest_level):  # assuming child is one level deeper than parent\n",
    "            for _, row in df.iterrows():\n",
    "\n",
    "                parent_col = f'cluster_level_{level}'\n",
    "                child_col = f'cluster_level_{level + 1}'\n",
    "\n",
    "                if isinstance(row[parent_col], (str, int)):\n",
    "                    parent_cluster_id = f\"{topic_name}_{row[parent_col]}\"\n",
    "                else:\n",
    "                    parent_path = eval(row[parent_col]) if isinstance(row[parent_col], str) else row[parent_col]\n",
    "                    parent_cluster_id = f\"{topic_name}_\" + '_'.join(map(str, parent_path))\n",
    "                \n",
    "                if isinstance(row[child_col], (str, int)):\n",
    "                    child_cluster_id = f\"{topic_name}_{row[child_col]}\"\n",
    "                else:\n",
    "                    child_path = eval(row[child_col]) if isinstance(row[child_col], str) else row[child_col]\n",
    "                    child_cluster_id = f\"{topic_name}_\" + '_'.join(map(str, child_path))\n",
    "                \n",
    "                \n",
    "                query = (\n",
    "                    \"MATCH (parent:Cluster {id: $parent_cluster_id}), \"\n",
    "                    \"(child:Cluster {id: $child_cluster_id}) \"\n",
    "                    \"MERGE (parent)-[:HAS_SUBCLUSTER]->(child)\"\n",
    "                    \"MERGE (child)-[:HAS_PARENT_CLUSTER]->(parent)\"\n",
    "                )\n",
    "                tx.run(query, parent_cluster_id=parent_cluster_id, child_cluster_id=child_cluster_id)\n",
    "\n",
    "        # Link Publications to Lowest-Level Clusters\n",
    "        for _, row in df.iterrows():\n",
    "\n",
    "            publication_id = int(row['id'])\n",
    "            \n",
    "            lowest_cluster_col = f'cluster_level_{highest_level}'\n",
    "        \n",
    "            if isinstance(row[lowest_cluster_col], (str, int)):\n",
    "                cluster_id = f\"{topic_name}_{row[lowest_cluster_col]}\"\n",
    "            else:\n",
    "                cluster_path = eval(row[lowest_cluster_col]) if isinstance(row[lowest_cluster_col], str) else row[lowest_cluster_col]\n",
    "                cluster_id = f\"{topic_name}_\" + '_'.join(map(str, cluster_path))\n",
    "\n",
    "            query = (\n",
    "                \"MATCH (p:Publication), (cluster:Cluster {id: $cluster_id}) \"\n",
    "                \"WHERE ID(p) = $publication_id \"\n",
    "                \"MERGE (p)-[:BELONGS_TO]->(cluster) \"\n",
    "                \"MERGE (cluster)-[:HAS_PUBLICATION]->(p)\"\n",
    "            )\n",
    "\n",
    "            tx.run(query, publication_id=publication_id, cluster_id=cluster_id)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './output'\n",
    "\n",
    "for topic in subtopics:\n",
    "    formatted_topic = topic.replace(' ', '_').lower()\n",
    "    df_loaded = pd.read_csv(os.path.join(directory, 'clustered_'+formatted_topic+'.csv'))\n",
    "    app = Neo4jApp()\n",
    "    app.insert_clusters(topic, df_loaded)\n",
    "    app.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
