1	OBJECTIVE	We study the problem of optimally investing in nodes of a social network in a competitive setting, where two camps aim to maximize adoption of their opinions by the population.
2	METHODS	In particular, we consider the possibility of campaigning in multiple phases, where the final opinion of a node in a phase acts as its initial biased opinion for the following phase.
3	METHODS	Using an extension of the popular DeGroot-Friedkin model, we formulate the utility functions of the camps, and show that they involve what can be interpreted as multiphase Katz centrality.
4	METHODS	Focusing on two phases, we analytically derive Nash equilibrium investment strategies, and the extent of loss that a camp would incur if it acted myopically.
5	CONCLUSIONS	Our simulation study affirms that nodes attributing higher weightage to initial biases necessitate higher investment in the first phase, so as to influence these biases for the terminal phase.
6	OBJECTIVE	We then study the setting in which a camp's influence on a node depends on its initial bias.
7	METHODS	For single camp, we present a polynomial time algorithm for determining an optimal way to split the budget between the two phases.
8	CONCLUSIONS	For competing camps, we show the existence of Nash equilibria under reasonable assumptions, and that they can be computed in polynomial time.
1	OBJECTIVE	This paper addresses the problem of community membership detection using only text features in a scenario where a small number of positive labeled examples defines the community.
2	METHODS	The solution introduces an unsupervised proxy task for learning user embeddings: user re-identification.
3	CONCLUSIONS	Experiments with 16 different communities show that the resulting embeddings are more effective for community membership identification than common unsupervised representations.
1	BACKGROUND	Political identity is often manifested in language variation, but the relationship between the two is still relatively unexplored from a quantitative perspective.
2	OBJECTIVE	This study examines the use of Catalan, a language local to the semi-autonomous region of Catalonia in Spain, on Twitter in discourse related to the 2017 independence referendum.
3	RESULTS	We corroborate prior findings that pro-independence tweets are more likely to include the local language than anti-independence tweets.
4	RESULTS	We also find that Catalan is used more often in referendum-related discourse than in other contexts, contrary to prior findings on language variation.
5	CONCLUSIONS	This suggests a strong role for the Catalan language in the expression of Catalonian political identity.
1	BACKGROUND	While social media empowers freedom of expression and individual voices, it also enables anti-social behavior, online harassment, cyberbullying, and hate speech.
2	OBJECTIVE	"In this paper, we deepen our understanding of online hate speech by focusing on a largely neglected but crucial aspect of hate speech -- its target: either ""directed"" towards a specific person or entity, or ""generalized"" towards a group of people sharing a common protected characteristic."
3	METHODS	We perform the first linguistic and psycholinguistic analysis of these two forms of hate speech and reveal the presence of interesting markers that distinguish these types of hate speech.
4	RESULTS	Our analysis reveals that Directed hate speech, in addition to being more personal and directed, is more informal, angrier, and often explicitly attacks the target (via name calling) with fewer analytic words and more words suggesting authority and influence.
5	RESULTS	Generalized hate speech, on the other hand, is dominated by religious hate, is characterized by the use of lethal words such as murder, exterminate, and kill; and quantity words such as million and many.
6	OBJECTIVE	Altogether, our work provides a data-driven analysis of the nuances of online-hate speech that enables not only a deepened understanding of hate speech and its social implications but also its detection.
1	BACKGROUND	Given the complexity of human minds and their behavioral flexibility, it requires sophisticated data analysis to sift through a large amount of human behavioral evidence to model human minds and to predict human behavior.
2	BACKGROUND	People currently spend a significant amount of time on social media such as Twitter and Facebook.
3	BACKGROUND	Thus many aspects of their lives and behaviors have been digitally captured and continuously archived on these platforms.
4	BACKGROUND	This makes social media a great source of large, rich and diverse human behavioral evidence.
5	OBJECTIVE	In this paper, we survey the recent work on applying machine learning to infer human traits and behavior from social media data.
6	OBJECTIVE	We will also point out several future research directions.
1	BACKGROUND	Estimating influence on social media networks is an important practical and theoretical problem, especially because this new medium is widely exploited as a platform for disinformation and propaganda.
2	BACKGROUND	This paper introduces a novel approach to influence estimation on social media networks and applies it to the real-world problem of characterizing active influence operations on Twitter during the 2017 French presidential elections.
3	BACKGROUND	The new influence estimation approach attributes impact by accounting for narrative propagation over the network using a network causal inference framework applied to data arising from graph sampling and filtering.
4	BACKGROUND	This causal framework infers the difference in outcome as a function of exposure, in contrast to existing approaches that attribute impact to activity volume or topological features, which do not explicitly measure nor necessarily indicate actual network influence.
5	BACKGROUND	Cram\'er-Rao estimation bounds are derived for parameter estimation as a step in the causal analysis, and used to achieve geometrical insight on the causal inference problem.
6	BACKGROUND	The ability to infer high causal influence is demonstrated on real-world social media accounts that are later independently confirmed to be either directly affiliated or correlated with foreign influence operations using evidence supplied by the U.S.
7	BACKGROUND	Congress and journalistic reports.
1	BACKGROUND	Understanding and predicting the popularity of online items is an important open problem in social media analysis.
2	BACKGROUND	Considerable progress has been made recently in data-driven predictions, and in linking popularity to external promotions.
3	BACKGROUND	However, the existing methods typically focus on a single source of external influence, whereas for many types of online content such as YouTube videos or news articles, attention is driven by multiple heterogeneous sources simultaneously - e.g. microblogs or traditional media coverage.
4	OBJECTIVE	Here, we propose RNN-MAS, a recurrent neural network for modeling asynchronous streams.
5	METHODS	It is a sequence generator that connects multiple streams of different granularity via joint inference.
6	RESULTS	We show RNN-MAS not only to outperform the current state-of-the-art Youtube popularity prediction system by 17%, but also to capture complex dynamics, such as seasonal trends of unseen influence.
7	METHODS	We define two new metrics: promotion score quantifies the gain in popularity from one unit of promotion for a Youtube video; the loudness level captures the effects of a particular user tweeting about the video.
8	METHODS	We use the loudness level to compare the effects of a video being promoted by a single highly-followed user (in the top 1% most followed users) against being promoted by a group of mid-followed users.
9	RESULTS	We find that results depend on the type of content being promoted: superusers are more successful in promoting Howto and Gaming videos, whereas the cohort of regular users are more influential for Activism videos.
10	CONCLUSIONS	This work provides more accurate and explainable popularity predictions, as well as computational tools for content producers and marketers to allocate resources for promotion campaigns.
1	BACKGROUND	Measuring research impact is important for ranking publications in academic search engines and for research evaluation.
2	OBJECTIVE	Social media metrics or altmetrics measure the impact of scientific work based on social media activity.
3	OBJECTIVE	Altmetrics are complementary to traditional, citation-based metrics, e.g. allowing the assessment of new publications for which citations are not yet available.
4	METHODS	Despite the increasing importance of altmetrics, their characteristics are not well understood: Until now it has not been researched what kind of researchers are actively using which social media services and why - important questions for scientific impact prediction.
5	RESULTS	Based on a survey among 3,430 scientists, we uncover previously unknown and significant differences between social media services: We identify services which attract young and experienced researchers, respectively, and detect differences in usage motivations.
6	CONCLUSIONS	Our findings have direct implications for the future design of altmetrics for scientific impact prediction.
1	BACKGROUND	Existing techniques for efficiently crawling social media sites rely on URL patterns, query logs, and human supervision.
2	OBJECTIVE	This paper describes SOUrCe, a structure-oriented unsupervised crawler that uses page structures to learn how to crawl a social media site efficiently.
3	METHODS	SOUrCe consists of two stages.
4	METHODS	During its unsupervised learning phase, SOUrCe constructs a sitemap that clusters pages based on their structural similarity and generates a navigation table that describes how the different types of pages in the site are linked together.
5	METHODS	During its harvesting phase, it uses the navigation table and a crawling policy to guide the choice of which links to crawl next.
6	CONCLUSIONS	Experiments show that this architecture supports different styles of crawling efficiently, and does a better job of staying focused on user-created contents than baseline methods.
1	BACKGROUND	Modern threats have emerged from the prevalence of social networks.
2	BACKGROUND	Hostile actors, such as extremist groups or foreign governments, utilize these networks to run propaganda campaigns with different aims.
3	BACKGROUND	For extremists, these campaigns are designed for recruiting new members or inciting violence.
4	BACKGROUND	For foreign governments, the aim may be to create instability in rival nations.
5	BACKGROUND	Proper social network counter-measures are needed to combat these threats.
6	OBJECTIVE	Here we present one important counter-measure: penetrating social networks.
7	OBJECTIVE	This means making target users connect with or follow agents deployed in the social network.
8	OBJECTIVE	Once such connections are established with the targets, the agents can influence them by sharing content which counters the influence campaign.
9	OBJECTIVE	In this work we study how to penetrate a social network, which we call the follow-back problem.
10	OBJECTIVE	The goal here is to find a policy that maximizes the number of targets that follow the agent.
11	METHODS	We conduct an empirical study to understand what behavioral and network features affect the probability of a target following an agent.
12	METHODS	We find that the degree of the target and the size of the mutual neighborhood of the agent and target in the network affect this probability.
13	METHODS	Based on our empirical findings, we then propose a model for targets following an agent.
14	METHODS	Using this model, we solve the follow-back problem exactly on directed acyclic graphs and derive a closed form expression for the expected number of follows an agent receives under the optimal policy.
15	METHODS	We then formulate the follow-back problem on an arbitrary graph as an integer program.
16	METHODS	To evaluate our integer program based policies, we conduct simulations on real social network topologies in Twitter.
17	CONCLUSIONS	We find that our polices result in more effective network penetration, with significant increases in the expected number of targets that follow the agent.
1	BACKGROUND	The concept of truth, as a public good is the production of a collective understanding, which emerges from a complex network of social interactions.
2	BACKGROUND	The recent impact of social networks on shaping the perception of truth in political arena shows how such perception is corroborated and established by the online users, collectively.
3	BACKGROUND	However, investigative journalism for discovering truth is a costly option, given the vast spectrum of online information.
4	BACKGROUND	In some cases, both journalist and online users choose not to investigate the authenticity of the news they receive, because they assume other actors of the network had carried the cost of validation.
5	BACKGROUND	"Therefore, the new phenomenon of ""fake news"" has emerged within the context of social networks."
6	BACKGROUND	The online social networks, similarly to System of Systems, cause emergent properties, which makes authentication processes difficult, given availability of multiple sources.
7	OBJECTIVE	In this study, we show how this conflict can be modeled as a volunteer's dilemma.
8	OBJECTIVE	We also show how the public contribution through news subscription (shared rewards) can impact the dominance of truth over fake news in the network.
1	BACKGROUND	Recent advances in Socially Aware Networks (SANs) have allowed its use in many domains, out of which social Internet of vehicles (SIOV) is of prime importance.
2	BACKGROUND	SANs can provide a promising routing and forwarding paradigm for SIOV by using interest-based communication.
3	BACKGROUND	Though able to improve the forwarding performance, existing interest-based schemes fail to consider the important issue of protecting users' interest information.
4	OBJECTIVE	In this paper, we propose a PRivacy-preserving Interest-based Forwarding scheme (PRIF) for SIOV, which not only protects the interest information, but also improves the forwarding performance.
5	OBJECTIVE	We propose a privacy-preserving authentication protocol to recognize communities among mobile nodes.
6	METHODS	During data routing and forwarding, a node can know others' interests only if they are affiliated with the same community.
7	METHODS	Moreover, to improve forwarding performance, a new metric {\em community energy} is introduced to indicate vehicular social proximity.
8	METHODS	Community energy is generated when two nodes encounter one another and information is shared among them.
9	METHODS	PRIF considers this energy metric to select forwarders towards the destination node or the destination community.
10	CONCLUSIONS	Security analysis indicates PRIF can protect nodes' interest information.
11	CONCLUSIONS	In addition, extensive simulations have been conducted to demonstrate that PRIF outperforms the existing algorithms including the BEEINFO, Epidemic, and PRoPHET.
1	BACKGROUND	Spectral graph theory gives an algebraical approach to analyze the dynamics of a network by using the matrix that represents the network structure.
2	BACKGROUND	However, it is not easy for social networks to apply the spectral graph theory because the matrix elements cannot be given exactly to represent the structure of a social network.
3	BACKGROUND	The matrix element should be set on the basis of the relationship between persons, but the relationship cannot be quantified accurately from obtainable data (e.g., call history and chat history).
4	OBJECTIVE	To get around this problem, we utilize the universality of random matrix with the feature of social networks.
5	OBJECTIVE	As such random matrix, we use normalized Laplacian matrix for a network where link weights are randomly given.
6	OBJECTIVE	In this paper, we first clarify that the universality (i.e., the Wigner semicircle law) of the normalized Laplacian matrix appears in the eigenvalue frequency distribution regardless of the link weight distribution.
7	OBJECTIVE	Then, we analyze the information propagation speed by using the spectral graph theory and the universality of the normalized Laplacian matrix.
8	RESULTS	As the results, we show that the worst-case speed of the information propagation changes at most 2 if the structure (i.e., relationship among people) of a social network changes.
1	BACKGROUND	Finding community structures in social networks is considered to be a challenging task as many of the proposed algorithms are computationally expensive and does not scale well for large graphs.
2	BACKGROUND	Most of the community detection algorithms proposed till date are unsuitable for applications that would require detection of communities in real-time, especially for massive networks.
3	METHODS	The Louvain method, which uses modularity maximization to detect clusters, is usually considered to be one of the fastest community detection algorithms even without any provable bound on its running time.
4	OBJECTIVE	We propose a novel graph traversal-based community detection framework, which not only runs faster than the Louvain method but also generates clusters of better quality for most of the benchmark datasets.
5	RESULTS	We show that our algorithms run in O(|V | + |E|) time to create an initial cover before using modularity maximization to get the final cover.
6	BACKGROUND	Keywords - community detection; Influenced Neighbor Score; brokers; community nodes; communities
1	BACKGROUND	The prevalence of online media has attracted researchers from various domains to explore human behavior and make interesting predictions.
2	OBJECTIVE	In this research, we leverage heterogeneous social media data collected from various online platforms to predict Taiwan's 2016 presidential election.
3	METHODS	"In contrast to most existing research, we take a ""signal"" view of heterogeneous information and adopt the Kalman filter to fuse multiple signals into daily vote predictions for the candidates."
4	METHODS	We also consider events that influenced the election in a quantitative manner based on the so-called event study model that originated in the field of financial research.
5	RESULTS	We obtained the following interesting findings.
6	RESULTS	First, public opinions in online media dominate traditional polls in Taiwan election prediction in terms of both predictive power and timeliness.
7	RESULTS	But offline polls can still function on alleviating the sample bias of online opinions.
8	RESULTS	"Second, although online signals converge as election day approaches, the simple Facebook ""Like"" is consistently the strongest indicator of the election result."
9	RESULTS	Third, most influential events have a strong connection to cross-strait relations, and the Chou Tzu-yu flag incident followed by the apology video one day before the election increased the vote share of Tsai Ing-Wen by 3.66%.
10	CONCLUSIONS	This research justifies the predictive power of online media in politics and the advantages of information fusion.
11	CONCLUSIONS	The combined use of the Kalman filter and the event study method contributes to the data-driven political analytics paradigm for both prediction and attribution purposes.
1	BACKGROUND	Despite the increasing use of social media platforms for information and news gathering, its unmoderated nature often leads to the emergence and spread of rumours, i.e. pieces of information that are unverified at the time of posting.
2	BACKGROUND	At the same time, the openness of social media platforms provides opportunities to study how users share and discuss rumours, and to explore how natural language processing and data mining techniques may be used to find ways of determining their veracity.
3	OBJECTIVE	In this survey we introduce and discuss two types of rumours that circulate on social media; long-standing rumours that circulate for long periods of time, and newly-emerging rumours spawned during fast-paced events such as breaking news, where reports are released piecemeal and often with an unverified status in their early stages.
4	OBJECTIVE	We provide an overview of research into social media rumours with the ultimate goal of developing a rumour classification system that consists of four components: rumour detection, rumour tracking, rumour stance classification and rumour veracity classification.
5	METHODS	We delve into the approaches presented in the scientific literature for the development of each of these four components.
6	CONCLUSIONS	We summarise the efforts and achievements so far towards the development of rumour classification systems and conclude with suggestions for avenues for future research in social media mining for detection and resolution of rumours.
1	BACKGROUND	Social media platforms such as Twitter and Facebook are becoming popular in multilingual societies.
2	BACKGROUND	This trend induces portmanteau of South Asian languages with English.
3	BACKGROUND	The blend of multiple languages as code-mixed data has recently become popular in research communities for various NLP tasks.
4	BACKGROUND	Code-mixed data consist of anomalies such as grammatical errors and spelling variations.
5	OBJECTIVE	In this paper, we leverage the contextual property of words where the different spelling variation of words share similar context in a large noisy social media text.
6	METHODS	We capture different variations of words belonging to same context in an unsupervised manner using distributed representations of words.
7	CONCLUSIONS	Our experiments reveal that preprocessing of the code-mixed dataset based on our approach improves the performance in state-of-the-art part-of-speech tagging (POS-tagging) and sentiment analysis tasks.
1	BACKGROUND	Recent years have witnessed a significant trend towards filling the gap between Social Network Analysis (SNA) and control theory.
2	BACKGROUND	This trend was enabled by the introduction of new mathematical models describing dynamics of social groups, the development of algorithms and software for data analysis and the tremendous progress in understanding complex networks and multi-agent systems (MAS) dynamics.
3	OBJECTIVE	The aim of this tutorial is to highlight a novel chapter of control theory, dealing with dynamic models of social networks and processes over them, to the attention of the broad research community.
4	OBJECTIVE	In its first part [1], we have considered the most classical models of social dynamics, which have anticipated and to a great extent inspired the recent extensive studies on MAS and complex networks.
5	OBJECTIVE	This paper is the second part of the tutorial, and it is focused on more recent models of social processes that have been developed concurrently with MAS theory.
6	OBJECTIVE	Future perspectives of control in social and techno-social systems are also discussed.
1	BACKGROUND	Interaction patterns among individuals play vital roles in spreading infectious diseases.
2	BACKGROUND	Understanding these patterns and integrating their impact in modeling diffusion dynamics of infectious diseases are important for epidemiological studies.
3	BACKGROUND	Current network-based diffusion models assume that diseases transmit through interactions where both infected and susceptible individuals are co-located at the same time.
4	BACKGROUND	However, there are several infectious diseases that can transmit when a susceptible individual visits a location after an infected individual has left.
5	BACKGROUND	Recently, we introduced a diffusion model called same place different time (SPDT) transmission to capture the indirect transmissions that happen when an infected individual leaves before a susceptible individual's arrival along with direct transmissions.
6	OBJECTIVE	In this paper, we demonstrate how these indirect transmission links significantly enhance the emergence of infectious diseases simulating airborne disease spreading on a synthetic social contact network.
7	METHODS	We denote individuals having indirect links but no direct links during their infectious periods as hidden spreaders.
8	RESULTS	Our simulation shows that indirect links play similar roles of direct links and a single hidden spreader can cause large outbreak in the SPDT model which causes no infection in the current model based on direct link.
9	CONCLUSIONS	Our work opens new direction in modeling infectious diseases.
1	BACKGROUND	Metadata are associated to most of the information we produce in our daily interactions and communication in the digital world.
2	BACKGROUND	Yet, surprisingly, metadata are often still catergorized as non-sensitive.
3	BACKGROUND	Indeed, in the past, researchers and practitioners have mainly focused on the problem of the identification of a user from the content of a message.
4	METHODS	In this paper, we use Twitter as a case study to quantify the uniqueness of the association between metadata and user identity and to understand the effectiveness of potential obfuscation strategies.
5	METHODS	More specifically, we analyze atomic fields in the metadata and systematically combine them in an effort to classify new tweets as belonging to an account using different machine learning algorithms of increasing complexity.
6	RESULTS	We demonstrate that through the application of a supervised learning algorithm, we are able to identify any user in a group of 10,000 with approximately 96.7% accuracy.
7	RESULTS	Moreover, if we broaden the scope of our search and consider the 10 most likely candidates we increase the accuracy of the model to 99.22%.
8	RESULTS	We also found that data obfuscation is hard and ineffective for this type of data: even after perturbing 60% of the training data, it is still possible to classify users with an accuracy higher than 95%.
9	RESULTS	These results have strong implications in terms of the design of metadata obfuscation strategies, for example for data set release, not only for Twitter, but, more generally, for most social media platforms.
1	BACKGROUND	The workforce remains the most basic element of social production, even in modern societies.
2	BACKGROUND	Its migration, especially for developing economies such as China, plays a strong role in the reallocation of productive resources and offers a promising proxy for understanding socio-economic issues.
3	BACKGROUND	Nevertheless, due to long cycle, expensive cost and coarse granularity, conventional surveys face challenges in comprehensively profiling it.
4	BACKGROUND	With the permeation of smart and mobile devices in recent decades, booming social media has essentially broken spatio-temporal constraints and enabled the continuous sensing of the real-time mobility of massive numbers of individuals.
5	OBJECTIVE	In this study, we demonstrate that similar to a natural shock, the Spring Festival culturally drives workforce travel between workplaces and hometowns, and the trajectory footprints from social media therefore open a window with unparalleled richness and fine granularity to explore laws in national-level workforce migration.
6	METHODS	To understand the core driving forces of workforce migration flux between cities in China, various indicators reflecting the benefits and costs of migration are introduced into our prediction model.
7	RESULTS	We find that urban GDP (gross domestic product) and travel time are two excellent indicators to help make predictions.
8	RESULTS	Diverse migration patterns are then revealed by clustering the trajectories, which give important clues to help understand the different roles of Chinese cities in their own development and in regional economic development.
9	RESULTS	These patterns are further explained as a joint effect of the subjective will to seek personal benefits and the capacity requirements of local labour markets.
10	CONCLUSIONS	Our study implies that the non-negligible entanglement between social media and macroeconomic behaviours can be insightful for policymaking in social-economic issues.
1	BACKGROUND	Social networking sites such as Twitter have provided a great opportunity for organizations such as public libraries to disseminate information for public relations purposes.
2	BACKGROUND	However, there is a need to analyze vast amounts of social media data.
3	OBJECTIVE	This study presents a computational approach to explore the content of tweets posted by nine public libraries in the northeastern United States of America.
4	METHODS	In December 2017, this study extracted more than 19,000 tweets from the Twitter accounts of seven state libraries and two urban public libraries.
5	METHODS	Computational methods were applied to collect the tweets and discover meaningful themes.
6	CONCLUSIONS	This paper shows how the libraries have used Twitter to represent their services and provides a starting point for different organizations to evaluate the themes of their public tweets.
1	BACKGROUND	Mobile social networks (MSNs) enable people with similar interests to interact without Internet access.
2	BACKGROUND	By forming a temporary group, users can disseminate their data to other interested users in proximity with short-range communication technologies.
3	BACKGROUND	However, due to user mobility, airtime available for users in the same group to disseminate data is limited.
4	BACKGROUND	In addition, for practical consideration, a star network topology among users in the group is expected.
5	BACKGROUND	For the former, unfair airtime allocation among the users will undermine their willingness to participate in MSNs.
6	BACKGROUND	For the latter, a group head is required to connect other users.
7	BACKGROUND	These two problems have to be properly addressed to enable real implementation and adoption of MSNs.
8	OBJECTIVE	To this aim, we propose a Nash bargaining-based joint head selection and airtime allocation scheme for data dissemination within the group.
9	METHODS	Specifically, the bargaining game of joint head selection and airtime allocation is first formulated.
10	METHODS	Then, Nash bargaining solution (NBS) based optimization problems are proposed for a homogeneous case and a more general heterogeneous case.
11	METHODS	For both cases, the existence of solution to the optimization problem is proved, which guarantees Pareto optimality and proportional fairness.
12	METHODS	Next, an algorithm, allowing distributed implementation, for join head selection and airtime allocation is introduced.
13	METHODS	Finally, numerical results are presented to evaluate the performance, validate intuitions and derive insights of the proposed scheme.
1	BACKGROUND	Massive content about user's social, personal and professional life stored on Online Social Networks (OSNs) has attracted not only the attention of researchers and social analysts but also the cyber criminals.
2	BACKGROUND	These cyber criminals penetrate illegally into an OSN by establishing fake profiles or by designing bots and exploit the vulnerabilities of an OSN to carry out illegal activities.
3	BACKGROUND	With the growth of technology cyber crimes have been increasing manifold.
4	BACKGROUND	Daily reports of the security and privacy threats in the OSNs demand not only the intelligent automated detection systems that can identify and alleviate fake profiles in real time but also the reinforcement of the security and privacy laws to curtail the cyber crime.
5	OBJECTIVE	In this paper, we have studied various categories of fake profiles like compromised profiles, cloned profiles and online bots (spam-bots, social-bots, like-bots and influential-bots) on different OSN sites along with existing cyber laws to mitigate their threats.
6	METHODS	In order to design fake profile detection systems, we have highlighted different category of fake profile features which are capable to distinguish different kinds of fake entities from real ones.
7	BACKGROUND	Another major challenges faced by researchers while building the fake profile detection systems is the unavailability of data specific to fake users.
8	METHODS	The paper addresses this challenge by providing extremely obliging data collection techniques along with some existing data sources.
9	METHODS	Furthermore, an attempt is made to present several machine learning techniques employed to design different fake profile detection systems.
1	BACKGROUND	Social media platforms are revolutionizing the way users communicate by increasing the exposure to highly stigmatized issues in the society.
2	BACKGROUND	Sexual abuse is one such issue that recently took over social media via attaching the hashtag #metoo to the shared posts.
3	BACKGROUND	Individuals with different backgrounds and ethnicities began sharing their unfortunate personal experiences of being assaulted.
4	OBJECTIVE	Through comparative analysis of the tweets via #meToo on Twitter versus the posts shared on the #meToo subreddit, this paper makes an initial attempt to assess public reactions and emotions.
5	CONCLUSIONS	Though nearly equal ratios of negative and positive posts are shared on both platforms, Reddit posts are focused on the sexual assaults within families and workplaces while Twitter posts are on showing empathy and encouraging others to continue the #metoo movement.
6	CONCLUSIONS	The data collected in this research and preliminary analysis demonstrate that users use various ways to share their experience, exchange ideas and encourage each other, and social media is suitable for groundswells such as #metoo movement.
1	BACKGROUND	Social media and data mining are increasingly being used to analyse political and societal issues.
2	OBJECTIVE	Here we undertake the classification of social media users as supporting or opposing ongoing independence movements in their territories.
3	BACKGROUND	Independence movements occur in territories whose citizens have conflicting national identities; users with opposing national identities will then support or oppose the sense of being part of an independent nation that differs from the officially recognised country.
4	METHODS	We describe a methodology that relies on users' self-reported location to build large-scale datasets for three territories -- Catalonia, the Basque Country and Scotland.
5	CONCLUSIONS	An analysis of these datasets shows that homophily plays an important role in determining who people connect with, as users predominantly choose to follow and interact with others from the same national identity.
6	RESULTS	We show that a classifier relying on users' follow networks can achieve accurate, language-independent classification performances ranging from 85% to 97% for the three territories.
1	OBJECTIVE	This paper provides a model to investigate information spreading over cyber-social network of agents communicating with each other.
2	METHODS	The cyber-social network considered here comprises individuals and news agencies.
3	METHODS	Each individual holds a belief represented by a scalar.
4	RESULTS	Individuals receive information from news agencies that are closer to their belief, confirmation bias is explicitly incorporated into the model.
5	BACKGROUND	The proposed dynamics of cyber-social networks is adopted from DeGroot-Friedkin model, where the individual's opinion update mechanism is a convex combination of his innate opinion, his neighbors' opinions at the previous time step (obtained from the social network), and the opinions passed along by news agencies from cyber layer which he follows.
6	BACKGROUND	The characteristics of the interdependent social and cyber networks are radically different here: the social network relies on trust and hence static while the news agencies are highly dynamic since they are weighted as a function of the distance between an individual state and the state of news agency to account for confirmation bias.
7	BACKGROUND	The conditions for convergence of the aforementioned dynamics to a unique equilibrium are characterized.
8	RESULTS	The estimation and exact computation of the steady-state values under non-linear and linear state-dependent weight functions are provided.
9	OBJECTIVE	Finally, the impact of polarization in the opinions of news agencies on the public opinion evolution is numerically analyzed in the context of the well-known Krackhardt's advice network.
1	BACKGROUND	With the popularity of microblogging services such as Twitter in recent years, an increasing number of users use these services in their daily lives.
2	BACKGROUND	The huge volume of information generated by users raises new opportunities in various applications and areas.
3	BACKGROUND	Inferring user interests plays a significant role in providing personalized recommendations on microblogging services, and third-party applications providing social logins via these services, especially in cold-start situations.
4	OBJECTIVE	In this survey, we review user modeling strategies with respect to inferring user interests in previous studies.
5	METHODS	To this end, we focus on four dimensions of inferring user interest profiles: (1) data collection, (2) representation of user interest profiles, (3) construction and enhancement of user interest profiles, and (4) the evaluation of the constructed profiles.
6	METHODS	Through this survey, we aim to provide an overview of state-of-the-art user modeling strategies for inferring user interest profiles on microblogging social networks with respect to the four dimensions.
7	RESULTS	For each dimension, we review and summarize previous studies based on specified criteria.
8	CONCLUSIONS	Finally, we discuss some challenges and opportunities for future work in this research domain.
1	BACKGROUND	Sybil detection in social networks is a basic security research problem.
2	BACKGROUND	Structure-based methods have been shown to be promising at detecting Sybils.
3	OBJECTIVE	Existing structure-based methods can be classified into Random Walk (RW)-based methods and Loop Belief Propagation (LBP)-based methods.
4	METHODS	RW-based methods cannot leverage labeled Sybils and labeled benign users simultaneously, which limits their detection accuracy, and/or they are not robust to noisy labels.
5	METHODS	LBP-based methods are not scalable and cannot guarantee convergence.
6	METHODS	In this work, we propose SybilSCAR, a novel structure-based method to detect Sybils in social networks.
7	METHODS	SybilSCAR is Scalable, Convergent, Accurate, and Robust to label noise.
8	METHODS	We first propose a framework to unify RW-based and LBP-based methods.
9	METHODS	Under our framework, these methods can be viewed as iteratively applying a (different) local rule to every user, which propagates label information among a social graph.
10	METHODS	Second, we design a new local rule, which SybilSCAR iteratively applies to every user to detect Sybils.
11	METHODS	We compare SybilSCAR with state-of-the-art RW-based and LBP-based methods theoretically and empirically.
12	RESULTS	Theoretically, we show that, with proper parameter settings, SybilSCAR has a tighter asymptotical bound on the number of Sybils that are falsely accepted into a social network than existing structure-based methods.
13	RESULTS	Empirically, we perform evaluation using both social networks with synthesized Sybils and a large-scale Twitter dataset (41.7M nodes and 1.2B edges) with real Sybils.
14	CONCLUSIONS	Our results show that 1) SybilSCAR is substantially more accurate and more robust to label noise than state-of-the-art RW-based methods; 2) SybilSCAR is more accurate and one order of magnitude more scalable than state-of-the-art LBP-based methods.
1	BACKGROUND	Homophily --- our tendency to surround ourselves with others who share our perspectives and opinions about the world --- is both a part of human nature and an organizing principle underpinning many of our digital social networks.
2	BACKGROUND	"However, when it comes to politics or culture, homophily can amplify tribal mindsets and produce ""echo chambers"" that degrade the quality, safety, and diversity of discourse online."
3	BACKGROUND	While several studies have empirically proven this point, few have explored how making users aware of the extent and nature of their political echo chambers influences their subsequent beliefs and actions.
4	OBJECTIVE	In this paper, we introduce Social Mirror, a social network visualization tool that enables a sample of Twitter users to explore the politically-active parts of their social network.
5	METHODS	We use Social Mirror to recruit Twitter users with a prior history of political discourse to a randomized experiment where we evaluate the effects of different treatments on participants' i) beliefs about their network connections, ii) the political diversity of who they choose to follow, and iii) the political alignment of the URLs they choose to share.
6	RESULTS	While we see no effects on average political alignment of shared URLs, we find that recommending accounts of the opposite political ideology to follow reduces participants' beliefs in the political homogeneity of their network connections but still enhances their connection diversity one week after treatment.
7	RESULTS	Conversely, participants who enhance their belief in the political homogeneity of their Twitter connections have less diverse network connections 2-3 weeks after treatment.
8	OBJECTIVE	We explore the implications of these disconnects between beliefs and actions on future efforts to promote healthier exchanges in our digital public spheres.
1	BACKGROUND	Millions of users share their experiences on social media sites, such as Twitter, which in turn generate valuable data for public health monitoring, digital epidemiology, and other analyses of population health at global scale.
2	OBJECTIVE	The first, critical, task for these applications is classifying whether a personal health event was mentioned, which we call the (PHM) problem.
3	METHODS	"This task is challenging for many reasons, including typically short length of social media posts, inventive spelling and lexicons, and figurative language, including hyperbole using diseases like ""heart attack"" or ""cancer"" for emphasis, and not as a health self-report."
4	METHODS	"This problem is even more challenging for rarely reported, or frequent but ambiguously expressed conditions, such as ""stroke""."
5	METHODS	To address this problem, we propose a general, robust method for detecting PHMs in social media, which we call WESPAD, that combines lexical, syntactic, word embedding-based, and context-based features.
6	METHODS	WESPAD is able to generalize from few examples by automatically distorting the word embedding space to most effectively detect the true health mentions.
7	CONCLUSIONS	Unlike previously proposed state-of-the-art supervised and deep-learning techniques, WESPAD requires relatively little training data, which makes it possible to adapt, with minimal effort, to each new disease and condition.
8	CONCLUSIONS	We evaluate WESPAD on both an established publicly available Flu detection benchmark, and on a new dataset that we have constructed with mentions of multiple health conditions.
9	CONCLUSIONS	Our experiments show that WESPAD outperforms the baselines and state-of-the-art methods, especially in cases when the number and proportion of true health mentions in the training data is small.
1	BACKGROUND	Kempe, Kleinberg and Tardos (KKT) proposed the following conjecture about the general threshold model in social networks: local monotonicity and submodularity imply global monotonicity and submodularity.
2	BACKGROUND	That is, if the threshold function of every node is monotone and submodular, then the spread function $\sigma(S)$ is monotone and submodular, where $S$ is a seed set and the spread function $\sigma(S)$ denotes the expected number of active nodes at termination of a diffusion process starting from $S$.
3	BACKGROUND	The correctness of this conjecture has been proved by Mossel and Roch.
4	BACKGROUND	In this paper, we first provide the concept AD-k (Alternating Difference-$k$) as a generalization of monotonicity and submodularity.
5	BACKGROUND	Specifically, a set function $f$ is called \adk if all the $\ell$-th order differences of $f$ on all inputs have sign $(-1)^{\ell+1}$ for every $\ell\leq k$.
6	BACKGROUND	Note that AD-1 corresponds to monotonicity and AD-2 corresponds to monotonicity and submodularity.
7	OBJECTIVE	We propose a refined version of KKT's conjecture: in the general threshold model, local AD-k implies global AD-k.
8	METHODS	The original KKT conjecture corresponds to the case for AD-2, and the case for AD-1 is the trivial one of local monotonicity implying global monotonicity.
9	METHODS	By utilizing continuous extensions of set functions as well as social graph constructions, we prove the correctness of our conjecture when the social graph is a directed acyclic graph (DAG).
10	METHODS	Furthermore, we affirm our conjecture on general social graphs when $k=\infty$.
1	BACKGROUND	The value and relevance of indigenous knowledge towards sustainability of human societies drives for its preservation.
2	OBJECTIVE	This work explored the use of Facebook groups to promote indigenous knowledge among Igorot peoples in the diaspora.
3	OBJECTIVE	The virtual communities help intensify the connection of Igorot migrants to their traditional culture despite the challenges of assimilation to a different society.
4	METHODS	A survey of posts on 20 Facebook groups identified and classified the indigenous cultural elements conveyed through social media.
5	RESULTS	A subsequent survey of 56 Igorot migrants revealed that popular social media has a significant role in the exchange, revitalization, practice, and learning of indigenous culture; inciting an effective medium to leverage preservation strategies.
1	BACKGROUND	We study the effectiveness of using multiple phases for maximizing the extent of information diffusion through a social network, and present insights while considering various aspects.
2	OBJECTIVE	In particular, we focus on the independent cascade model with the possibility of adaptively selecting seed nodes in multiple phases based on the observed diffusion in preceding phases, and conduct a detailed simulation study on real-world network datasets and various values of seeding budgets.
3	METHODS	We first present a negative result that more phases do not guarantee a better spread, however the adaptability advantage of more phases generally leads to a better spread in practice, as observed on real-world datasets.
4	METHODS	We study how diffusing in multiple phases affects the mean and standard deviation of the distribution representing the extent of diffusion.
5	RESULTS	We then study how the number of phases impacts the effectiveness of multiphase diffusion, how the diffusion progresses phase-by-phase, and what is an optimal way to split the total seeding budget across phases.
6	RESULTS	Our experiments suggest a significant gain when we move from single phase to two phases, and an appreciable gain when we further move to three phases, but the marginal gain thereafter is usually not very significant.
7	CONCLUSIONS	Our main conclusion is that, given the number of phases, an optimal way to split the budget across phases is such that the number of nodes influenced in each phase is almost the same.
1	BACKGROUND	We develop an agent-based model in order to understand agent/node behaviors that generate social media networks.
2	OBJECTIVE	We use simple rules to synthetically generate a backcloth (friend/follow) network collected using Twitter's API.
3	OBJECTIVE	The Twitter network was collected using seeds for known terrorist propaganda accounts in 2015.
4	METHODS	Model parameter adjustments were made to reproduce the collected network's summary statistics, stylized facts and general structural measures.
5	METHODS	We produced an approximate network in line with the general properties of our collected data.
6	RESULTS	We present our findings with a focus on the challenging aspects of this reproduction.
7	RESULTS	We find that while it is possible to generate a social media network utilizing a few simple rules, numerous challenges arise requiring departure from the agent viewpoint and the development of more useful methods.
8	CONCLUSIONS	We present numerous weaknesses and challenges in our reproduction and propose potential solutions for future efforts.
1	BACKGROUND	Large-scale rumor spreading could pose severe social and economic damages.
2	OBJECTIVE	The emergence of online social networks along with the new media can even make rumor spreading more severe.
3	OBJECTIVE	Effective control of rumor spreading is of theoretical and practical significance.
4	METHODS	This paper takes the first step to understand how the blockchain technology can help limit the spread of rumors.
5	METHODS	Specifically, we develop a new paradigm for social networks embedded with the blockchain technology, which employs decentralized contracts to motivate trust networks as well as secure information exchange contract.
6	METHODS	We design a blockchain-based sequential algorithm which utilizes virtual information credits for each peer-to-peer information exchange.
7	RESULTS	We validate the effectiveness of the blockchain-enabled social network on limiting the rumor spreading.
8	CONCLUSIONS	Simulation results validate our algorithm design in avoiding rapid and intense rumor spreading, and motivate better mechanism design for trusted social networks.
1	BACKGROUND	CMO Council reports that 71\% of internet users in the U.S. were influenced by coupons and discounts when making their purchase decisions.
2	BACKGROUND	It has also been shown that offering coupons to a small fraction of users (called seed users) may affect the purchase decisions of many other users in a social network.
3	OBJECTIVE	This motivates us to study the optimal coupon allocation problem, and our objective is to allocate coupons to a set of users so as to maximize the expected cascade.
4	OBJECTIVE	Different from existing studies on influence maximizaton (IM), our framework allows a general utility function and a more complex set of constraints.
5	METHODS	In particular, we formulate our problem as an approximate submodular maximization problem subject to matroid and knapsack constraints.
6	METHODS	Existing techniques relying on the submodularity of the utility function, such as greedy algorithm, can not work directly on a non-submodular function.
7	METHODS	We use $\epsilon$ to measure the difference between our function and its closest submodular function and propose a novel approximate algorithm with approximation ratio $\beta(\epsilon)$ with $\lim_{\epsilon\rightarrow 0}\beta(\epsilon)=1-1/e$.
8	RESULTS	This is the best approximation guarantee for approximate submodular maximization subject to a partition matroid and knapsack constraints, our results apply to a broad range of optimization problems that can be formulated as an approximate submodular maximization problem.
1	BACKGROUND	We introduce a new task called Multimodal Named Entity Recognition (MNER) for noisy user-generated data such as tweets or Snapchat captions, which comprise short text with accompanying images.
2	OBJECTIVE	These social media posts often come in inconsistent or incomplete syntax and lexical notations with very limited surrounding textual contexts, bringing significant challenges for NER.
3	METHODS	To this end, we create a new dataset for MNER called SnapCaptions (Snapchat image-caption pairs submitted to public and crowd-sourced stories with fully annotated named entities).
4	METHODS	We then build upon the state-of-the-art Bi-LSTM word/character based NER models with 1) a deep image network which incorporates relevant visual context to augment textual information, and 2) a generic modality-attention module which learns to attenuate irrelevant modalities while amplifying the most informative ones to extract contexts from, adaptive to each sample and token.
5	METHODS	The proposed MNER model with modality attention significantly outperforms the state-of-the-art text-only NER models by successfully leveraging provided visual contexts, opening up potential applications of MNER on myriads of social media platforms.
1	BACKGROUND	It is well known that any bipartite (social) network can be regarded as a formal context $(G,M,I)$.
2	BACKGROUND	Therefore, such networks give raise to formal concept lattices which can be investigated utilizing the toolset of Formal Concept Analysis (FCA).
3	BACKGROUND	In particular, the notion of clones in closure systems on $M$, i.e., pairwise interchangeable attributes that leave the closure system unchanged, suggests itself naturally as a candidate to be analyzed in the realm of FCA based social network analysis.
4	OBJECTIVE	In this study, we investigate the notion of clones in social networks.
5	METHODS	After building up some theoretical background for the clone relation in formal contexts we try to find clones in real word data sets.
6	RESULTS	To this end, we provide an experimental evaluation on nine mostly well known social networks and provide some first insights on the impact of clones.
7	CONCLUSIONS	We conclude our work by nourishing the understanding of clones by generalizing those to permutations of higher order.
1	BACKGROUND	Domestic Violence against women is now recognized to be a serious and widespread problem worldwide.
2	BACKGROUND	Domestic Violence and Abuse is at the root of so many issues in society and considered as the societal tabooed topic.
3	BACKGROUND	Fortunately, with the popularity of social media, social welfare communities and victim support groups facilitate the victims to share their abusive stories and allow others to give advice and help victims.
4	OBJECTIVE	Hence, in order to offer the immediate resources for those needs, the specific messages from the victims need to be alarmed from other messages.
5	METHODS	In this paper, we regard intention mining as a binary classification problem (abuse or advice) with the usecase of abuse discourse.
6	METHODS	To address this problem, we extract rich feature sets from the raw corpus, using psycholinguistic clues and textual features by term-class interaction method.
7	RESULTS	Machine learning algorithms are used to predict the accuracy of the classifiers between two different feature sets.
8	CONCLUSIONS	Our experimental results with high classification accuracy give a promising solution to understand a big social problem through big social media and its use in serving information needs of various community welfare organizations.
1	BACKGROUND	Health insurance companies in Brazil have their data about claims organized having the view only for providers.
2	BACKGROUND	In this way, they loose the physician view and how they share patients.
3	BACKGROUND	Partnership between physicians can view as a fruitful work in most of the cases but sometimes this could be a problem for health insurance companies and patients, for example a recommendation to visit another physician only because they work in same clinic.
4	OBJECTIVE	The focus of the work is to better understand physicians activities and how these activities are represented in the data.
5	METHODS	Our approach considers three aspects: the relationships among physicians, the relationships between physicians and patients, and the relationships between physicians and health providers.
6	RESULTS	We present the results of an analysis of a claims database (detailing 18 months of activity) from a large health insurance company in Brazil.
7	CONCLUSIONS	The main contribution presented in this paper is a set of models to represent: mutual referral between physicians, patient retention, and physician centrality in the health insurance network.
8	CONCLUSIONS	Our results show the proposed models based on social network frameworks, extracted surprising insights about physicians from real health insurance claims data.
1	BACKGROUND	Finding influential users in online social networks is an important problem with many possible useful applications.
2	BACKGROUND	HITS and other link analysis methods, in particular, have been often used to identify hub and authority users in web graphs and online social networks.
3	CONCLUSIONS	These works, however, have not considered topical aspect of links in their analysis.
4	METHODS	A straightforward approach to overcome this limitation is to first apply topic models to learn the user topics before applying the HITS algorithm.
5	OBJECTIVE	In this paper, we instead propose a novel topic model known as Hub and Authority Topic (HAT) model to combine the two process so as to jointly learn the hub, authority and topical interests.
6	RESULTS	We evaluate HAT against several existing state-of-the-art methods in two aspects: (i) modeling of topics, and (ii) link recommendation.
7	RESULTS	We conduct experiments on two real-world datasets from Twitter and Instagram.
8	CONCLUSIONS	Our experiment results show that HAT is comparable to state-of-the-art topic models in learning topics and it outperforms the state-of-the-art in link recommendation task.
1	BACKGROUND	Social media has grown to be a crucial information source for pharmacovigilance studies where an increasing number of people post adverse reactions to medical drugs that are previously unreported.
2	OBJECTIVE	Aiming to effectively monitor various aspects of Adverse Drug Reactions (ADRs) from diversely expressed social medical posts, we propose a multi-task neural network framework that learns several tasks associated with ADR monitoring with different levels of supervisions collectively.
3	OBJECTIVE	Besides being able to correctly classify ADR posts and accurately extract ADR mentions from online posts, the proposed framework is also able to further understand reasons for which the drug is being taken, known as 'indication', from the given social media post.
4	METHODS	A coverage-based attention mechanism is adopted in our framework to help the model properly identify 'phrasal' ADRs and Indications that are attentive to multiple words in a post.
5	RESULTS	Our framework is applicable in situations where limited parallel data for different pharmacovigilance tasks are available.
6	CONCLUSIONS	We evaluate the proposed framework on real-world Twitter datasets, where the proposed model outperforms the state-of-the-art alternatives of each individual task consistently.
1	RESULTS	We study the problem of optimally investing in nodes of a social network in a competitive setting, wherein two camps attempt to drive the average opinion of the population in their favor.
2	RESULTS	Using DeGroot-Friedkin model of opinion dynamics, we formulate the problem as a zero-sum game with its players being the two camps.
3	RESULTS	We derive optimal investment strategies for both camps, and show that a random investment strategy is optimal when the underlying network follows a popular class of weight distributions.
4	RESULTS	We study a broad framework, where we consider several settings of the problem, namely, when the influence of a camp on a node is a concave function of its investment on that node, when a camp aims at maximizing competitor's investment or deviation from its desired investment, and when one of the camps has uncertain information about the values of the model parameters.
5	RESULTS	We also study the problem under common coupled constraints on the combined investments by the camps and derive optimal strategies of the two camps, and hence quantify the first-mover advantage.
6	RESULTS	For a quantitative and illustrative study, we conduct simulations on real-world datasets and provide results and insights.
1	OBJECTIVE	This paper reports about our work in the NLP Tool Contest @ICON-2017, shared task on Sentiment Analysis for Indian Languages (SAIL) (code mixed).
2	METHODS	"To implement our system, we have used a machine learning algo-rithm called Multinomial Na\""ive Bayes trained using n-gram and SentiWordnet features."
3	METHODS	We have also used a small SentiWordnet for English and a small SentiWordnet for Bengali.
4	METHODS	But we have not used any SentiWordnet for Hindi language.
5	RESULTS	We have tested our system on Hindi-English and Bengali-English code mixed social media data sets released for the contest.
6	RESULTS	The performance of our system is very close to the best system participated in the contest.
7	RESULTS	For both Bengali-English and Hindi-English runs, our system was ranked at the 3rd position out of all submitted runs and awarded the 3rd prize in the contest.
1	BACKGROUND	Historically, machine learning in computer security has prioritized defense: think intrusion detection systems, malware classification, and botnet traffic identification.
2	BACKGROUND	Offense can benefit from data just as well.
3	BACKGROUND	Social networks, with their access to extensive personal data, bot-friendly APIs, colloquial syntax, and prevalence of shortened links, are the perfect venues for spreading machine-generated malicious content.
4	OBJECTIVE	We aim to discover what capabilities an adversary might utilize in such a domain.
5	RESULTS	We present a long short-term memory (LSTM) neural network that learns to socially engineer specific users into clicking on deceptive URLs.
6	METHODS	The model is trained with word vector representations of social media posts, and in order to make a click-through more likely, it is dynamically seeded with topics extracted from the target's timeline.
7	RESULTS	We augment the model with clustering to triage high value targets based on their level of social engagement, and measure success of the LSTM's phishing expedition using click-rates of IP-tracked links.
8	RESULTS	We achieve state of the art success rates, tripling those of historic email attack campaigns, and outperform humans manually performing the same task.
1	BACKGROUND	US voters shared large volumes of polarizing political news and information in the form of links to content from Russian, WikiLeaks and junk news sources.
2	BACKGROUND	Was this low quality political information distributed evenly around the country, or concentrated in swing states and particular parts of the country?
3	METHODS	In this data memo we apply a tested dictionary of sources about political news and information being shared over Twitter over a ten day period around the 2016 Presidential Election.
4	METHODS	Using self-reported location information, we place a third of users by state and create a simple index for the distribution of polarizing content around the country.
5	RESULTS	We find that (1) nationally, Twitter users got more misinformation, polarizing and conspiratorial content than professionally produced news.
6	RESULTS	(2) Users in some states, however, shared more polarizing political news and information than users in other states.
7	RESULTS	(3) Average levels of misinformation were higher in swing states than in uncontested states, even when weighted for the relative size of the user population in each state.
8	CONCLUSIONS	We conclude with some observations about the impact of strategically disseminated polarizing information on public life.
1	BACKGROUND	Social media are more than just a one-way communication channel.
2	BACKGROUND	Data can be collected, analyzed and contextualized to support disaster risk management.
3	BACKGROUND	However, disaster management agencies typically use such added-value information to support only their own decisions.
4	BACKGROUND	A feedback loop between contextualized information and data suppliers would result in various advantages.
5	BACKGROUND	First, it could facilitate the near real-time communication of early warnings derived from social media, linked to other sources of information.
6	BACKGROUND	Second, it could support the staff of aid organizations during response operations.
7	RESULTS	Based on the example of Hurricanes Harvey and Irma we show how filtered, geolocated Tweets can be used for rapid damage assessment.
8	CONCLUSIONS	We claim that the next generation of big data analyses will have to generate actionable information resulting from the application of advanced analytical techniques.
9	CONCLUSIONS	These applications could include the provision of social media-based training data for algorithms designed to forecast actual cyclone impacts or new socio-economic validation metrics for seasonal climate forecasts.
1	BACKGROUND	Social media, as a major platform for communication and information exchange, is a rich repository of the opinions and sentiments of 2.3 billion users about a vast spectrum of topics.
2	BACKGROUND	To sense the whys of certain social user's demands and cultural-driven interests, however, the knowledge embedded in the 1.8 billion pictures which are uploaded daily in public profiles has just started to be exploited since this process has been typically been text-based.
3	METHODS	Following this trend on visual-based social analysis, we present a novel methodology based on Deep Learning to build a combined image-and-text based personality trait model, trained with images posted together with words found highly correlated to specific personality traits.
4	OBJECTIVE	So the key contribution here is to explore whether OCEAN personality trait modeling can be addressed based on images, here called \emph{Mind{P}ics}, appearing with certain tags with psychological insights.
5	RESULTS	We found that there is a correlation between those posted images and their accompanying texts, which can be successfully modeled using deep neural networks for personality estimation.
6	CONCLUSIONS	The experimental results are consistent with previous cyber-psychology results based on texts or images.
7	RESULTS	In addition, classification results on some traits show that some patterns emerge in the set of images corresponding to a specific text, in essence to those representing an abstract concept.
8	CONCLUSIONS	These results open new avenues of research for further refining the proposed personality model under the supervision of psychology experts.
1	METHODS	A public dataset, with a variety of properties suitable for sentiment analysis [1], event prediction, trend detection and other text mining applications, is needed in order to be able to successfully perform analysis studies.
2	BACKGROUND	The vast majority of data on social media is text-based and it is not possible to directly apply machine learning processes into these raw data, since several different processes are required to prepare the data before the implementation of the algorithms.
3	BACKGROUND	For example, different misspellings of same word enlarge the word vector space unnecessarily, thereby it leads to reduce the success of the algorithm and increase the computational power requirement.
4	OBJECTIVE	This paper presents an improved Turkish dataset with an effective spelling correction algorithm based on Hadoop [2].
5	METHODS	The collected data is recorded on the Hadoop Distributed File System and the text based data is processed by MapReduce programming model.
6	BACKGROUND	This method is suitable for the storage and processing of large sized text based social media data.
7	METHODS	In this study, movie reviews have been automatically recorded with Apache ManifoldCF (MCF) [3] and data clusters have been created.
8	BACKGROUND	Various methods compared such as Levenshtein and Fuzzy String Matching have been proposed to create a public dataset from collected data.
9	CONCLUSIONS	Experimental results show that the proposed algorithm, which can be used as an open source dataset in sentiment analysis studies, have been performed successfully to the detection and correction of spelling errors.
1	BACKGROUND	The discovery of influential entities in all kinds of networks (e.g. social, digital, or computer) has always been an important field of study.
2	BACKGROUND	In recent years, Online Social Networks (OSNs) have been established as a basic means of communication and often influencers and opinion makers promote politics, events, brands or products through viral content.
3	OBJECTIVE	In this work, we present a systematic review across i) online social influence metrics, properties, and applications and ii) the role of semantic in modeling OSNs information.
4	CONCLUSIONS	We end up with the conclusion that both areas can jointly provide useful insights towards the qualitative assessment of viral user-generated content, as well as for modeling the dynamic properties of influential content and its flow dynamics.
1	METHODS	We propose a novel method for predicting image labels by fusing image content descriptors with the social media context of each image.
2	BACKGROUND	An image uploaded to a social media site such as Flickr often has meaningful, associated information, such as comments and other images the user has uploaded, that is complementary to pixel content and helpful in predicting labels.
3	BACKGROUND	Prediction challenges such as ImageNet~\cite{imagenet_cvpr09} and MSCOCO~\cite{LinMBHPRDZ:ECCV14} use only pixels, while other methods make predictions purely from social media context \cite{McAuleyECCV12}.
4	METHODS	Our method is based on a novel fully connected Conditional Random Field (CRF) framework, where each node is an image, and consists of two deep Convolutional Neural Networks (CNN) and one Recurrent Neural Network (RNN) that model both textual and visual node/image information.
5	METHODS	The edge weights of the CRF graph represent textual similarity and link-based metadata such as user sets and image groups.
6	METHODS	We model the CRF as an RNN for both learning and inference, and incorporate the weighted ranking loss and cross entropy loss into the CRF parameter optimization to handle the training data imbalance issue.
7	METHODS	Our proposed approach is evaluated on the MIR-9K dataset and experimentally outperforms current state-of-the-art approaches.
1	BACKGROUND	In the recent years, social media have become one of the main places where creative content is being published and consumed by billions of users.
2	BACKGROUND	Contrary to traditional media, social media allow the publishers to receive almost instantaneous feedback regarding their creative work at an unprecedented scale.
3	BACKGROUND	This is a perfect use case for machine learning methods that can use these massive amounts of data to provide content creators with inspirational ideas and constructive criticism of their work.
4	OBJECTIVE	In this work, we present a comprehensive overview of machine learning-empowered tools we developed for video creators at Group Nine Media - one of the major social media companies that creates short-form videos with over three billion views per month.
5	METHODS	Our main contribution is a set of tools that allow the creators to leverage massive amounts of data to improve their creation process, evaluate their videos before the publication and improve content quality.
6	BACKGROUND	These applications include an interactive conversational bot that allows access to material archives, a Web-based application for automatic selection of optimal video thumbnail, as well as deep learning methods for optimizing headline and predicting video popularity.
7	RESULTS	Our A/B tests show that deployment of our tools leads to significant increase of average video view count by 12.9%.
8	CONCLUSIONS	Our additional contribution is a set of considerations collected during the deployment of those tools that can hel
1	BACKGROUND	The spread of unwanted or malicious content through social media has become a major challenge.
2	BACKGROUND	Traditional examples of this include social network spam, but an important new concern is the propagation of fake news through social media.
3	BACKGROUND	A common approach for mitigating this problem is by using standard statistical classification to distinguish malicious (e.g., fake news) instances from benign (e.g., actual news stories).
4	BACKGROUND	However, such an approach ignores the fact that malicious instances propagate through the network, which is consequential both in quantifying consequences (e.g., fake news diffusing through the network), and capturing detection redundancy (bad content can be detected at different nodes).
5	BACKGROUND	An additional concern is evasion attacks, whereby the generators of malicious instances modify the nature of these to escape detection.
6	METHODS	We model this problem as a Stackelberg game between the defender who is choosing parameters of the detection model, and an attacker, who is choosing both the node at which to initiate malicious spread, and the nature of malicious entities.
7	CONCLUSIONS	We develop a novel bi-level programming approach for this problem, as well as a novel solution approach based on implicit function gradients, and experimentally demonstrate the advantage of our approach over alternatives which ignore network structure.
1	BACKGROUND	The emergence of online social networks has greatly facilitated the diffusion of information and behaviors.
2	BACKGROUND	"While the two diffusion processes are often intertwined, ""talking the talk"" does not necessarily mean ""walking the talk""--those who share information about an action may not actually participate in it."
3	BACKGROUND	We do not know if the diffusion of information and behaviors are similar, or if social influence plays an equally important role in these processes.
4	METHODS	Integrating text mining, social network analyses, and survival analysis, this research examines the concurrent spread of information and behaviors related to the Ice Bucket Challenge on Twitter.
5	RESULTS	We show that the two processes follow different patterns.
6	CONCLUSIONS	Unilateral social influence contributes to the diffusion of information, but not to the diffusion of behaviors; bilateral influence conveyed via the communication process is a significant and positive predictor of the diffusion of behaviors, but not of information.
7	CONCLUSIONS	These results have implications for theories of social influence, social networks, and contagion.
1	BACKGROUND	The cross-site linking function is widely adopted by online social networks (OSNs).
2	BACKGROUND	This function allows a user to link her account on one OSN to her accounts on other OSNs.
3	BACKGROUND	Thus, users are able to sign in with the linked accounts, share contents among these accounts and import friends from them.
4	BACKGROUND	It leads to the service integration of different OSNs.
5	BACKGROUND	This integration not only provides convenience for users to manage accounts of different OSNs, but also introduces usefulness to OSNs that adopt the cross-site linking function.
6	OBJECTIVE	In this paper, we investigate this usefulness based on users' data collected from a popular OSN called Medium.
7	METHODS	We conduct a thorough analysis on its social graph, and find that the service integration brought by the cross-site linking function is able to change Medium's social graph structure and attract a large number of new users.
8	METHODS	However, almost none of the new users would become high PageRank users (PageRank is used to measure a user's influence in an OSN).
9	METHODS	To solve this problem, we build a machine-learning-based model to predict high PageRank users in Medium based on their Twitter data only.
10	RESULTS	This model achieves a high F1-score of 0.942 and a high area under the curve (AUC) of 0.986.
11	CONCLUSIONS	Based on it, we design a system to assist new OSNs to identify and attract high PageRank users from other well-established OSNs through the cross-site linking function.
1	BACKGROUND	There have been various studies analyzing public sentiment after a large-scale disaster.
2	BACKGROUND	However, few studies have focused on the relationship between public sentiment on social media and its results on people's activities in the real world.
3	OBJECTIVE	In this paper, we conduct a long-term sentiment analysis after the Great East Japan Earthquake and Tsunami of 2011 using Facebook Pages with the aim of investigating the correlation between public sentiment and people's actual needs in areas damaged by water disasters.
4	OBJECTIVE	In addition, we try to analyze whether different types of disaster-related communication created different kinds of relationships on people's activities in the physical world.
5	RESULTS	Our analysis reveals that sentiment of geo-info-related communication, which might be affected by sentiment inside a damaged area, had a positive correlation with the prices of used cars in the damaged area.
6	RESULTS	On the other hand, the sentiment of disaster-interest-based-communication, which might be affected more by people who were interested in the disaster, but were outside the damaged area, had a negative correlation with the prices of used cars.
7	CONCLUSIONS	The result could be interpreted to mean that when people begin to recover, used-car prices rise because they become more positive in their sentiment.
8	CONCLUSIONS	This study suggests that, for long-term disaster-recovery analysis, we need to consider the different characteristics of online communication posted by locals directly affected by the disaster and non-locals not directly affected by the disaster.
1	BACKGROUND	In this paper, de-anonymizing internet users by actively querying their group memberships in social networks is considered.
2	BACKGROUND	In this problem, an anonymous victim visits the attacker's website, and the attacker uses the victim's browser history to query her social media activity for the purpose of de-anonymization using the minimum number of queries.
3	BACKGROUND	A stochastic model of the problem is considered where the attacker has partial prior knowledge of the group membership graph and receives noisy responses to its real-time queries.
4	BACKGROUND	The victim's identity is assumed to be chosen randomly based on a given distribution which models the users' risk of visiting the malicious website.
5	METHODS	A de-anonymization algorithm is proposed which operates based on information thresholds and its performance both in the finite and asymptotically large social network regimes is analyzed.
6	METHODS	Furthermore, a converse result is provided which proves the optimality of the proposed attack strategy.
1	RESULTS	Harassment by cyberbullies is a significant phenomenon on the social media.
2	RESULTS	Existing works for cyberbullying detection have at least one of the following three bottlenecks.
3	RESULTS	First, they target only one particular social media platform (SMP).
4	RESULTS	Second, they address just one topic of cyberbullying.
5	RESULTS	Third, they rely on carefully handcrafted features of the data.
6	RESULTS	We show that deep learning based models can overcome all three bottlenecks.
7	RESULTS	Knowledge learned by these models on one dataset can be transferred to other datasets.
8	RESULTS	We performed extensive experiments using three real-world datasets: Formspring (12k posts), Twitter (16k posts), and Wikipedia(100k posts).
9	RESULTS	Our experiments provide several useful insights about cyberbullying detection.
10	CONCLUSIONS	To the best of our knowledge, this is the first work that systematically analyzes cyberbullying detection on various topics across multiple SMPs using deep learning based models and transfer learning.
1	BACKGROUND	Online game involves a very large number of users who are interconnected and interact with each other via the Internet.
2	BACKGROUND	"We studied the characteristics of exchanging virtual goods with real money through processes called ""real money trading (RMT)."""
3	BACKGROUND	This exchange might influence online game user behaviors and cause damage to the reputation of game companies.
4	METHODS	We examined in-game transactions to reveal RMT by constructing a social graph of virtual goods exchanges in an online game and identifying network communities of users.
5	RESULTS	We analyzed approximately 6,000,000 transactions in a popular online game and inferred RMT transactions by comparing the RMT transactions crawled from an out-game market.
6	CONCLUSIONS	Our findings are summarized as follows: (1) the size of the RMT market could be approximately estimated; (2) professional RMT providers typically form a specific network structure (either star-shape or chain) in the trading network, which can be used as a clue for tracing RMT transactions; and (3) the observed RMT market has evolved over time into a monopolized market with a small number of large-sized virtual goods providers.
1	BACKGROUND	Topic lifecycle analysis on Twitter, a branch of study that investigates Twitter topics from their birth through lifecycle to death, has gained immense mainstream research popularity.
2	BACKGROUND	In the literature, topics are often treated as one of (a) hashtags (independent from other hashtags), (b) a burst of keywords in a short time span or (c) a latent concept space captured by advanced text analysis methodologies, such as Latent Dirichlet Allocation (LDA).
3	BACKGROUND	The first two approaches are not capable of recognizing topics where different users use different hashtags to express the same concept (semantically related), while the third approach misses out the user's explicit intent expressed via hashtags.
4	METHODS	In our work, we use a word embedding based approach to cluster different hashtags together, and the temporal concurrency of the hashtag usages, thus forming topics (a semantically and temporally related group of hashtags).
5	METHODS	We present a novel analysis of topic lifecycles with respect to communities.
6	METHODS	We characterize the participation of social communities in the topic clusters, and analyze the lifecycle of topic clusters with respect to such participation.
7	METHODS	We derive first-of-its-kind novel insights with respect to the complex evolution of topics over communities and time: temporal morphing of topics over hashtags within communities, how the hashtags die in some communities but morph into some other hashtags in some other communities (that, it is a community-level phenomenon), and how specific communities adopt to specific hashtags.
8	RESULTS	Our work is fundamental in the space of topic lifecycle modeling and understanding in communities: it redefines our understanding of topic lifecycles and shows that the social boundaries of topic lifecycles are deeply ingrained with community behavior.
1	BACKGROUND	While social media offer great communication opportunities, they also increase the vulnerability of young people to threatening situations online.
2	BACKGROUND	Recent studies report that cyberbullying constitutes a growing problem among youngsters.
3	BACKGROUND	Successful prevention depends on the adequate detection of potentially harmful messages and the information overload on the Web requires intelligent systems to identify potential risks automatically.
4	OBJECTIVE	The focus of this paper is on automatic cyberbullying detection in social media text by modelling posts written by bullies, victims, and bystanders of online bullying.
5	METHODS	We describe the collection and fine-grained annotation of a training corpus for English and Dutch and perform a series of binary classification experiments to determine the feasibility of automatic cyberbullying detection.
6	METHODS	We make use of linear support vector machines exploiting a rich feature set and investigate which information sources contribute the most for this particular task.
7	RESULTS	Experiments on a holdout test set reveal promising results for the detection of cyberbullying-related posts.
8	CONCLUSIONS	After optimisation of the hyperparameters, the classifier yields an F1-score of 64% and 61% for English and Dutch respectively, and considerably outperforms baseline systems based on keywords and word unigrams.
1	BACKGROUND	It is important to study the risks of publishing privacy-sensitive data.
2	BACKGROUND	Even if sensitive identities (e.g., name, social security number) were removed and advanced data perturbation techniques were applied, several de-anonymization attacks have been proposed to re-identify individuals.
3	BACKGROUND	However, existing attacks have some limitations: 1) they are limited in de-anonymization accuracy; 2) they require prior seed knowledge and suffer from the imprecision of such seed information.
4	RESULTS	We propose a novel structure-based de-anonymization attack, which does not require the attacker to have prior information (e.g., seeds).
5	OBJECTIVE	Our attack is based on two key insights: using multi-hop neighborhood information, and optimizing the process of de-anonymization by exploiting enhanced machine learning techniques.
6	RESULTS	The experimental results demonstrate that our method is robust to data perturbations and significantly outperforms the state-of-the-art de-anonymization techniques by up to $10\times$ improvement.
1	OBJECTIVE	This paper proposes a novel adaptive algorithm for the automated short-term trading of financial instrument.
2	METHODS	The algorithm adopts a semantic sentiment analysis technique to inspect the Twitter posts and to use them to predict the behaviour of the stock market.
3	METHODS	Indeed, the algorithm is specifically developed to take advantage of both the sentiment and the past values of a certain financial instrument in order to choose the best investment decision.
4	RESULTS	This allows the algorithm to ensure the maximization of the obtainable profits by trading on the stock market.
5	RESULTS	We have conducted an investment simulation and compared the performance of our proposed with a well-known benchmark (DJTATO index) and the optimal results, in which an investor knows in advance the future price of a product.
6	CONCLUSIONS	The result shows that our approach outperforms the benchmark and achieves the performance score close to the optimal result.
1	OBJECTIVE	In current study, a mechanism to extract traffic related information such as congestion and incidents from textual data from the internet is proposed.
2	METHODS	The current source of data is Twitter.
3	METHODS	As the data being considered is extremely large in size automated models are developed to stream, download, and mine the data in real-time.
4	METHODS	Furthermore, if any tweet has traffic related information then the models should be able to infer and extract this data.
5	METHODS	Currently, the data is collected only for United States and a total of 120,000 geo-tagged traffic related tweets are extracted, while six million geo-tagged non-traffic related tweets are retrieved and classification models are trained.
6	METHODS	Furthermore, this data is used for various kinds of spatial and temporal analysis.
7	METHODS	A mechanism to calculate level of traffic congestion, safety, and traffic perception for cities in U.S. is proposed.
8	RESULTS	Traffic congestion and safety rankings for the various urban areas are obtained and then they are statistically validated with existing widely adopted rankings.
9	RESULTS	Traffic perception depicts the attitude and perception of people towards the traffic.
10	RESULTS	It is also seen that traffic related data when visualized spatially and temporally provides the same pattern as the actual traffic flows for various urban areas.
11	RESULTS	When visualized at the city level, it is clearly visible that the flow of tweets is similar to flow of vehicles and that the traffic related tweets are representative of traffic within the cities.
12	RESULTS	With all the findings in current study, it is shown that significant amount of traffic related information can be extracted from Twitter and other sources on internet.
13	CONCLUSIONS	Furthermore, Twitter and these data sources are freely available and are not bound by spatial and temporal limitations.
14	CONCLUSIONS	That is, wherever there is a user there is a potential for data.
1	OBJECTIVE	In this paper we aim at providing a general reflection around the present and future of social media metrics (or altmetrics) and how they could evolve into a new discipline focused on the study of the relationships and interactions between science and social media, in what could be seen as the social media studies of science.
1	METHODS	In order to better understand the effect of social media in the dissemination of scholarly articles, employing the daily updated referral data of 110 PeerJ articles collected over a period of 345 days, we analyze the relationship between social media attention and article visitors directed by social media.
2	RESULTS	Our results show that social media presence of PeerJ articles is high.
3	CONCLUSIONS	About 68.18% of the papers receive at least one tweet from Twitter accounts other than @PeerJ, the official account of the journal.
4	CONCLUSIONS	Social media attention increases the dissemination of scholarly articles.
5	CONCLUSIONS	Altmetrics could not only act as the complement of traditional citation measures but also play an important role in increasing the article downloads and promoting the impacts of scholarly articles.
6	CONCLUSIONS	There also exists a significant correlation among the online attention from different social media platforms.
7	CONCLUSIONS	Articles with more Facebook shares tend to get more tweets.
8	CONCLUSIONS	The temporal trends show that social attention comes immediately following publication but does not last long, so do the social media directed article views.
1	BACKGROUND	As social networks are constantly changing and evolving, methods to analyze dynamic social networks are becoming more important in understanding social trends.
2	BACKGROUND	However, due to the restrictions imposed by the social network service providers, the resources available to fetch the entire contents of a social network are typically very limited.
3	BACKGROUND	As a result, analysis of dynamic social network data requires maintaining an approximate copy of the social network for each time period, locally.
4	OBJECTIVE	In this paper, we study the problem of dynamic network and text fetching with limited probing capacities, for identifying and maintaining influential users as the social network evolves.
5	METHODS	We propose an algorithm to probe the relationships (required for global influence computation) as well as posts (required for topic-based influence computation) of a limited number of users during each probing period, based on the influence trends and activities of the users.
6	METHODS	We infer the current network based on the newly probed user data and the last known version of the network maintained locally.
7	METHODS	Additionally, we propose to use link prediction methods to further increase the accuracy of our network inference.
8	METHODS	We employ PageRank as the metric for influence computation.
9	METHODS	We illustrate how the proposed solution maintains accurate PageRank scores for computing global influence, and topic-sensitive weighted PageRank scores for topic-based influence.
10	METHODS	The latter relies on a topic-based network constructed via weights determined by semantic analysis of posts and their sharing statistics.
11	METHODS	We evaluate the effectiveness of our algorithms by comparing them with the true influence scores of the full and up-to-date version of the network, using data from the micro-blogging service Twitter.
12	CONCLUSIONS	Results show that our techniques significantly outperform baseline methods and are superior to state-of-the-art techniques from the literature.
1	METHODS	This paper employs deep learning in detecting the traffic accident from social media data.
2	METHODS	First, we thoroughly investigate the 1-year over 3 million tweet contents in two metropolitan areas: Northern Virginia and New York City.
3	CONCLUSIONS	Our results show that paired tokens can capture the association rules inherent in the accident-related tweets and further increase the accuracy of the traffic accident detection.
4	METHODS	Second, two deep learning methods: Deep Belief Network (DBN) and Long Short-Term Memory (LSTM) are investigated and implemented on the extracted token.
5	RESULTS	Results show that DBN can obtain an overall accuracy of 85% with about 44 individual token features and 17 paired token features.
6	CONCLUSIONS	The classification results from DBN outperform those of Support Vector Machines (SVMs) and supervised Latent Dirichlet allocation (sLDA).
7	METHODS	Finally, to validate this study, we compare the accident-related tweets with both the traffic accident log on freeways and traffic data on local roads from 15,000 loop detectors.
8	RESULTS	It is found that nearly 66% of the accident-related tweets can be located by the accident log and more than 80% of them can be tied to nearby abnormal traffic data.
9	CONCLUSIONS	Several important issues of using Twitter to detect traffic accidents have been brought up by the comparison including the location and time bias, as well as the characteristics of influential users and hashtags.
1	BACKGROUND	Social media has brought a revolution on how people are consuming news.
2	BACKGROUND	Beyond the undoubtedly large number of advantages brought by social-media platforms, a point of criticism has been the creation of echo chambers and filter bubbles, caused by social homophily and algorithmic personalization.
3	OBJECTIVE	In this paper we address the problem of balancing the information exposure in a social network.
4	OBJECTIVE	We assume that two opposing campaigns (or viewpoints) are present in the network, and that network nodes have different preferences towards these campaigns.
5	OBJECTIVE	Our goal is to find two sets of nodes to employ in the respective campaigns, so that the overall information exposure for the two campaigns is balanced.
6	METHODS	We formally define the problem, characterize its hardness, develop approximation algorithms, and present experimental evaluation results.
7	METHODS	Our model is inspired by the literature on influence maximization, but we offer significant novelties.
8	METHODS	First, balance of information exposure is modeled by a symmetric difference function, which is neither monotone nor submodular, and thus, not amenable to existing approaches.
9	METHODS	Second, while previous papers consider a setting with selfish agents and provide bounds on best response strategies (i.e., move of the last player), we consider a setting with a centralized agent and provide bounds for a global objective function.
1	BACKGROUND	The discovery of community structures in social networks has gained significant attention since it is a fundamental problem in understanding the networks' topology and functions.
2	BACKGROUND	However, most social network data are collected from partially observable networks with both missing nodes and edges.
3	OBJECTIVE	In this paper, we address a new problem of detecting overlapping community structures in the context of such an incomplete network, where communities in the network are allowed to overlap since nodes belong to multiple communities at once.
4	METHODS	To solve this problem, we introduce KroMFac, a new framework that conducts community detection via regularized nonnegative matrix factorization (NMF) based on the Kronecker graph model.
5	METHODS	Specifically, from a generative parameter matrix acquired by the expectation-maximization (EM) algorithm, we first estimate the missing part of the network.
6	METHODS	As our major contribution to the proposed framework, to improve community detection accuracy, we then characterize and select influential nodes (which tend to have high degrees) by ranking, and add them to the existing graph.
7	METHODS	Finally, we uncover the community structures by solving the regularized NMF-aided optimization problem in terms of maximizing the likelihood of the underlying graph.
8	METHODS	Furthermore, adopting normalized mutual information (NMI), we empirically show superiority of our KroMFac approach over two baseline schemes.
1	BACKGROUND	The rise of social media and online social networks has been a disruptive force in society.
2	BACKGROUND	Opinions are increasingly shaped by interactions on online social media, and social phenomena including disagreement and polarization are now tightly woven into everyday life.
3	OBJECTIVE	In this work we initiate the study of the following question: given $n$ agents, each with its own initial opinion that reflects its core value on a topic, and an opinion dynamics model, what is the structure of a social network that minimizes {\em polarization} and {\em disagreement} simultaneously?
4	OBJECTIVE	This question is central to recommender systems: should a recommender system prefer a link suggestion between two online users with similar mindsets in order to keep disagreement low, or between two users with different opinions in order to expose each to the other's viewpoint of the world, and decrease overall levels of polarization?
5	METHODS	Our contributions include a mathematical formalization of this question as an optimization problem and an exact, time-efficient algorithm.
6	RESULTS	We also prove that there always exists a network with $O(n/\epsilon^2)$ edges that is a $(1+\epsilon)$ approximation to the optimum.
7	RESULTS	For a fixed graph, we additionally show how to optimize our objective function over the agents' innate opinions in polynomial time.
8	CONCLUSIONS	We perform an empirical study of our proposed methods on synthetic and real-world data that verify their value as mining tools to better understand the trade-off between of disagreement and polarization.
9	CONCLUSIONS	We find that there is a lot of space to reduce both polarization and disagreement in real-world networks; for instance, on a Reddit network where users exchange comments on politics, our methods achieve a $\sim 60\,000$-fold reduction in polarization and disagreement.
1	OBJECTIVE	In this paper we examine methods to detect hate speech in social media, while distinguishing this from general profanity.
2	OBJECTIVE	We aim to establish lexical baselines for this task by applying supervised classification methods using a recently released dataset annotated for this purpose.
3	BACKGROUND	As features, our system uses character n-grams, word n-grams and word skip-grams.
4	RESULTS	We obtain results of 78% accuracy in identifying posts across three classes.
5	RESULTS	Results demonstrate that the main challenge lies in discriminating profanity and hate speech from each other.
6	CONCLUSIONS	A number of directions for future work are discussed.
1	OBJECTIVE	We present our approach for computer-aided social media text authorship attribution based on recent advances in short text authorship verification.
2	METHODS	We use various natural language techniques to create word-level and character-level models that act as hidden layers to simulate a simple neural network.
3	METHODS	The choice of word-level and character-level models in each layer was informed through validation performance.
4	METHODS	The output layer of our system uses an unweighted majority vote vector to arrive at a conclusion.
5	METHODS	We also considered writing bias in social media posts while collecting our training dataset to increase system robustness.
6	RESULTS	Our system achieved a precision, recall, and F-measure of 0.82, 0.926 and 0.869 respectively.
1	BACKGROUND	Seven out of ten people with bipolar disorder are initially misdiagnosed and thirty percent of individuals with bipolar disorder will commit suicide.
2	BACKGROUND	Identifying the early phases of the disorder is one of the key components for reducing the full development of the disorder.
3	OBJECTIVE	In this study, we aim at leveraging the data from social media to design predictive models, which utilize the psychological and phonological features, to determine the onset period of bipolar disorder and provide insights on its prodrome.
4	METHODS	This study makes these discoveries possible by employing a novel data collection process, coined as Time-specific Subconscious Crowdsourcing, which helps collect a reliable dataset that supplements diagnosis information from people suffering from bipolar disorder.
5	CONCLUSIONS	Our experimental results demonstrate that the proposed models could greatly contribute to the regular assessments of people with bipolar disorder, which is important in the primary care setting.
1	BACKGROUND	Online Social Networks (OSNs) attract billions of users to share information and communicate where viral marketing has emerged as a new way to promote the sales of products.
2	BACKGROUND	An OSN provider is often hired by an advertiser to conduct viral marketing campaigns.
3	BACKGROUND	The OSN provider generates revenue from the commission paid by the advertiser which is determined by the spread of its product information.
4	BACKGROUND	Meanwhile, to propagate influence, the activities performed by users such as viewing video ads normally induce diffusion cost to the OSN provider.
5	OBJECTIVE	In this paper, we aim to find a seed set to optimize a new profit metric that combines the benefit of influence spread with the cost of influence propagation for the OSN provider.
6	METHODS	Under many diffusion models, our profit metric is the difference between two submodular functions which is challenging to optimize as it is neither submodular nor monotone.
7	METHODS	We design a general two-phase framework to select seeds for profit maximization and develop several bounds to measure the quality of the seed set constructed.
8	RESULTS	Experimental results with real OSN datasets show that our approach can achieve high approximation guarantees and significantly outperform the baseline algorithms, including state-of-the-art influence maximization algorithms.
1	BACKGROUND	The rapid growth of location-based services(LBSs)has greatly enriched people's urban lives and attracted millions of users in recent years.
2	BACKGROUND	Location-based social networks(LBSNs)allow users to check-in at a physical location and share daily tips on points-of-interest (POIs) with their friends anytime and anywhere.
3	BACKGROUND	Such check-in behavior can make daily real-life experiences spread quickly through the Internet.
4	BACKGROUND	Moreover, such check-in data in LBSNs can be fully exploited to understand the basic laws of human daily movement and mobility.
5	OBJECTIVE	This paper focuses on reviewing the taxonomy of user modeling for POI recommendations through the data analysis of LBSNs.
6	METHODS	First, we briefly introduce the structure and data characteristics of LBSNs,then we present a formalization of user modeling for POI recommendations in LBSNs.
7	METHODS	Depending on which type of LBSNs data was fully utilized in user modeling approaches for POI recommendations, we divide user modeling algorithms into four categories: pure check-in data-based user modeling, geographical information-based user modeling, spatio-temporal information-based user modeling, and geo-social information-based user modeling.
8	METHODS	Finally,summarizing the existing works, we point out the future challenges and new directions in five possible aspects
1	BACKGROUND	The advent of social networks poses severe threats on user privacy as adversaries can de-anonymize users' identities by mapping them to correlated cross-domain networks.
2	BACKGROUND	Without ground-truth mapping, prior literature proposes various cost functions in hope of measuring the quality of mappings.
3	BACKGROUND	However, there is generally a lacking of rationale behind the cost functions, whose minimizer also remains algorithmically unknown.
4	BACKGROUND	We jointly tackle above concerns under a more practical social network model parameterized by overlapping communities, which, neglected by prior art, can serve as side information for de-anonymization.
5	OBJECTIVE	Regarding the unavailability of ground-truth mapping to adversaries, by virtue of the Minimum Mean Square Error (MMSE), our first contribution is a well-justified cost function minimizing the expected number of mismatched users over all possible true mappings.
6	RESULTS	While proving the NP-hardness of minimizing MMSE, we validly transform it into the weighted-edge matching problem (WEMP), which, as disclosed theoretically, resolves the tension between optimality and complexity: (i) WEMP asymptotically returns a negligible mapping error in large network size under mild conditions facilitated by higher overlapping strength; (ii) WEMP can be algorithmically characterized via the convex-concave based de-anonymization algorithm (CBDA), perfectly finding the optimum of WEMP.
7	CONCLUSIONS	Extensive experiments further confirm the effectiveness of CBDA under overlapping communities, in terms of averagely 90% re-identified users in the rare true cross-domain co-author networks when communities overlap densely, and roughly 70% enhanced re-identification ratio compared to non-overlapping cases.
1	BACKGROUND	The use of virtual reality (VR) is exponentially increasing and due to that many researchers has started to work on developing new VR based social media.
2	BACKGROUND	For this purpose it is important to have an avatar of the users which look like them to be easily generated by the devices which are accessible, such as mobile phone.
3	OBJECTIVE	In this paper, we propose a novel method of recreating a 3D human face model captured with a phone camera image or video data.
4	METHODS	The method focuses more on model shape than texture in order to make the face recognizable.
5	RESULTS	We detect 68 facial feature points and use them to separate a face into four regions.
6	RESULTS	For each area the best fitting models are found and are further morphed combined to find the best fitting models for each area.
7	CONCLUSIONS	These are then combined and further morphed in order to restore the original facial proportions.
8	CONCLUSIONS	We also present a method of texturing the resulting model, where the aforementioned feature points are used to generate a texture for the resulting model
1	BACKGROUND	Prediction of popularity has profound impact for social media, since it offers opportunities to reveal individual preference and public attention from evolutionary social systems.
2	BACKGROUND	Previous research, although achieves promising results, neglects one distinctive characteristic of social data, i.e., sequentiality.
3	BACKGROUND	For example, the popularity of online content is generated over time with sequential post streams of social media.
4	OBJECTIVE	To investigate the sequential prediction of popularity, we propose a novel prediction framework called Deep Temporal Context Networks (DTCN) by incorporating both temporal context and temporal attention into account.
5	METHODS	Our DTCN contains three main components, from embedding, learning to predicting.
6	METHODS	With a joint embedding network, we obtain a unified deep representation of multi-modal user-post data in a common embedding space.
7	METHODS	Then, based on the embedded data sequence over time, temporal context learning attempts to recurrently learn two adaptive temporal contexts for sequential popularity.
8	METHODS	Finally, a novel temporal attention is designed to predict new popularity (the popularity of a new user-post pair) with temporal coherence across multiple time-scales.
9	RESULTS	Experiments on our released image dataset with about 600K Flickr photos demonstrate that DTCN outperforms state-of-the-art deep prediction algorithms, with an average of 21.51% relative performance improvement in the popularity prediction (Spearman Ranking Correlation).
1	METHODS	We introduce initial groundwork for estimating suicide risk and mental health in a deep learning framework.
2	METHODS	By modeling multiple conditions, the system learns to make predictions about suicide risk and mental health at a low false positive rate.
3	METHODS	Conditions are modeled as tasks in a multi-task learning (MTL) framework, with gender prediction as an additional auxiliary task.
4	RESULTS	We demonstrate the effectiveness of multi-task learning by comparison to a well-tuned single-task baseline with the same number of parameters.
5	RESULTS	Our best MTL model predicts potential suicide attempt, as well as the presence of atypical mental health, with AUC > 0.8.
6	RESULTS	We also find additional large improvements using multi-task learning on mental health tasks with limited training data.
1	BACKGROUND	Rumour stance classification, defined as classifying the stance of specific social media posts into one of supporting, denying, querying or commenting on an earlier post, is becoming of increasing interest to researchers.
2	METHODS	While most previous work has focused on using individual tweets as classifier inputs, here we report on the performance of sequential classifiers that exploit the discourse features inherent in social media interactions or 'conversational threads'.
3	RESULTS	Testing the effectiveness of four sequential classifiers -- Hawkes Processes, Linear-Chain Conditional Random Fields (Linear CRF), Tree-Structured Conditional Random Fields (Tree CRF) and Long Short Term Memory networks (LSTM) -- on eight datasets associated with breaking news stories, and looking at different types of local and contextual features, our work sheds new light on the development of accurate stance classifiers.
4	CONCLUSIONS	We show that sequential classifiers that exploit the use of discourse properties in social media conversations while using only local features, outperform non-sequential classifiers.
5	CONCLUSIONS	Furthermore, we show that LSTM using a reduced set of features can outperform the other sequential classifiers; this performance is consistent across datasets and across types of stances.
6	METHODS	To conclude, our work also analyses the different features under study, identifying those that best help characterise and distinguish between stances, such as supporting tweets being more likely to be accompanied by evidence than denying tweets.
7	RESULTS	We also set forth a number of directions for future research.
1	BACKGROUND	Social network analysis is a prominent approach to investigate interpersonal relationships.
2	BACKGROUND	Most studies use self-report data to quantify the connections between participants and construct social networks.
3	BACKGROUND	In recent years smartphones have been used as an alternative to map networks by assessing the proximity between participants based on Bluetooth and GPS data.
4	BACKGROUND	While most studies have handed out specially programmed smartphones to study participants, we developed an application for iOS and Android to collect Bluetooth data from participants own smartphones.
5	OBJECTIVE	In this study, we compared the networks estimated with the smartphone app to those obtained from sociometric badges and self-report data.
6	METHODS	Participants (n=21) installed the app on their phone and wore a sociometric badge during office hours.
7	METHODS	Proximity data was collected for 4 weeks.
8	RESULTS	A contingency table revealed a significant association between proximity data (rho = 0.17, p<0.0001), but the marginal odds were higher for the app (8.6%) than for the badges (1.3%), indicating that dyads were more often detected by the app.
9	RESULTS	We then compared the networks that were estimated using the proximity and self-report data.
10	RESULTS	All three networks were significantly correlated, although the correlation with self-reported data was lower for the app (rho = 0.25) than for badges (rho = 0.67).
11	RESULTS	The scanning rates of the app varied considerably between devices and was lower on iOS than on Android.
12	CONCLUSIONS	The association between the app and the badges increased when the network was estimated between participants whose app recorded more regularly.
13	CONCLUSIONS	These findings suggest that the accuracy of proximity networks can be further improved by reducing missing data and restricting the interpersonal distance at which interactions are detected.
1	METHODS	We employ the recently developed theory of isospectral network reductions to analyze multi-mode social networks.
2	METHODS	This procedure allows us to uncover the hierarchical structure of the networks we consider as well as the hierarchical structure of each mode of the network.
3	RESULTS	Additionally, by performing a dynamical analysis of these networks we are able to analyze the evolution of their structure allowing us to find a number of other network features.
4	RESULTS	We apply both of these approaches to the Southern Women Data Set, one of the most studied social networks and demonstrate that these techniques provide new information, which complements previous findings.
1	OBJECTIVE	This paper considers a multiple stopping time problem for a Markov chain observed in noise, where a decision maker chooses at most L stopping times to maximize a cumulative objective.
2	METHODS	We formulate the problem as a Partially Observed Markov Decision Process (POMDP) and derive structural results for the optimal multiple stopping policy.
3	RESULTS	The main results are as follows: i) The optimal multiple stopping policy is shown to be characterized by threshold curves in the unit simplex of Bayesian Posteriors. ii) The stopping setsl (defined by the threshold curves) are shown to exhibit a nested structure. iii) The optimal cumulative reward is shown to be monotone with respect to the copositive ordering of the transition matrix. iv) A stochastic gradient algorithm is provided for estimating linear threshold policies by exploiting the structural results.
4	RESULTS	These linear threshold policies approximate the threshold curves, and share the monotone structure of the optimal multiple stopping policy.
5	RESULTS	As an illustrative example, we apply the multiple stopping framework to interactively schedule advertisements in live online social media.
6	RESULTS	It is shown that advertisement scheduling using multiple stopping performs significantly better than currently used methods.
1	BACKGROUND	The analysis of the use of social media for innovative entrepreneurship in the context has received little attention in the literature, especially in the context of Knowledge Intensive Business Services (KIBS).
2	OBJECTIVE	Therefore, this paper focuses on bridging this gap by applying text mining and sentiment analysis techniques to identify the innovative entrepreneurship reflected by these companies in their social media.
3	METHODS	Finally, we present and analyze the results of our quantitative analysis of 23.483 posts based on eleven Spanish and Italian consultancy KIBS Twitter Usernames and Keywords using data interpretation techniques such as clustering and topic modeling.
4	CONCLUSIONS	This paper suggests that there is a significant gap between the perceived potential of social media and the entrepreneurial behaviors at the social context in business-to-business (B2B) companies.
1	BACKGROUND	Recommender systems in location based social networks mainly take advantage of social and geographical influence in making personalized Points-of-interest (POI) recommendations.
2	BACKGROUND	The social influence is obtained from social network friends or similar users based on matching visit history whilst the geographical influence is obtained from the geographical footprints users' leave when they check-in at different POIs.
3	BACKGROUND	However, this approach may fall short when a user moves to a new region where they have little or no activity history.
4	OBJECTIVE	We propose a location aware POI recommendation system that models user preferences mainly based on; user reviews and categories of POIs.
5	CONCLUSIONS	We evaluate our algorithm on the Yelp dataset and the experimental results show that our algorithm achieves a better accuracy.
1	BACKGROUND	Social media platforms have recently seen an increase in the occurrence of hate speech discourse which has led to calls for improved detection methods.
2	BACKGROUND	Most of these rely on annotated data, keywords, and a classification technique.
3	BACKGROUND	While this approach provides good coverage, it can fall short when dealing with new terms produced by online extremist communities which act as original sources of words which have alternate hate speech meanings.
4	BACKGROUND	These code words (which can be both created and adopted words) are designed to evade automatic detection and often have benign meanings in regular discourse.
5	BACKGROUND	"As an example, ""skypes"", ""googles"", and ""yahoos"" are all instances of words which have an alternate meaning that can be used for hate speech."
6	BACKGROUND	This overlap introduces additional challenges when relying on keywords for both the collection of data that is specific to hate speech, and downstream classification.
7	OBJECTIVE	In this work, we develop a community detection approach for finding extremist hate speech communities and collecting data from their members.
8	OBJECTIVE	We also develop a word embedding model that learns the alternate hate speech meaning of words and demonstrate the candidacy of our code words with several annotation experiments, designed to determine if it is possible to recognize a word as being used for hate speech without knowing its alternate meaning.
9	RESULTS	We report an inter-annotator agreement rate of K=0.871, and K=0.676 for data drawn from our extremist community and the keyword approach respectively, supporting our claim that hate speech detection is a contextual task and does not depend on a fixed list of keywords.
10	OBJECTIVE	Our goal is to advance the domain by providing a high quality hate speech dataset in addition to learned code words that can be fed into existing classification approaches, thus improving the accuracy of automated detection.
1	BACKGROUND	In social networks, different users may have different privacy preferences and there are many users with public identities.
2	BACKGROUND	Most work on differentially private social network data publication neglects this fact.
3	OBJECTIVE	We aim to release the number of public users that a private user connects to within n hops, called n-range Connection fingerprints(CFPs), under user-level personalized privacy preferences.
4	METHODS	We proposed two schemes, Distance-based exponential budget absorption (DEBA) and Distance-based uniformly budget absorption using Ladder function (DUBA-LF), for privacy-preserving publication of the CFPs based on Personalized differential privacy(PDP), and we conducted a theoretical analysis of the privacy guarantees provided within the proposed schemes.
5	CONCLUSIONS	The implementation showed that the proposed schemes are superior in publication errors on real datasets.
1	BACKGROUND	There is an ongoing debate about whether the Internet is like a public sphere or an echo chamber.
2	BACKGROUND	Among many forms of social media, Twitter is one of the most crucial online places for political debate.
3	BACKGROUND	Most of the previous studies focus on the formal structure of the Twitter political field, such as its homophilic tendency, or otherwise limit the analysis to a few topics.
4	OBJECTIVE	In order to explore whether Twitter functions as an echo chamber in general, however, we have to investigate not only the structure but also the contents of Twitter's political field.
5	METHODS	Accordingly, we conducted both large-scale social network analysis and natural language processing.
6	METHODS	We firstly applied a community detection method to the reciprocal following network in Twitter and found five politically distinct communities in the field.
7	METHODS	We further examined dominant topics discussed therein by employing a topic model in analyzing the content of the tweets, and we found that a topic related to xenophobia is circulated solely in right-wing communities.
8	RESULTS	To our knowledge, this is the first study to address echo chambers in Japanese Twitter political field and to examine the formal structure and the contents of tweets with the combination of large-scale social network analysis and natural language processing.
1	BACKGROUND	Two of the defining elements of Social Networking Services are the social profile, containing information about the user, and the social graph, containing information about the connections between users.
2	BACKGROUND	Social Networking Services are used to connect to known people as well as to discover new contacts.
3	BACKGROUND	Current friend recommendation mechanisms typically utilize the social graph.
4	OBJECTIVE	In this paper, we argue that psychometrics, the field of measuring personality traits, can help make meaningful friend recommendations based on an extended social profile containing collected smartphone sensor data.
5	OBJECTIVE	This will support the development of highly distributed Social Networking Services without central knowledge of the social graph.
1	BACKGROUND	To deal with the sheer volume of information and gain competitive advantage, the news industry has started to explore and invest in news automation.
2	OBJECTIVE	In this paper, we present Reuters Tracer, a system that automates end-to-end news production using Twitter data.
3	RESULTS	It is capable of detecting, classifying, annotating, and disseminating news in real time for Reuters journalists without manual intervention.
4	RESULTS	In contrast to other similar systems, Tracer is topic and domain agnostic.
5	RESULTS	It has a bottom-up approach to news detection, and does not rely on a predefined set of sources or subjects.
6	RESULTS	Instead, it identifies emerging conversations from 12+ million tweets per day and selects those that are news-like.
7	RESULTS	Then, it contextualizes each story by adding a summary and a topic to it, estimating its newsworthiness, veracity, novelty, and scope, and geotags it.
8	RESULTS	Designing algorithms to generate news that meets the standards of Reuters journalists in accuracy and timeliness is quite challenging.
9	RESULTS	But Tracer is able to achieve competitive precision, recall, timeliness, and veracity on news detection and delivery.
10	CONCLUSIONS	In this paper, we reveal our key algorithm designs and evaluations that helped us achieve this goal, and lessons learned along the way.
1	BACKGROUND	Detecting community structure in social networks is a fundamental problem empowering us to identify groups of actors with similar interests.
2	BACKGROUND	There have been extensive works focusing on finding communities in static networks, however, in reality, due to dynamic nature of social networks, they are evolving continuously.
3	BACKGROUND	Ignoring the dynamic aspect of social networks, neither allows us to capture evolutionary behavior of the network nor to predict the future status of individuals.
4	BACKGROUND	Aside from being dynamic, another significant characteristic of real-world social networks is the presence of leaders, i.e. nodes with high degree centrality having a high attraction to absorb other members and hence to form a local community.
5	METHODS	In this paper, we devised an efficient method to incrementally detect communities in highly dynamic social networks using the intuitive idea of importance and persistence of community leaders over time.
6	OBJECTIVE	Our proposed method is able to find new communities based on the previous structure of the network without recomputing them from scratch.
7	CONCLUSIONS	This unique feature, enables us to efficiently detect and track communities over time rapidly.
8	RESULTS	Experimental results on the synthetic and real-world social networks demonstrate that our method is both effective and efficient in discovering communities in dynamic social networks.
1	OBJECTIVE	In this work, we propose a profile matching (or deanonymization) attack for unstructured online social networks (OSNs) in which similarity in graphical structure cannot be used for profile matching.
2	METHODS	We consider different attributes that are publicly shared by users.
3	METHODS	Such attributes include both obvious identifiers such as the user name and non-obvious identifiers such as interest similarity or sentiment variation between different posts of a user in different platforms.
4	METHODS	We study the effect of using different combinations of these attributes to the profile matching in order to show the privacy threat in an extensive way.
5	METHODS	Our proposed framework mainly relies on machine learning techniques and optimization algorithms.
6	METHODS	We evaluate the proposed framework on two real-life datasets that are constructed by us.
7	RESULTS	Our results indicate that profiles of the users in different OSNs can be matched with high probability by only using publicly shared attributes and without using the underlying graphical structure of the OSNs.
8	METHODS	We also propose possible countermeasures to mitigate this threat in the expense of reduction in the accuracy (or utility) of the attributes shared by the users.
9	RESULTS	We formulate the tradeoff between the privacy and profile utility of the users as an optimization problem and show how slight changes in the profiles of the users would reduce the success of the attack.
10	CONCLUSIONS	We believe that this work will be a valuable step to build a privacy-preserving tool for users against profile matching attacks between OSNs.
1	BACKGROUND	In many instances one may want to gain situational awareness in an environment by monitoring the content of local social media users.
2	BACKGROUND	Often the challenge is how to build a set of users from a target location.
3	METHODS	Here we introduce a method for building such a set of users by using an \emph{expand-classify} approach which begins with a small set of seed users from the target location and then iteratively collects their neighbors and then classifies their locations.
4	METHODS	We perform this classification using maximum likelihood estimation on a factor graph model which incorporates features of the user profile and also social network connections.
5	RESULTS	We show that maximum likelihood estimation reduces to solving a minimum cut problem on an appropriately defined graph.
6	RESULTS	We are able to obtain several thousand users within a few hours for many diverse locations using our approach.
7	RESULTS	Using geo-located data, we find that our approach typically achieves good accuracy for population centers with less than 500,000 inhabitants, while for larger cities performance degrades somewhat.
8	RESULTS	We also find that our approach is able to collect many more users with higher accuracy than existing search methods.
9	CONCLUSIONS	Finally, we show that by studying the content of location specific users obtained with our approach, we can identify the onset of significant social unrest in locations such as the Philippines.
1	BACKGROUND	A question of interest in both theory and practice is if and how familiarity between members of a team, expressed in terms of social network structure, relates to the success of the team in a given task.
2	METHODS	In this paper we revisit this important question in a novel manner by employing game outcome statistics from Dota 2, a popular team-based multiplayer online game, combined with network data from Steam Community, a social networking service for gamers.
3	METHODS	We conduct a large-scale analysis of 4168 teams to study how network density, and the minimum and maximum degree of the within-team social network are associated with team performance, and determine how this association is moderated by team skill.
4	RESULTS	We observe that minimum degree is strongly associated with good performance, especially in teams with lower skill.
5	CONCLUSIONS	Together with previous results on network density that we corroborate in this paper, our findings suggest that a successful team is not only moderately connected overall, but its members should also individually have not too few nor too many within team connections.
1	OBJECTIVE	We analyse the corpus of user relationships of the Slashdot technology news site.
2	METHODS	The data was collected from the Slashdot Zoo feature where users of the website can tag other users as friends and foes, providing positive and negative endorsements.
3	METHODS	We adapt social network analysis techniques to the problem of negative edge weights.
4	METHODS	In particular, we consider signed variants of global network characteristics such as the clustering coefficient, node-level characteristics such as centrality and popularity measures, and link-level characteristics such as distances and similarity measures.
5	METHODS	We evaluate these measures on the task of identifying unpopular users, as well as on the task of predicting the sign of links and show that the network exhibits multiplicative transitivity which allows algebraic methods based on matrix multiplication to be used.
6	METHODS	We compare our methods to traditional methods which are only suitable for positively weighted edges.
1	OBJECTIVE	This chapter discusses important challenges of designing the data collection setup for social media studies.
2	OBJECTIVE	It outlines how it is necessary to carefully think about which data to collect and to use, and to recognize the effects that a specific data collection approach may have on the types of analyses that can be carried out and the results that can be expected in a study.
3	METHODS	We will highlight important questions one should ask before setting up a data collection framework and relate them to the different options for accessing social media data.
4	METHODS	The chapter will mainly be illustrated with examples from studying Twitter and Facebook.
5	METHODS	A case study studying political communication around the 2013 elections in Germany should serve as a practical application scenario.
6	METHODS	In this case study we constructed several social media datasets based on different collection approaches, using data from Facebook and Twitter.
1	BACKGROUND	Following the trend of data trading and data publishing, many online social networks have enabled potentially sensitive data to be exchanged or shared on the web.
2	BACKGROUND	As a result, users' privacy could be exposed to malicious third parties since they are extremely vulnerable to de-anonymization attacks, i.e., the attacker links the anonymous nodes in the social network to their real identities with the help of background knowledge.
3	BACKGROUND	Previous work in social network de-anonymization mostly focuses on designing accurate and efficient de-anonymization methods.
4	OBJECTIVE	We study this topic from a different perspective and attempt to investigate the intrinsic relation between the attacker's knowledge and the expected de-anonymization gain.
5	BACKGROUND	One common intuition is that the more auxiliary information the attacker has, the more accurate de-anonymization becomes.
6	BACKGROUND	However, their relation is much more sophisticated than that.
7	OBJECTIVE	To simplify the problem, we attempt to quantify background knowledge and de-anonymization gain under several assumptions.
8	RESULTS	Our theoretical analysis and simulations on synthetic and real network data show that more background knowledge may not necessarily lead to more de-anonymization gain in certain cases.
9	CONCLUSIONS	Though our analysis is based on a few assumptions, the findings still leave intriguing implications for the attacker to make better use of the background knowledge when performing de-anonymization, and for the data owners to better measure the privacy risk when releasing their data to third parties.
1	BACKGROUND	Homophily, ranging from demographics to sentiments, breeds connections in social networks, either offline or online.
2	BACKGROUND	However, with the prosperous growth of music streaming service, whether homophily exists in online music listening remains unclear.
3	OBJECTIVE	In this study, two online social networks of a same group of active users are established respectively in Netease Music and Weibo.
4	CONCLUSIONS	Through presented multiple similarity measures, it is evidently demonstrated that homophily does exist in music listening of both online social networks.
5	RESULTS	The unexpected music similarity in Weibo also implies that knowledge from generic social networks can be confidently transfered to domain-oriented networks for context enrichment and algorithm enhancement.
6	RESULTS	Comprehensive factors that might function in formation of homophily are further probed and many interesting patterns are profoundly revealed.
7	CONCLUSIONS	It is found that female friends are more homogeneous in music listening and positive and energetic songs significantly pull users close.
8	CONCLUSIONS	Our methodology and findings would shed lights on realistic applications in online music services.
1	BACKGROUND	This paper presents Klout Topics, a lightweight ontology to describe social media users' topics of interest and expertise.
2	BACKGROUND	Klout Topics is designed to: be human-readable and consumer-friendly; cover multiple domains of knowledge in depth; and promote data extensibility via knowledge base entities.
3	BACKGROUND	We discuss why this ontology is well-suited for text labeling and interest modeling applications, and how it compares to available alternatives.
4	BACKGROUND	We show its coverage against common social media interest sets, and examples of how it is used to model the interests of over 780M social media users on Klout.com.
5	BACKGROUND	Finally, we open the ontology for external use.
1	BACKGROUND	Politicians all over the world are investing considerable time and effort in both creating and curating social media profiles, with many sending hundreds or even thousands of messages over social platforms during election time, often with the help of trained and professional staff.
2	BACKGROUND	However, there have been only a handful of papers that have sought to test whether active campaigning on social media actually makes a positive difference to vote share outcomes.
3	BACKGROUND	All of these studies are based on cross-sectional datasets from one election period that make separating true relationships from unobserved variables problematic.
4	BACKGROUND	Hence empirical evidence on the actual impact of social media campaigning is thin.
5	OBJECTIVE	We analyse data from the first panel study of candidate social media use during elections, based on Twitter use in the 2015 and 2017 elections in the United Kingdom.
6	RESULTS	We find support for the idea that Twitter based campaigning is associated with voting outcomes, a finding which is robust to a variety of different model specifications and a strong empirical test using a two wave panel design.
7	RESULTS	Furthermore, we show that while the impact of Twitter use is small in absolute terms, it is nevertheless comparable with that of increased campaign spending, and could conceivably make a difference in a close electoral race.
8	CONCLUSIONS	We use our results to advance theory around the impact of social media use on voter behaviour.
1	BACKGROUND	This article presents a novel approach for learning low-dimensional distributed representations of users in online social networks.
2	BACKGROUND	Existing methods rely on the network structure formed by the social relationships among users to extract these representations.
3	BACKGROUND	However, the network information can be obsolete, incomplete or dynamically changing.
4	BACKGROUND	In addition, in some cases, it can be prohibitively expensive to get the network information.
5	OBJECTIVE	Therefore, we propose an alternative approach based on observations from topics being talked on in social networks.
6	METHODS	We utilise the time information of users adopting topics in order to embed them in a real-valued vector space.
7	METHODS	Through extensive experiments, we investigate the properties of the representations learned and their efficacy in preserving information about link structure among users.
8	METHODS	We also evaluate the representations in two different prediction tasks, namely, predicting most likely future adopters of a topic and predicting the geo-location of users.
9	RESULTS	Experiments to validate the proposed methods are performed on a large-scale social network extracted from Twitter, consisting of about 7.7 million users and their activity on around 3.6 million topics over a month-long period.
1	OBJECTIVE	In this paper, we propose an approach for the detection of clickbait posts in online social media (OSM).
2	BACKGROUND	Clickbait posts are short catchy phrases that attract a user's attention to click to an article.
3	METHODS	The approach is based on a machine learning (ML) classifier capable of distinguishing between clickbait and legitimate posts published in OSM.
4	METHODS	The suggested classifier is based on a variety of features, including image related features, linguistic analysis, and methods for abuser detection.
5	RESULTS	In order to evaluate our method, we used two datasets provided by Clickbait Challenge 2017.
6	RESULTS	The best performance obtained by the ML classifier was an AUC of 0.8, an accuracy of 0.812, precision of 0.819, and recall of 0.966.
7	CONCLUSIONS	In addition, as opposed to previous studies, we found that clickbait post titles are statistically significant shorter than legitimate post titles.
8	CONCLUSIONS	Finally, we found that counting the number of formal English words in the given content is useful for clickbait detection.
1	BACKGROUND	With the rise of social media, millions of people are routinely expressing their moods, feelings, and daily struggles with mental health issues on social media platforms like Twitter.
2	METHODS	Unlike traditional observational cohort studies conducted through questionnaires and self-reported surveys, we explore the reliable detection of clinical depression from tweets obtained unobtrusively.
3	RESULTS	Based on the analysis of tweets crawled from users with self-reported depressive symptoms in their Twitter profiles, we demonstrate the potential for detecting clinical depression symptoms which emulate the PHQ-9 questionnaire clinicians use today.
4	METHODS	Our study uses a semi-supervised statistical model to evaluate how the duration of these symptoms and their expression on Twitter (in terms of word usage patterns and topical preferences) align with the medical findings reported via the PHQ-9.
5	RESULTS	Our proactive and automatic screening tool is able to identify clinical depressive symptoms with an accuracy of 68% and precision of 72%.
1	METHODS	In this paper, a new mathematical formulation for the problem of de-anonymizing social network users by actively querying their membership in social network groups is introduced.
2	METHODS	In this formulation, the attacker has access to a noisy observation of the group membership of each user in the social network.
3	METHODS	When an unidentified victim visits a malicious website, the attacker uses browser history sniffing to make queries regarding the victim's social media activity.
4	METHODS	Particularly, it can make polar queries regarding the victim's group memberships and the victim's identity.
5	METHODS	The attacker receives noisy responses to her queries.
6	METHODS	The goal is to de-anonymize the victim with the minimum number of queries.
7	METHODS	Starting with a rigorous mathematical model for this active de-anonymization problem, an upper bound on the attacker's expected query cost is derived, and new attack algorithms are proposed which achieve this bound.
8	BACKGROUND	These algorithms vary in computational cost and performance.
9	CONCLUSIONS	The results suggest that prior heuristic approaches to this problem provide sub-optimal solutions.
1	BACKGROUND	"Users' persistent social media contents like posts on Facebook Timeline are presented as an ""exhibition"" about the person to others, and managing these exhibitional contents for impression management needs intentional and manual efforts."
2	RESULTS	To raise awareness of and facilitate impression management around past contents, we developed a prototype called PersonalityInsight.
3	METHODS	The system employs computational psycho-linguistic analysis to help users visualize the way their past text posts might convey impressions of their personality and allowed users to modify their posts based on these visualizations.
4	RESULTS	We conducted a user study to evaluate the design; users overall found that such a tool raised awareness of the fact and the ways personality might be conveyed through their past content as one aspect of impression management, but that it needs design improvement to offer action-able suggestions for content modification, as well as careful thinking about impression management as one of many values people have about their digital past.
1	OBJECTIVE	In a large social network whose members harbor binary sentiments towards an issue, we investigate the asymptotic accuracy of sentiment detection.
2	METHODS	We model the user sentiments by an Ising Markov random field model and allow the user sentiments to be biased by an external influence.
3	CONCLUSIONS	We consider a general supermajority sentiment detection problem and show that the detection accuracy is affected by the network structure, its parameters, as well as the external influence level.
1	BACKGROUND	Clickbait (headlines) make use of misleading titles that hide critical information from or exaggerate the content on the landing target pages to entice clicks.
2	BACKGROUND	As clickbaits often use eye-catching wording to attract viewers, target contents are often of low quality.
3	BACKGROUND	Clickbaits are especially widespread on social media such as Twitter, adversely impacting user experience by causing immense dissatisfaction.
4	BACKGROUND	Hence, it has become increasingly important to put forward a widely applicable approach to identify and detect clickbaits.
5	OBJECTIVE	In this paper, we make use of a dataset from the clickbait challenge 2017 (clickbait-challenge.com) comprising of over 21,000 headlines/titles, each of which is annotated by at least five judgments from crowdsourcing on how clickbait it is.
6	OBJECTIVE	We attempt to build an effective computational clickbait detection model on this dataset.
7	RESULTS	We first considered a total of 331 features, filtered out many features to avoid overfitting and improve the running time of learning, and eventually selected the 60 most important features for our final model.
8	RESULTS	Using these features, Random Forest Regression achieved the following results: MSE=0.035 MSE, Accuracy=0.82, and F1-sore=0.61 on the clickbait class.
1	BACKGROUND	Hurricane Sandy was one of the deadliest and costliest of hurricanes over the past few decades.
2	BACKGROUND	Many states experienced significant power outage, however many people used social media to communicate while having limited or no access to traditional information sources.
3	OBJECTIVE	In this study, we explored the evolution of various communication patterns using machine learning techniques and determined user concerns that emerged over the course of Hurricane Sandy.
4	METHODS	The original data included ~52M tweets coming from ~13M users between October 14, 2012 and November 12, 2012.
5	METHODS	We run topic model on ~763K tweets from top 4,029 most frequent users who tweeted about Sandy at least 100 times.
6	RESULTS	We identified 250 well-defined communication patterns based on perplexity.
7	RESULTS	Conversations of most frequent and relevant users indicate the evolution of numerous storm-phase (warning, response, and recovery) specific topics.
8	RESULTS	People were also concerned about storm location and time, media coverage, and activities of political leaders and celebrities.
9	METHODS	We also present each relevant keyword that contributed to one particular pattern of user concerns.
10	METHODS	Such keywords would be particularly meaningful in targeted information spreading and effective crisis communication in similar major disasters.
11	CONCLUSIONS	Each of these words can also be helpful for efficient hash-tagging to reach target audience as needed via social media.
12	CONCLUSIONS	The pattern recognition approach of this study can be used in identifying real time user needs in future crises.
1	BACKGROUND	Badges are a common, and sometimes the only, method of incentivizing users to perform certain actions on online sites.
2	BACKGROUND	However, due to many competing factors influencing user temporal dynamics, it is difficult to determine whether the badge had (or will have) the intended effect or not.
3	OBJECTIVE	In this paper, we introduce two complementary approaches for determining badge influence on users.
4	METHODS	In the first one, we cluster users' temporal traces (represented with point processes) and apply covariates (user features) to regularize results.
5	METHODS	In the second approach, we first classify users' temporal traces with a novel statistical framework, and then we refine the classification results with a semi-supervised clustering of covariates.
6	CONCLUSIONS	Outcomes obtained from an evaluation on synthetic datasets and experiments on two badges from a popular Q&A platform confirm that it is possible to validate, characterize and to some extent predict users affected by the badge.
1	BACKGROUND	On social networks, while nodes bear rich attributes, we often lack the `semantics' of why each link is formed-- and thus we are missing the `road signs' to navigate and organize the complex social universe.
2	OBJECTIVE	How to identify relationship semantics without labels?
3	METHODS	Founded on the prevalent homophily principle, we propose the novel problem of Attribute-based Relationship Profiling (ARP), to profile the closeness w.r.t. the underlying relationships (e.g., schoolmate) between users based on their similarity in the corresponding attributes (e.g., education) and, as output, learn a set of social affinity graphs, where each link is weighted by its probabilities of carrying the relationships.
4	METHODS	As requirements, ARP should be systematic and complete to profile every link for every relationship-- our challenges lie in effectively modeling homophily.
5	CONCLUSIONS	We propose a novel reverse smoothness principle by observing that the similarity-closeness duality of homophily is consistent with the well-known smoothness assumption in graph-based semi-supervised learning-- only the direction of inference is reversed.
6	RESULTS	To realize smoothness over noisy social graphs, we further propose a novel holistic closeness modeling approach to capture `high-order' smoothness by extending closeness from edges to paths.
7	CONCLUSIONS	Extensive experiments on three real-world datasets demonstrate the efficacy of ARP.
1	METHODS	This paper discusses discrete-time maps of the form $x(k + 1) = F(x(k))$, focussing on equilibrium points of such maps.
2	METHODS	Under some circumstances, Lefschetz fixed-point theory can be used to establish the existence of a single locally attractive equilibrium (which is sometimes globally attractive) when a general property of local attractivity is known for any equilibrium.
3	METHODS	Problems in social networks often involve such discrete-time systems, and we make an application to one such problem.
1	BACKGROUND	Existing socio-psychological studies suggest that users of a social network form their opinions relying on the opinions of their neighbors.
2	BACKGROUND	According to DeGroot opinion formation model, one value of particular importance is the asymptotic consensus value---the sum of user opinions weighted by the users' eigenvector centralities.
3	BACKGROUND	This value plays the role of an attractor for the opinions in the network and is a lucrative target for external influence.
4	BACKGROUND	However, since any potentially malicious control of the opinion distribution in a social network is clearly undesirable, it is important to design methods to prevent the external attempts to strategically change the asymptotic consensus value.
5	METHODS	In this work, we assume that the adversary wants to maximize the asymptotic consensus value by altering the opinions of some users in a network; we, then, state DIVER---an NP-hard problem of disabling such external influence attempts by strategically adding a limited number of edges to the network.
6	RESULTS	Relying on the theory of Markov chains, we provide perturbation analysis that shows how eigenvector centrality and, hence, DIVER's objective function change in response to an edge's addition to the network.
7	CONCLUSIONS	The latter leads to the design of a pseudo-linear-time heuristic for DIVER, whose computation relies on efficient estimation of mean first passage times in a Markov chain.
8	CONCLUSIONS	We confirm our theoretical findings in experiments.
1	OBJECTIVE	We study a unique network dataset including periodic surveys and electronic logs of dyadic contacts via smartphones.
2	METHODS	The participants were a sample of freshmen entering university in the Fall 2011.
3	METHODS	Their opinions on a variety of political and social issues and lists of activities on campus were regularly recorded at the beginning and end of each semester for the first three years of study.
4	RESULTS	We identify a behavioral network defined by call and text data, and a cognitive network based on friendship nominations in ego-network surveys.
5	RESULTS	Both networks are limited to study participants.
6	RESULTS	Since a wide range of attributes on each node were collected in self-reports, we refer to these networks as attribute-rich networks.
7	OBJECTIVE	We study whether student preferences for certain attributes of friends can predict formation and dissolution of edges in both networks.
8	OBJECTIVE	We introduce a method for computing student preferences for different attributes which we use to predict link formation and dissolution.
9	OBJECTIVE	We then rank these attributes according to their importance for making predictions.
10	CONCLUSIONS	We find that personal preferences, in particular political views, and preferences for common activities help predict link formation and dissolution in both the behavioral and cognitive networks.
1	BACKGROUND	Which topics spark the most heated debates on social media?
2	BACKGROUND	Identifying those topics is not only interesting from a societal point of view, but also allows the filtering and aggregation of social media content for disseminating news stories.
3	OBJECTIVE	In this paper, we perform a systematic methodological study of controversy detection by using the content and the network structure of social media.
4	METHODS	Unlike previous work, rather than study controversy in a single hand-picked topic and use domain specific knowledge, we take a general approach to study topics in any domain.
5	METHODS	Our approach to quantifying controversy is based on a graph-based three-stage pipeline, which involves (i) building a conversation graph about a topic; (ii) partitioning the conversation graph to identify potential sides of the controversy; and (iii) measuring the amount of controversy from characteristics of the graph.
6	METHODS	We perform an extensive comparison of controversy measures, different graph-building approaches, and data sources.
7	METHODS	We use both controversial and non-controversial topics on Twitter, as well as other external datasets.
8	CONCLUSIONS	We find that our new random-walk-based measure outperforms existing ones in capturing the intuitive notion of controversy, and show that content features are vastly less helpful in this task.
1	RESULTS	We develop a novel visual model which can recognize protesters, describe their activities by visual attributes and estimate the level of perceived violence in an image.
2	CONCLUSIONS	Studies of social media and protests use natural language processing to track how individuals use hashtags and links, often with a focus on those items' diffusion.
3	CONCLUSIONS	These approaches, however, may not be effective in fully characterizing actual real-world protests (e.g., violent or peaceful) or estimating the demographics of participants (e.g., age, gender, and race) and their emotions.
4	RESULTS	Our system characterizes protests along these dimensions.
5	OBJECTIVE	We have collected geotagged tweets and their images from 2013-2017 and analyzed multiple major protest events in that period.
6	BACKGROUND	A multi-task convolutional neural network is employed in order to automatically classify the presence of protesters in an image and predict its visual attributes, perceived violence and exhibited emotions.
7	RESULTS	We also release the UCLA Protest Image Dataset, our novel dataset of 40,764 images (11,659 protest images and hard negatives) with various annotations of visual attributes and sentiments.
8	RESULTS	Using this dataset, we train our model and demonstrate its effectiveness.
9	OBJECTIVE	We also present experimental results from various analysis on geotagged image data in several prevalent protest events.
10	RESULTS	Our dataset will be made accessible at https://www.sscnet.ucla.edu/comm/jjoo/mm-protest/.
1	BACKGROUND	The success of a disaster relief and response process is largely dependent on timely and accurate information regarding the status of the disaster, the surrounding environment, and the affected people.
2	BACKGROUND	This information is primarily provided by first responders on-site and can be enhanced by the firsthand reports posted in real-time on social media.
3	BACKGROUND	Many tools and methods have been developed to automate disaster relief by extracting, analyzing, and visualizing actionable information from social media.
4	BACKGROUND	However, these methods are not well integrated in the relief and response processes and the relation between the two requires exposition for further advancement.
5	OBJECTIVE	In this survey, we review the new frontier of intelligent disaster relief and response using social media, show stages of disasters which are reflected on social media, establish a connection between proposed methods based on social media and relief efforts by first responders, and outline pressing challenges and future research directions.
1	BACKGROUND	A social network service is a platform to build social relations among people sharing similar interests and activities.
2	BACKGROUND	The underlying structure of a social networks service is the social graph, where nodes represent users and the arcs represent the users' social links and other kind of connections.
3	BACKGROUND	One important concern in social networks is privacy: what others are (not) allowed to know about us.
4	BACKGROUND	"The ""logic of knowledge"" (epistemic logic) is thus a good formalism to define, and reason about, privacy policies."
5	BACKGROUND	In this paper we consider the problem of verifying knowledge properties over social network models (SNMs), that is social graphs enriched with knowledge bases containing the information that the users know.
6	BACKGROUND	More concretely, our contributions are: i) We prove that the model checking problem for epistemic properties over SNMs is decidable; ii) We prove that a number of properties of knowledge that are sound w.r.t.
7	BACKGROUND	Kripke models are also sound w.r.t.
8	BACKGROUND	SNMs; iii) We give a satisfaction-preserving encoding of SNMs into canonical Kripke models, and we also characterise which Kripke models may be translated into SNMs; iv) We show that, for SNMs, the model checking problem is cheaper than the one based on standard Kripke models.
9	BACKGROUND	Finally, we have developed a proof-of-concept implementation of the model-checking algorithm for SNMs.
1	BACKGROUND	In networks, multiple contagions, such as information and purchasing behaviors, may interact with each other as they spread simultaneously.
2	BACKGROUND	However, most of the existing information diffusion models are built on the assumption that each individual contagion spreads independently, regardless of their interactions.
3	BACKGROUND	Gaining insights into such interaction is crucial to understand the contagion adoption behaviors, and thus can make better predictions.
4	OBJECTIVE	In this paper, we study the contagion adoption behavior under a set of interactions, specifically, the interactions among users, contagions' contents and sentiments, which are learned from social network structures and texts.
5	OBJECTIVE	We then develop an effective and efficient interaction-aware diffusion (IAD) framework, incorporating these interactions into a unified model.
6	OBJECTIVE	We also present a generative process to distinguish user roles, a co-training method to determine contagions' categories and a new topic model to obtain topic-specific sentiments.
7	METHODS	Evaluation on large-scale Weibo dataset demonstrates that our proposal can learn how different users, contagion categories and sentiments interact with each other efficiently.
8	CONCLUSIONS	With these interactions, we can make a more accurate prediction than the state-of-art baselines.
9	CONCLUSIONS	Moreover, we can better understand how the interactions influence the propagation process and thus can suggest useful directions for information promotion or suppression in viral marketing.
1	BACKGROUND	Nowadays, there are many approaches designed for the task of detecting communities in social networks.
2	BACKGROUND	Among them, some methods only consider the topological graph structure, while others take use of both the graph structure and the node attributes.
3	BACKGROUND	In real-world networks, there are many uncertain and noisy attributes in the graph.
4	OBJECTIVE	In this paper, we will present how we detect communities in graphs with uncertain attributes in the first step.
5	METHODS	The numerical, probabilistic as well as evidential attributes are generated according to the graph structure.
6	METHODS	In the second step, some noise will be added to the attributes.
7	METHODS	We perform experiments on graphs with different types of attributes and compare the detection results in terms of the Normalized Mutual Information (NMI) values.
8	RESULTS	The experimental results show that the clustering with evidential attributes gives better results comparing to those with probabilistic and numerical attributes.
9	CONCLUSIONS	This illustrates the advantages of evidential attributes.
1	BACKGROUND	Research on the structure of dialogue has been hampered for years because large dialogue corpora have not been available.
2	BACKGROUND	This has impacted the dialogue research community's ability to develop better theories, as well as good off the shelf tools for dialogue processing.
3	BACKGROUND	Happily, an increasing amount of information and opinion exchange occur in natural dialogue in online forums, where people share their opinions about a vast range of topics.
4	BACKGROUND	In particular we are interested in rejection in dialogue, also called disagreement and denial, where the size of available dialogue corpora, for the first time, offers an opportunity to empirically test theoretical accounts of the expression and inference of rejection in dialogue.
5	RESULTS	In this paper, we test whether topic-independent features motivated by theoretical predictions can be used to recognize rejection in online forums in a topic independent way.
6	RESULTS	Our results show that our theoretically motivated features achieve 66% accuracy, an improvement over a unigram baseline of an absolute 6%.
1	BACKGROUND	Social media for news consumption is a double-edged sword.
2	BACKGROUND	On the one hand, its low cost, easy access, and rapid dissemination of information lead people to seek out and consume news from social media.
3	BACKGROUND	"On the other hand, it enables the wide spread of ""fake news"", i.e., low quality news with intentionally false information."
4	BACKGROUND	The extensive spread of fake news has the potential for extremely negative impacts on individuals and society.
5	BACKGROUND	Therefore, fake news detection on social media has recently become an emerging research that is attracting tremendous attention.
6	BACKGROUND	Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ineffective or not applicable.
7	BACKGROUND	First, fake news is intentionally written to mislead readers to believe false information, which makes it difficult and nontrivial to detect based on news content; therefore, we need to include auxiliary information, such as user social engagements on social media, to help make a determination.
8	BACKGROUND	Second, exploiting this auxiliary information is challenging in and of itself as users' social engagements with fake news produce data that is big, incomplete, unstructured, and noisy.
9	BACKGROUND	Because the issue of fake news detection on social media is both challenging and relevant, we conducted this survey to further facilitate research on the problem.
10	OBJECTIVE	In this survey, we present a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets.
11	OBJECTIVE	We also discuss related research areas, open problems, and future research directions for fake news detection on social media.
1	BACKGROUND	Communities typically capture homophily as people of the same community share many common features.
2	BACKGROUND	This paper is motivated by the problem of community detection in social networks, as it can help improve our understanding of the network topology and the spread of information.
3	BACKGROUND	Given the selfish nature of humans to align with like-minded people, we employ game theoretic models and algorithms to detect communities in this paper.
4	METHODS	Specifically, we employ coordination games to represent interactions between individuals in a social network.
5	RESULTS	We represent the problem of community detection as a graph coordination game.
6	RESULTS	We provide a novel and scalable two phased approach to compute an accurate overlapping community structure in the given network.
7	RESULTS	We evaluate our algorithm against the best existing methods for community detection and show that our algorithm improves significantly on benchmark networks (real and synthetic) with respect to standard Normalised Mutual Information measure.
1	OBJECTIVE	The present work proposes the use of social media as a tool for better understanding the relationship between a journalists' social network and the content they produce.
2	OBJECTIVE	Specifically, we ask: what is the relationship between the ideological leaning of a journalist's social network on Twitter and the news content he or she produces?
3	CONCLUSIONS	Using a novel dataset linking over 500,000 news articles produced by 1,000 journalists at 25 different news outlets, we show a modest correlation between the ideologies of who a journalist follows on Twitter and the content he or she produces.
4	RESULTS	This research can provide the basis for greater self-reflection among media members about how they source their stories and how their own practice may be colored by their online networks.
5	RESULTS	For researchers, the findings furnish a novel and important step in better understanding the construction of media stories and the mechanics of how ideology can play a role in shaping public information.
1	BACKGROUND	Random walk-based sampling methods are gaining popularity and importance in characterizing large networks.
2	BACKGROUND	While powerful, they suffer from the slow mixing problem when the graph is loosely connected, which results in poor estimation accuracy.
3	BACKGROUND	Random walk with jumps (RWwJ) can address the slow mixing problem but it is inapplicable if the graph does not support uniform vertex sampling (UNI).
4	METHODS	In this work, we develop methods that can efficiently sample a graph without the necessity of UNI but still enjoy the similar benefits as RWwJ.
5	RESULTS	We observe that many graphs under study, called target graphs, do not exist in isolation.
6	RESULTS	In many situations, a target graph is related to an auxiliary graph and a bipartite graph, and they together form a better connected {\em two-layered network structure}.
7	RESULTS	This new viewpoint brings extra benefits to graph sampling: if directly sampling a target graph is difficult, we can sample it indirectly with the assistance of the other two graphs.
8	CONCLUSIONS	We propose a series of new graph sampling techniques by exploiting such a two-layered network structure to estimate target graph characteristics.
9	CONCLUSIONS	Experiments conducted on both synthetic and real-world networks demonstrate the effectiveness and usefulness of these new techniques.
1	BACKGROUND	Bots have been playing a crucial role in online platform ecosystems, as efficient and automatic tools to generate content and diffuse information to the social media human population.
2	OBJECTIVE	In this chapter, we will discuss the role of social bots in content spreading dynamics in social media.
3	OBJECTIVE	In particular, we will first investigate some differences between diffusion dynamics of content generated by bots, as opposed to humans, in the context of political communication, then study the characteristics of bots behind the diffusion dynamics of social media spam campaigns.
1	BACKGROUND	Information can propagate among Online Social Network (OSN) users at a high speed, which makes the OSNs become important platforms for viral marketing.
2	BACKGROUND	Although the viral marketing related problems in OSNs have been extensively studied in the past decade, the existing works all assume known propagation rates and are not able to solve the scenario when the rates may dynamically increase for popular topics.
3	OBJECTIVE	In this paper, we propose a novel model, Dynamic Influence Propagation (DIP), which allows propagation rates to change during the diffusion and can be used for describing information propagation in OSNs more realistically.
4	METHODS	Based on DIP, we define a new research problem: Threshold Activation Problem under DIP (TAP-DIP).
5	METHODS	TAP-DIP is more generalized than TAP and can be used for studying the DIP model.
6	METHODS	However, it adds another layer of complexity over the already \#P-hard TAP problem.
7	RESULTS	Despite it hardness, we are able to approximate TAP-DIP with $O(\log|V|)$ ratio.
8	METHODS	Our solution consists of two major parts: 1) the Lipschitz optimization technique and 2) a novel solution to the general version of TAP, the Multi-TAP problem.
9	CONCLUSIONS	We experimentally test our solution Using various real OSN datasets, and demonstrate that our solution not only generates high-quality yet much smaller seed sets when being aware of the rate increase, but also is scalable.
10	CONCLUSIONS	In addition, considering DIP or not has a significant difference in seed set selection.
1	METHODS	We model the spread of news as a social learning game on a network.
2	RESULTS	Agents can either endorse or oppose a claim made in a piece of news, which itself may be either true or false.
3	RESULTS	Agents base their decision on a private signal and their neighbors' past actions.
4	RESULTS	Given these inputs, agents follow strategies derived via multi-agent deep reinforcement learning and receive utility from acting in accordance with the veracity of claims.
5	RESULTS	Our framework yields strategies with agent utility close to a theoretical, Bayes optimal benchmark, while remaining flexible to model re-specification.
6	RESULTS	Optimized strategies allow agents to correctly identify most false claims, when all agents receive unbiased private signals.
7	RESULTS	However, an adversary's attempt to spread fake news by targeting a subset of agents with a biased private signal can be successful.
8	RESULTS	Even more so when the adversary has information about agents' network position or private signal.
9	RESULTS	When agents are aware of the presence of an adversary they re-optimize their strategies in the training stage and the adversary's attack is less effective.
10	RESULTS	Hence, exposing agents to the possibility of fake news can be an effective way to curtail the spread of fake news in social networks.
11	RESULTS	Our results also highlight that information about the users' private beliefs and their social network structure can be extremely valuable to adversaries and should be well protected.
1	BACKGROUND	Classic models on opinion dynamics usually focus on a group of agents forming their opinions interactively over single issue.
2	BACKGROUND	Yet generally consensus can not be achieved over single issue when agents are not completely open to interpersonal influence.
3	OBJECTIVE	In this paper, opinion consensus in social networks with stubborn agents is considered over issue sequences.
4	BACKGROUND	The social network with stubborn agents is described by the Friedkin-Johnsen (F-J) model where agents are stubborn to their initial opinions.
5	METHODS	Firstly, we propose some sufficient and necessary conditions both in terms of network topology and system matrix for convergence of the F-J model over single issue.
6	METHODS	Secondly, opinion consensus of the F-J model is investigated over issue sequences.
7	RESULTS	Our analysis establishes connections between the interpersonal influence network and the network describing the relationship of agents' initial opinions for successive issues.
8	METHODS	Taking advantage of these connections, we derive the sufficient and necessary condition for the F-J model to achieve opinion consensus over issue sequences.
9	METHODS	Finally, we consider a more general scenario where each agent has bounded confidence in forming its initial opinion for every issue.
10	CONCLUSIONS	By analyzing the evolution of agents' ultimate opinions for each issue over issue sequences, we prove that the connectivity of the state-dependent network is preserved in this setting.
11	CONCLUSIONS	Then the conditions for agents to achieve opinion consensus over issue sequences are proposed.
12	CONCLUSIONS	Simulation examples are provided to illustrate the effectiveness of our theoretical results.
1	BACKGROUND	Classification of social media data is an important approach in understanding user behavior on the Web.
2	BACKGROUND	Although information on social media can be of different modalities such as texts, images, audio or videos, traditional approaches in classification usually leverage only one prominent modality.
3	BACKGROUND	Techniques that are able to leverage multiple modalities are often complex and susceptible to the absence of some modalities.
4	OBJECTIVE	In this paper, we present simple models that combine information from different modalities to classify social media content and are able to handle the above problems with existing techniques.
5	METHODS	Our models combine information from different modalities using a pooling layer and an auxiliary learning task is used to learn a common feature space.
6	OBJECTIVE	We demonstrate the performance of our models and their robustness to the missing of some modalities in the emotion classification domain.
7	CONCLUSIONS	Our approaches, although being simple, can not only achieve significantly higher accuracies than traditional fusion approaches but also have comparable results when only one modality is available.
1	BACKGROUND	The popularity and widespread usage of online social networks (OSN) have attracted cyber criminals who have used OSNs as a platform to spread malware.
2	BACKGROUND	Among different types of malware in OSNs, Trojan is the most popular type with hundreds of attacks on OSN users in the past few years.
3	BACKGROUND	Trojans infecting a user's computer have the ability to steal confidential information, install ransomware and infect other computers in the network.
4	BACKGROUND	Therefore, it is important to understand propagation dynamics of Trojans in OSNs in order to detect, contain and remove them as early as possible.
5	OBJECTIVE	In this article, we present an analytical model to study propagation characteristics of Trojans and factors that impact their propagation in an online social network.
6	METHODS	The proposed model assumes all the topological characteristics of real online social networks.
7	METHODS	Moreover, the model takes into account attacking trends of modern Trojans, the role of anti-virus (AV) products, and security practices of OSN users and AV software providers.
8	CONCLUSIONS	By taking into account these factors, the proposed model can accurately and realistically estimate the infection rate caused by a Trojan malware in an OSN as well as the recovery rate of the user population.
1	BACKGROUND	Peatland fires and haze events are disasters with national, regional and international implications.
2	BACKGROUND	The phenomena lead to direct damage to local assets, as well as broader economic and environmental losses.
3	BACKGROUND	Satellite imagery is still the main and often the only available source of information for disaster management.
4	OBJECTIVE	In this article, we test the potential of social media to assist disaster management.
5	METHODS	To this end, we compare insights from two datasets: fire hotspots detected via NASA satellite imagery and almost all GPS-stamped tweets from Sumatra Island, Indonesia, posted during 2014.
6	METHODS	Sumatra Island is chosen as it regularly experiences a significant number of haze events, which affect citizens in Indonesia as well as in nearby countries including Malaysia and Singapore.
7	METHODS	We analyse temporal correlations between the datasets and their geo-spatial interdependence.
8	METHODS	Furthermore, we show how Twitter data reveals changes in users' behavior during severe haze events.
9	RESULTS	Overall, we demonstrate that social media is a valuable source of complementary and supplementary information for haze disaster management.
10	CONCLUSIONS	Based on our methodology and findings, an analytics tool to improve peatland fire and haze disaster management by the Indonesian authorities is under development.
1	BACKGROUND	Nowadays, with the remarkable expansion of the information through the internet, users prefer to receive the exact information that they need through some suggestions from their friends or profiles to save their time and money.
2	BACKGROUND	Recommend systems based on different algorithms as one of the basic ways to reach this goal through the internet have been proposed but each of them has their own advantages and disadvantages.
3	METHODS	In this study, we have selected and implemented two approaches which are Collaborative Filtering (CF) and Social Network Recommendations System (SNRS).
4	METHODS	Based on some limitations to finding a dataset which covers friendship, rating and item categories we generated it for 10 categories, 10 items, and 100 users and compared two approaches.
5	METHODS	We used Mean Absolute Error (MAE) and accuracy to compare the result of two mentioned approaches and found that the SNRS method as it is claimed to be improved version of CF works more efficiency.
1	BACKGROUND	Modern communication networks are inherently complex in nature.
2	BACKGROUND	First of all, they have a large number of heterogeneous components.
3	BACKGROUND	Secondly, their connectivity is extremely dynamic.
4	BACKGROUND	Nodes can come and go, links can be removed and added over time.
5	BACKGROUND	Traditional modeling and simulation techniques amalgamate or ignore such dynamics and therefore, are unable to represent them.
6	OBJECTIVE	Complex communication networks are therefore better modeled as mathematical structures called graphs.
7	METHODS	Modeling as graphs allows for the application of complex techniques such as various network based analysis techniques.
8	BACKGROUND	While this is a very important and much needed skill for communication networks researchers and engineers, to the best of our knowledge, currently there is no resource describing these details.
9	OBJECTIVE	In this paper, we give a concise but comprehensive review of modeling complex communication networks as graphs.
10	RESULTS	We also show how to apply complex social network analysis on these models besides a demonstration of formal modeling network dynamics.
1	OBJECTIVE	In this paper, we present a set of computational methods to identify the likeliness of a word being borrowed, based on the signals from social media.
2	RESULTS	In terms of Spearman correlation coefficient values, our methods perform more than two times better (nearly 0.62) in predicting the borrowing likeliness compared to the best performing baseline (nearly 0.26) reported in literature.
3	METHODS	Based on this likeliness estimate we asked annotators to re-annotate the language tags of foreign words in predominantly native contexts.
4	RESULTS	In 88 percent of cases the annotators felt that the foreign language tag should be replaced by native language tag, thus indicating a huge scope for improvement of automatic language identification systems.
1	BACKGROUND	The accelerated growth of mobile trajectories in location-based services brings valuable data resources to understand users' moving behaviors.
2	BACKGROUND	Apart from recording the trajectory data, another major characteristic of these location-based services is that they also allow the users to connect whomever they like.
3	BACKGROUND	A combination of social networking and location-based services is called as location-based social networks (LBSN).
4	BACKGROUND	As shown in previous works, locations that are frequently visited by socially-related persons tend to be correlated, which indicates the close association between social connections and trajectory behaviors of users in LBSNs.
5	OBJECTIVE	In order to better analyze and mine LBSN data, we present a novel neural network model which can joint model both social networks and mobile trajectories.
6	OBJECTIVE	In specific, our model consists of two components: the construction of social networks and the generation of mobile trajectories.
7	METHODS	We first adopt a network embedding method for the construction of social networks: a networking representation can be derived for a user.
8	METHODS	The key of our model lies in the component of generating mobile trajectories.
9	METHODS	We have considered four factors that influence the generation process of mobile trajectories, namely user visit preference, influence of friends, short-term sequential contexts and long-term sequential contexts.
10	METHODS	To characterize the last two contexts, we employ the RNN and GRU models to capture the sequential relatedness in mobile trajectories at different levels, i.e., short term or long term.
11	METHODS	Finally, the two components are tied by sharing the user network representations.
12	RESULTS	Experimental results on two important applications demonstrate the effectiveness of our model.
13	CONCLUSIONS	Especially, the improvement over baselines is more significant when either network structure or trajectory data is sparse.
1	RESULTS	The increasing popularity of online social network brings huge privacy threat for the end users.
2	BACKGROUND	While existing work focus on inferring sensitive attributes from the social network such as age, location and gender, little has been done on how to protect the users' privacy by preventing the malicious inference.
3	METHODS	In this paper we investigated the privacy vulnerability of the existing social network and designed a privacy-preserving framework.
4	OBJECTIVE	We evaluated the framework's privacy and usefulness guarantees, demonstrated its effectiveness on classification and the defense against the privacy attack.
1	BACKGROUND	Time is an important relevance signal when searching streams of social media posts.
2	BACKGROUND	The distribution of document timestamps from the results of an initial query can be leveraged to infer the distribution of relevant documents, which can then be used to rerank the initial results.
3	BACKGROUND	Previous experiments have shown that kernel density estimation is a simple yet effective implementation of this idea.
4	OBJECTIVE	This paper explores an alternative approach to mining temporal signals with recurrent neural networks.
5	BACKGROUND	Our intuition is that neural networks provide a more expressive framework to capture the temporal coherence of neighboring documents in time.
6	OBJECTIVE	To our knowledge, we are the first to integrate lexical and temporal signals in an end-to-end neural network architecture, in which existing neural ranking models are used to generate query-document similarity vectors that feed into a bidirectional LSTM layer for temporal modeling.
7	RESULTS	Our results are mixed: existing neural models for document ranking alone yield limited improvements over simple baselines, but the integration of lexical and temporal signals yield significant improvements over competitive temporal baselines.
1	OBJECTIVE	The aim of this article is to provide an understanding of social networks as a useful addition to the standard tool-box of techniques used by system designers.
2	OBJECTIVE	To this end, we give examples of how data about social links have been collected and used in di erent application contexts.
3	METHODS	We develop a broad taxonomy-based overview of common properties of social networks, review how they might be used in di erent applications, and point out potential pitfalls where appropriate.
4	METHODS	We propose a framework, distinguishing between two main types of social network-based user selection-personalised user selection which identi es target users who may be relevant for a given source node, using the social network around the source as a context, and generic user selection or group delimitation, which lters for a set of users who satisfy a set of application requirements based on their social properties.
5	METHODS	Using this framework, we survey applications of social networks in three typical kinds of application scenarios: recommender systems, content-sharing systems (e.g., P2P or video streaming), and systems which defend against users who abuse the system (e.g., spam or sybil attacks).
6	METHODS	In each case, we discuss potential directions for future research that involve using social network properties.
1	OBJECTIVE	This paper measures social media activity of 15 broad scientific disciplines indexed in Scopus database using Altmetric.com data.
2	METHODS	First, the presence of Altmetric.com data in Scopus database is investigated, overall and across disciplines.
3	METHODS	Second, the correlation between the bibliometric and altmetric indices is examined using Spearman correlation.
4	METHODS	Third, a zero-truncated negative binomial model is used to determine the association of various factors with increasing or decreasing citations.
5	METHODS	Lastly, the effectiveness of altmetric indices to identify publications with high citation impact is comprehensively evaluated by deploying Area Under the Curve (AUC) - an application of receiver operating characteristic.
6	RESULTS	Results indicate a rapid increase in the presence of Altmetric.com data in Scopus database from 10.19% in 2011 to 20.46% in 2015.
7	METHODS	A zero-truncated negative binomial model is implemented to measure the extent to which different bibliometric and altmetric factors contribute to citation counts.
8	RESULTS	Blog count appears to be the most important factor increasing the number of citations by 38.6% in the field of Health Professions and Nursing, followed by Twitter count increasing the number of citations by 8% in the field of Physics and Astronomy.
9	RESULTS	Interestingly, both Blog count and Twitter count always show positive increase in the number of citations across all fields.
10	RESULTS	While there was a positive weak correlation between bibliometric and altmetric indices, the results show that altmetric indices can be a good indicator to discriminate highly cited publications, with an encouragingly AUC= 0.725 between highly cited publications and total altmetric count.
11	CONCLUSIONS	Overall, findings suggest that altmetrics could better distinguish highly cited publications.
1	BACKGROUND	Networks are representations of complex underlying social processes.
2	BACKGROUND	However, the same given network may be more suitable to model one behavior of individuals than another.
3	BACKGROUND	In many cases, aggregate population models may be more effective than modeling on the network.
4	RESULTS	We present a general framework for evaluating the suitability of given networks for a set of predictive tasks of interest, compared against alternative, networks inferred from data.
5	RESULTS	We present several interpretable network models and measures for our comparison.
6	OBJECTIVE	We apply this general framework to the case study on collective classification of music preferences in a newly available dataset of the Last.fm social network.
1	BACKGROUND	Sentiment analysis is the Natural Language Processing (NLP) task dealing with the detection and classification of sentiments in texts.
2	BACKGROUND	While some tasks deal with identifying the presence of sentiment in the text (Subjectivity analysis), other tasks aim at determining the polarity of the text categorizing them as positive, negative and neutral.
3	BACKGROUND	Whenever there is a presence of sentiment in the text, it has a source (people, group of people or any entity) and the sentiment is directed towards some entity, object, event or person.
4	BACKGROUND	Sentiment analysis tasks aim to determine the subject, the target and the polarity or valence of the sentiment.
5	OBJECTIVE	In our work, we try to automatically extract sentiment (positive or negative) from Facebook posts using a machine learning approach.
6	METHODS	While some works have been done in code-mixed social media data and in sentiment analysis separately, our work is the first attempt (as of now) which aims at performing sentiment analysis of code-mixed social media text.
7	METHODS	We have used extensive pre-processing to remove noise from raw text.
8	METHODS	Multilayer Perceptron model has been used to determine the polarity of the sentiment.
9	METHODS	We have also developed the corpus for this task by manually labeling Facebook posts with their associated sentiments.
1	BACKGROUND	We highlight an important frontier in algorithmic fairness: disparity in the quality of natural language processing algorithms when applied to language from authors of different social groups.
2	BACKGROUND	For example, current systems sometimes analyze the language of females and minorities more poorly than they do of whites and males.
3	METHODS	We conduct an empirical analysis of racial disparity in language identification for tweets written in African-American English, and discuss implications of disparity in NLP.
1	METHODS	The concept named SocialStegDisc was introduced as an application of the original idea of StegHash method.
2	METHODS	This new kind of mass-storage was characterized by unlimited space.
3	METHODS	The design also attempted to improve the operation of StegHash by trade-off between memory requirements and computation time.
4	METHODS	Applying the mechanism of linked list provided the set of operations on files: creation, reading, deletion and modification.
5	METHODS	Features, limitations and opportunities were discussed.
1	BACKGROUND	Mobile devices are increasingly utilized to access social media and instant messaging services, which allow users to communicate with others easily and quickly.
2	BACKGROUND	However, the misuse of social media and instant messaging services facilitated conducting different cybercrimes such as cyber stalking, cyber bullying, slander spreading and sexual harassment.
3	BACKGROUND	Therefore, mobile devices are an important evidentiary piece in digital investigation.
4	RESULTS	In this chapter, we report the results of our investigation and analysis of social media and instant messaging services in Firefox OS.
5	RESULTS	We examined three social media services (Facebook, Twitter and Google+) as well as three instant messaging services (Telegram, OpenWapp and Line).
6	CONCLUSIONS	Our analysis may pave the way for future forensic investigators to trace and examine residual remnants of forensics value in FireFox OS.
1	OBJECTIVE	This paper introduces a novel deep learning framework including a lexicon-based approach for sentence-level prediction of sentiment label distribution.
2	METHODS	We propose to first apply semantic rules and then use a Deep Convolutional Neural Network (DeepCNN) for character-level embeddings in order to increase information for word-level embedding.
3	METHODS	After that, a Bidirectional Long Short-Term Memory Network (Bi-LSTM) produces a sentence-wide feature representation from the word-level embedding.
4	METHODS	We evaluate our approach on three Twitter sentiment classification datasets.
5	CONCLUSIONS	Experimental results show that our model can improve the classification accuracy of sentence-level sentiment analysis in Twitter social networking.
1	BACKGROUND	The problem of maximizing information diffusion, given a certain budget expressed in terms of the number of seed nodes, is an important topic in social networks research.
2	BACKGROUND	Existing literature focuses on single phase diffusion where all seed nodes are selected at the beginning of diffusion and all the selected nodes are activated simultaneously.
3	METHODS	This paper undertakes a detailed investigation of the effect of selecting and activating seed nodes in multiple phases.
4	METHODS	Specifically, we study diffusion in two phases assuming the well-studied independent cascade model.
5	METHODS	First, we formulate an objective function for two-phase diffusion, investigate its properties, and propose efficient algorithms for finding seed nodes in the two phases.
6	METHODS	Next, we study two associated problems: (1) budget splitting which seeks to optimally split the total budget between the two phases and (2) scheduling which seeks to determine an optimal delay after which to commence the second phase.
7	CONCLUSIONS	Our main conclusions include: (a) under strict temporal constraints, use single phase diffusion, (b) under moderate temporal constraints, use two-phase diffusion with a short delay while allocating most of the budget to the first phase, and (c) when there are no temporal constraints, use two-phase diffusion with a long delay while allocating roughly one-third of the budget to the first phase.
1	BACKGROUND	The rising attention to the spreading of fake news and unsubstantiated rumors on online social media and the pivotal role played by confirmation bias led researchers to investigate different aspects of the phenomenon.
2	BACKGROUND	Experimental evidence showed that confirmatory information gets accepted even if containing deliberately false claims while dissenting information is mainly ignored or might even increase group polarization.
3	BACKGROUND	It seems reasonable that, to address misinformation problem properly, we have to understand the main determinants behind content consumption and the emergence of narratives on online social media.
4	OBJECTIVE	In this paper we address such a challenge by focusing on the discussion around the Italian Constitutional Referendum by conducting a quantitative, cross-platform analysis on both Facebook public pages and Twitter accounts.
5	METHODS	We observe the spontaneous emergence of well-separated communities on both platforms.
6	METHODS	Such a segregation is completely spontaneous, since no categorization of contents was performed a priori.
7	METHODS	By exploring the dynamics behind the discussion, we find that users tend to restrict their attention to a specific set of Facebook pages/Twitter accounts.
8	METHODS	Finally, taking advantage of automatic topic extraction and sentiment analysis techniques, we are able to identify the most controversial topics inside and across both platforms.
9	RESULTS	We measure the distance between how a certain topic is presented in the posts/tweets and the related emotional response of users.
10	RESULTS	Our results provide interesting insights for the understanding of the evolution of the core narratives behind different echo chambers and for the early detection of massive viral phenomena around false claims.
1	BACKGROUND	The digital traces we leave behind when engaging with the modern world offer an interesting lens through which we study behavioral patterns as expression of gender.
2	BACKGROUND	Although gender differentiation has been observed in a number of settings, the majority of studies focus on a single data stream in isolation.
3	OBJECTIVE	Here we use a dataset of high resolution data collected using mobile phones, as well as detailed questionnaires, to study gender differences in a large cohort.
4	METHODS	We consider mobility behavior and individual personality traits among a group of more than $800$ university students.
5	METHODS	We also investigate interactions among them expressed via person-to-person contacts, interactions on online social networks, and telecommunication.
6	METHODS	Thus, we are able to study the differences between male and female behavior captured through a multitude of channels for a single cohort.
7	RESULTS	We find that while the two genders are similar in a number of aspects, there are robust deviations that include multiple facets of social interactions, suggesting the existence of inherent behavioral differences.
8	METHODS	Finally, we quantify how aspects of an individual's characteristics and social behavior reveals their gender by posing it as a classification problem.
9	OBJECTIVE	We ask: How well can we distinguish between male and female study participants based on behavior alone?
10	OBJECTIVE	Which behavioral features are most predictive?
1	BACKGROUND	In the last years researchers in the field of intelligent transportation systems have made several efforts to extract valuable information from social media streams.
2	BACKGROUND	However, collecting domain-specific data from any social media is a challenging task demanding appropriate and robust classification methods.
3	OBJECTIVE	In this work we focus on exploring geo-located tweets in order to create a travel-related tweet classifier using a combination of bag-of-words and word embeddings.
4	RESULTS	The resulting classification makes possible the identification of interesting spatio-temporal relations in S\~ao Paulo and Rio de Janeiro.
1	BACKGROUND	The vast penetration of smart mobile devices provides a unique opportunity to make mobile social networking pervasive by leveraging the feature of short-range wireless communication technologies (e.g.
2	BACKGROUND	WiFi Direct).
3	BACKGROUND	In this paper, we study local content dissemination in WiFi-Direct-based mobile social networks (MSNs).
4	BACKGROUND	We propose a simple GO-coordinated dissemination strategy, as WiFi Direct does not originally support content dissemination.
5	BACKGROUND	Due to mobility and the short transmission range, the duration of nodes in contact tends to be limited and consequently they compete for the limited airtime to disseminate their own data.
6	BACKGROUND	Therefore, fair allocation of the limited airtime among the nodes is required.
7	BACKGROUND	We focus on fairness in content dissemination rate, which is a key application-layer metric, rather than fairness in throughput or airtime and formulate the allocation problem as a generalized Nash bargaining game wherein the nodes bargain for a share of the limited airtime.
8	BACKGROUND	The game is proved to have a unique optimal solution, and an algorithm with low complexity is designed to find the optimal solution.
9	BACKGROUND	Furthermore, we propose a detailed scheduling approach to implement the optimal solution.
10	BACKGROUND	We also present numerical results to evaluate the Nash bargaining based allocation and scheduling.
1	BACKGROUND	Many people use social media to seek information during disasters while lacking access to traditional information sources.
2	OBJECTIVE	In this study, we analyze Twitter data to understand information spreading activities of social media users during hurricane Sandy.
3	OBJECTIVE	We create multiple subgraphs of Twitter users based on activity levels and analyze network properties of the subgraphs.
4	RESULTS	We observe that user information sharing activity follows a power-law distribution suggesting the existence of few highly active nodes in disseminating information and many other nodes being less active.
5	RESULTS	We also observe close enough connected components and isolates at all levels of activity, and networks become less transitive, but more assortative for larger subgraphs.
6	RESULTS	We also analyze the association between user activities and characteristics that may influence user behavior to spread information during a crisis.
7	CONCLUSIONS	Users become more active in spreading information if they are centrally placed in the network, less eccentric, and have higher degrees.
8	CONCLUSIONS	Our analysis provides insights on how to exploit user characteristics and network properties to spread information or limit the spreading of misinformation during a crisis event.
1	BACKGROUND	Recent studies suggest that human emotions diffuse in not only real-world communities but also online social media.
2	BACKGROUND	More and more mechanisms beyond emotion contagion are revealed, including emotion correlations which indicate their influence and the coupling of emotion diffusion and network structure such as tie strength.
3	BACKGROUND	Besides, different emotions might even compete in shaping the public opinion.
4	BACKGROUND	However, a comprehensive model that considers up-to-date findings to replicate the patterns of emotion contagion in online social media is still missing.
5	OBJECTIVE	In this paper, to bridge this vital gap, we propose an agent-based emotion contagion model which combines features of emotion influence and tie strength preference in the dissemination process.
6	RESULTS	The simulation results indicate that anger-dominated users have higher vitality than joy-dominated ones, and anger prefers weaker ties than joy in diffusion, which could make it easier to spread between online groups.
7	CONCLUSIONS	Moreover, anger's high influence makes it competitive and easily to dominate the community, especially when negative public events occur.
8	RESULTS	It is also surprisingly revealed that as the ratio of anger approaches joy with a gap less than 10%, angry tweets and users will eventually dominate the online social media and arrives the collective outrage in the cyber space.
9	CONCLUSIONS	The critical gap disclosed here can be indeed warning signals at early stages for outrage controlling in online social media.
10	CONCLUSIONS	All the parameters of the presented model can be easily estimated from the empirical observations and their values from historical data could help reproduce the emotion contagion of different circumstances.
11	CONCLUSIONS	Our model would shed lights on the study of multiple issues like forecasting of emotion contagion in terms of computer simulations.
1	RESULTS	We describe the results of a qualitative study on journalists' information seeking behavior on social media.
2	CONCLUSIONS	Based on interviews with eleven journalists along with a study of a set of university level journalism modules, we determined the categories of information need types that lead journalists to social media.
3	CONCLUSIONS	We also determined the ways that social media is exploited as a tool to satisfy information needs and to define influential factors, which impacted on journalists' information seeking behavior.
4	RESULTS	We find that not only is social media used as an information source, but it can also be a supplier of stories found serendipitously.
5	RESULTS	We find seven information need types that expand the types found in previous work.
6	RESULTS	We also find five categories of influential factors that affect the way journalists seek information.
1	BACKGROUND	An increasing number of social network mental disorders (SNMDs), such as Cyber-Relationship Addiction, Information Overload, and Net Compulsion, have been recently noted.
2	BACKGROUND	Symptoms of these mental disorders are usually observed passively today, resulting in delayed clinical intervention.
3	OBJECTIVE	In this paper, we argue that mining online social behavior provides an opportunity to actively identify SNMDs at an early stage.
4	BACKGROUND	It is challenging to detect SNMDs because the mental factors considered in standard diagnostic criteria (questionnaire) cannot be observed from online social activity logs.
5	METHODS	Our approach, new and innovative to the practice of SNMD detection, does not rely on self-revealing of those mental factors via questionnaires.
6	OBJECTIVE	Instead, we propose a machine learning framework, namely, Social Network Mental Disorder Detection (SNMDD), that exploits features extracted from social network data to accurately identify potential cases of SNMDs.
7	OBJECTIVE	We also exploit multi-source learning in SNMDD and propose a new SNMD-based Tensor Model (STM) to improve the performance.
8	METHODS	Our framework is evaluated via a user study with 3126 online social network users.
9	METHODS	We conduct a feature analysis, and also apply SNMDD on large-scale datasets and analyze the characteristics of the three SNMD types.
10	RESULTS	The results show that SNMDD is promising for identifying online social network users with potential SNMDs.
1	BACKGROUND	Researchers have attempted to model information diffusion and topic trends and lifecycle on online social networks.
2	BACKGROUND	They have investigated the role of content, social connections and communities, familiarity and behavioral similarity in this context.
3	OBJECTIVE	The current article presents a survey of representative models that perform topic analysis, capture information diffusion, and explore the properties of social connections in the context of online social networks.
4	CONCLUSIONS	The article concludes with a set of outlines of open problems and possible directions of future research interest.
5	OBJECTIVE	This article is intended for researchers to identify the current literature, and explore possibilities to improve the art.
1	BACKGROUND	Social media information distributes in different Online Social Networks (OSNs).
2	OBJECTIVE	This paper addresses the problem integrating the cross-OSN information to facilitate an immersive social media search experience.
3	OBJECTIVE	We exploit hashtag, which is widely used to annotate and organize multi-modal items in different OSNs, as the bridge for information aggregation and organization.
4	RESULTS	A three-stage solution framework is proposed for hashtag representation, clustering and demonstration.
5	RESULTS	Given an event query, the related items from three OSNs, Twitter, Flickr and YouTube, are organized in cluster-hashtag-item hierarchy for display.
6	CONCLUSIONS	The effectiveness of the proposed solution is validated by qualitative and quantitative experiments on hundreds of trending event queries.
1	OBJECTIVE	In this paper, we demonstrate how the state-of-the-art machine learning and text mining techniques can be used to build effective social media-based substance use detection systems.
2	METHODS	Since a substance use ground truth is difficult to obtain on a large scale, to maximize system performance, we explore different feature learning methods to take advantage of a large amount of unsupervised social media data.
3	METHODS	"We also demonstrate the benefit of using multi-view unsupervised feature learning to combine heterogeneous user information such as Facebook `""likes"" and ""status updates"" to enhance system performance."
4	RESULTS	Based on our evaluation, our best models achieved 86% AUC for predicting tobacco use, 81% for alcohol use and 84% for drug use, all of which significantly outperformed existing methods.
5	CONCLUSIONS	Our investigation has also uncovered interesting relations between a user's social media behavior (e.g., word usage) and substance use.
1	BACKGROUND	The recently proposed DeGroot-Friedkin model describes the dynamical evolution of individual social power in a social network that holds opinion discussions on a sequence of different issues.
2	OBJECTIVE	This paper revisits that model, and uses nonlinear contraction analysis, among other tools, to establish several novel results.
3	RESULTS	First, we show that for a social network with constant topology, each individual's social power converges to its equilibrium value exponentially fast, whereas previous results only concluded asymptotic convergence.
4	RESULTS	Second, when the network topology is dynamic (i.e., the relative interaction matrix may change between any two successive issues), we show that each individual exponentially forgets its initial social power.
5	BACKGROUND	Specifically, individual social power is dependent only on the dynamic network topology, and initial (or perceived) social power is forgotten as a result of sequential opinion discussion.
6	RESULTS	Last, we provide an explicit upper bound on an individual's social power as the number of issues discussed tends to infinity; this bound depends only on the network topology.
7	RESULTS	Simulations are provided to illustrate our results.
1	BACKGROUND	Social media platforms contain a great wealth of information which provides opportunities for us to explore hidden patterns or unknown correlations, and understand people's satisfaction with what they are discussing.
2	OBJECTIVE	As one showcase, in this paper, we present a system, TwiInsight which explores the insight of Twitter data.
3	OBJECTIVE	Different from other Twitter analysis systems, TwiInsight automatically extracts the popular topics under different categories (e.g., healthcare, food, technology, sports and transport) discussed in Twitter via topic modeling and also identifies the correlated topics across different categories.
4	OBJECTIVE	Additionally, it also discovers the people's opinions on the tweets and topics via the sentiment analysis.
5	RESULTS	The system also employs an intuitive and informative visualization to show the uncovered insight.
6	OBJECTIVE	Furthermore, we also develop and compare six most popular algorithms - three for sentiment analysis and three for topic modeling.
1	BACKGROUND	Over the past century, personality theory and research has successfully identified core sets of characteristics that consistently describe and explain fundamental differences in the way people think, feel and behave.
2	BACKGROUND	Such characteristics were derived through theory, dictionary analyses, and survey research using explicit self-reports.
3	BACKGROUND	The availability of social media data spanning millions of users now makes it possible to automatically derive characteristics from language use -- at large scale.
4	OBJECTIVE	Taking advantage of linguistic information available through Facebook, we study the process of inferring a new set of potential human traits based on unprompted language use.
5	METHODS	We subject these new traits to a comprehensive set of evaluations and compare them with a popular five factor model of personality.
6	RESULTS	We find that our language-based trait construct is often more generalizable in that it often predicts non-questionnaire-based outcomes better than questionnaire-based traits (e.g. entities someone likes, income and intelligence quotient), while the factors remain nearly as stable as traditional factors.
7	CONCLUSIONS	Our approach suggests a value in new constructs of personality derived from everyday human language use.
1	OBJECTIVE	In this paper, we formalize the notion of distributed sensitive social networks (DSSNs), which encompasses networks like enmity networks, financial transaction networks, supply chain networks and sexual relationship networks.
2	METHODS	Compared to the well studied traditional social networks, DSSNs are often more challenging to study, given the privacy concerns of the individuals on whom the network is knit.
3	OBJECTIVE	In the current work, we envision the use of secure multiparty tools and techniques for performing privacy preserving social network analysis over DSSNs.
4	METHODS	As a step towards realizing this, we design efficient data-oblivious algorithms for computing the K-shell decomposition and the PageRank centrality measure for a given DSSN.
5	RESULTS	The designed data-oblivious algorithms can be translated into equivalent secure computation protocols.
6	CONCLUSIONS	We also list a string of challenges that are needed to be addressed, for employing secure computation protocols as a practical solution for studying DSSNs.
1	BACKGROUND	Polarization is a troubling phenomenon that can lead to societal divisions and hurt the democratic process.
2	BACKGROUND	It is therefore important to develop methods to reduce it.
3	OBJECTIVE	We propose an algorithmic solution to the problem of reducing polarization.
4	OBJECTIVE	The core idea is to expose users to content that challenges their point of view, with the hope broadening their perspective, and thus reduce their polarity.
5	METHODS	Our method takes into account several aspects of the problem, such as the estimated polarity of the user, the probability of accepting the recommendation, the polarity of the content, and popularity of the content being recommended.
6	METHODS	We evaluate our recommendations via a large-scale user study on Twitter users that were actively involved in the discussion of the US elections results.
7	RESULTS	Results shows that, in most cases, the factors taken into account in the recommendation affect the users as expected, and thus capture the essential features of the problem.
1	OBJECTIVE	We study the evolution of long-lived controversial debates as manifested on Twitter from 2011 to 2016.
2	METHODS	Specifically, we explore how the structure of interactions and content of discussion varies with the level of collective attention, as evidenced by the number of users discussing a topic.
3	RESULTS	Spikes in the volume of users typically correspond to external events that increase the public attention on the topic -- as, for instance, discussions about `gun control' often erupt after a mass shooting.
4	RESULTS	This work is the first to study the dynamic evolution of polarized online debates at such scale.
5	RESULTS	By employing a wide array of network and content analysis measures, we find consistent evidence that increased collective attention is associated with increased network polarization and network concentration within each side of the debate; and overall more uniform lexicon usage across all users.
1	BACKGROUND	Corporations spend millions of dollars on developing creative image-based promotional content to advertise to their user-base on platforms like Twitter.
2	OBJECTIVE	Our paper is an initial study, where we propose a novel method to evaluate and improve outreach of promotional images from corporations on Twitter, based purely on their describable aesthetic attributes.
3	METHODS	Existing works in aesthetic based image analysis exclusively focus on the attributes of digital photographs, and are not applicable to advertisements due to the influences of inherent content and context based biases on outreach.
4	OBJECTIVE	Our paper identifies broad categories of biases affecting such images, describes a method for normalization to eliminate effects of those biases and score images based on their outreach, and examines the effects of certain handcrafted describable aesthetic features on image outreach.
5	RESULTS	Optimizing on the describable aesthetic features resulting from this research is a simple method for corporations to complement their existing marketing strategy to gain significant improvement in user engagement on social media for promotional images.
1	BACKGROUND	A concept of fourth generation social network is described as one that, built on the features of augmented reality (AR), is able to implement an enriched layer of digital information that displays in People Augmented Reality (PAR) devices data shared by users in social networks.
2	BACKGROUND	This PAR layer is accessed by the users in their devices through camera effects when targeting with a mobile phone to a user holding a mobile device with AGPS and with a profile in social media.
3	BACKGROUND	The social network of fourth generation will be a combination between Facebook and Pokemon Go.
1	BACKGROUND	Social networks are typical attributed networks with node attributes.
2	BACKGROUND	Different from traditional attribute community detection problem aiming at obtaining the whole set of communities in the network, we study an application-oriented problem of mining an application-aware community organization with respect to specific concerned attributes.
3	BACKGROUND	The concerned attributes are designated based on the requirements of any application by a user in advance.
4	BACKGROUND	The application-aware community organization w.r.t. concerned attributes consists of the communities with feature subspaces containing these concerned attributes.
5	BACKGROUND	Besides concerned attributes, feature subspace of each required community may contain some other relevant attributes.
6	BACKGROUND	All relevant attributes of a feature subspace jointly describe and determine the community embedded in such subspace.
7	BACKGROUND	Thus the problem includes two subproblems, i.e., how to expand the set of concerned attributes to complete feature subspaces and how to mine the communities embedded in the expanded subspaces.
8	BACKGROUND	Two subproblems are jointly solved by optimizing a quality function called subspace fitness.
9	OBJECTIVE	An algorithm called ACM is proposed.
10	METHODS	In order to locate the communities potentially belonging to the application-aware community organization, cohesive parts of a network backbone composed of nodes with similar concerned attributes are detected and set as the community seeds.
11	METHODS	The set of concerned attributes is set as the initial subspace for all community seeds.
12	METHODS	Then each community seed and its attribute subspace are adjusted iteratively to optimize the subspace fitness.
13	METHODS	Extensive experiments on synthetic datasets demonstrate the effectiveness and efficiency of our method and applications on real-world networks show its application values.
1	OBJECTIVE	Different measures have been proposed to predict whether individuals will adopt a new behavior in online social networks, given the influence produced by their neighbors.
2	RESULTS	In this paper, we show one can achieve significant improvement over these standard measures, extending them to consider a pair of time constraints.
3	CONCLUSIONS	These constraints provide a better proxy for social influence, showing a stronger correlation to the probability of influence as well as the ability to predict influence.
1	BACKGROUND	Mental illnesses adversely affect a significant proportion of the population worldwide.
2	BACKGROUND	However, the methods traditionally used for estimating and characterizing the prevalence of mental health conditions are time-consuming and expensive.
3	BACKGROUND	Consequently, best-available estimates concerning the prevalence of mental health conditions are often years out of date.
4	BACKGROUND	Automated approaches to supplement these survey methods with broad, aggregated information derived from social media content provides a potential means for near real-time estimates at scale.
5	BACKGROUND	These may, in turn, provide grist for supporting, evaluating and iteratively improving upon public health programs and interventions.
6	OBJECTIVE	We propose a novel model for automated mental health status quantification that incorporates user embeddings.
7	BACKGROUND	This builds upon recent work exploring representation learning methods that induce embeddings by leveraging social media post histories.
8	BACKGROUND	Such embeddings capture latent characteristics of individuals (e.g., political leanings) and encode a soft notion of homophily.
9	OBJECTIVE	In this paper, we investigate whether user embeddings learned from twitter post histories encode information that correlates with mental health statuses.
10	METHODS	To this end, we estimated user embeddings for a set of users known to be affected by depression and post-traumatic stress disorder (PTSD), and for a set of demographically matched `control' users.
11	METHODS	We then evaluated these embeddings with respect to: (i) their ability to capture homophilic relations with respect to mental health status; and (ii) the performance of downstream mental health prediction models based on these features.
12	RESULTS	Our experimental results demonstrate that the user embeddings capture similarities between users with respect to mental conditions, and are predictive of mental health.
1	BACKGROUND	In recent years, there have been efforts to collect human contact traces during social events (e.g., conferences) using Bluetooth devices (e.g., mobile phones, iMotes).
2	BACKGROUND	The results of these studies have enabled the ability to do the crowd-sourcing task from within the crowd, in order to answer questions, such as: what is the current density of the crowd, or how many people are attending the event?
3	BACKGROUND	However, in those studies, the sensing devices are usually distributed and configured in a certain manner.
4	BACKGROUND	For example, the number of devices is fixed, people register for the devices on a volunteering basis.
5	OBJECTIVE	In this paper, we treat the above problem as an optimization problem and draw the connection to the vertex cover problem in graph theory.
6	METHODS	Since finding the optimal solution for minimum vertex cover problem is NP-complete, approximation algorithms have to be used.
7	CONCLUSIONS	However, we will show that the well-known approximation algorithms do not perform well with the crowd-sensing task.
8	OBJECTIVE	In this paper, we propose the notions of node observability and coverage utility score and design a new context-aware approximation algorithm to find vertex cover that is tailored for crowd-sensing task.
9	OBJECTIVE	In addition, we design human-centric bootstrapping strategies to make initial assignment of sensing devices based on meta information about the participants (e.g., interests, friendship).
10	OBJECTIVE	"The motivation is to assign the sensing task to a more ""socialized"" device to obtain better sensing coverage."
11	METHODS	We perform comprehensive experiments on real-world data traces obtained from previous experimental studies in conference and academic social context.
12	RESULTS	The results show that our proposed approach significantly outperforms the baseline approximation algorithms in terms of sensing coverage.
1	BACKGROUND	In many systems privacy of users depends on the number of participants applying collectively some method to protect their security.
2	BACKGROUND	Indeed, there are numerous already classic results about revealing aggregated data from a set of users.
3	BACKGROUND	"The conclusion is usually as follows: if you have enough friends to ""aggregate"" the private data, you can safely reveal your private information."
4	BACKGROUND	Apart from data aggregation, it has been noticed that in a wider context privacy can be often reduced to being hidden in a crowd.
5	BACKGROUND	Generally, the problems is how to create such crowd.
6	BACKGROUND	"This task may be not easy in some distributed systems, wherein gathering enough ""individuals"" is hard for practical reasons."
7	BACKGROUND	Such example are social networks (or similar systems), where users have only a limited number of semi trusted contacts and their aim is to reveal some aggregated data in a privacy preserving manner.
8	BACKGROUND	This may be particularly problematic in the presence of a strong adversary that can additionally corrupt some users.
9	OBJECTIVE	We show two methods that allow to significantly amplify privacy with only limited number of local operations and very moderate communication overhead.
10	METHODS	Except theoretical analysis we show experimental results on topologies of real-life social networks to demonstrate that our methods can significantly amplify privacy of chosen aggregation protocols even facing a massive attack of a powerful adversary.
11	CONCLUSIONS	We believe however that our results can have much wider applications for improving security of systems based on locally trusted relations.
1	BACKGROUND	Sleep condition is closely related to an individual's health.
2	BACKGROUND	Poor sleep conditions such as sleep disorder and sleep deprivation affect one's daily performance, and may also cause many chronic diseases.
3	BACKGROUND	Many efforts have been devoted to monitoring people's sleep conditions.
4	BACKGROUND	However, traditional methodologies require sophisticated equipment and consume a significant amount of time.
5	OBJECTIVE	In this paper, we attempt to develop a novel way to predict individual's sleep condition via scrutinizing facial cues as doctors would.
6	METHODS	Rather than measuring the sleep condition directly, we measure the sleep-deprived fatigue which indirectly reflects the sleep condition.
7	METHODS	Our method can predict a sleep-deprived fatigue rate based on a selfie provided by a subject.
8	METHODS	This rate is used to indicate the sleep condition.
9	METHODS	To gain deeper insights of human sleep conditions, we collected around 100,000 faces from selfies posted on Twitter and Instagram, and identified their age, gender, and race using automatic algorithms.
10	METHODS	Next, we investigated the sleep condition distributions with respect to age, gender, and race.
11	RESULTS	Our study suggests among the age groups, fatigue percentage of the 0-20 youth and adolescent group is the highest, implying that poor sleep condition is more prevalent in this age group.
12	CONCLUSIONS	For gender, the fatigue percentage of females is higher than that of males, implying that more females are suffering from sleep issues than males.
13	RESULTS	Among ethnic groups, the fatigue percentage in Caucasian is the highest followed by Asian and African American.
1	BACKGROUND	Traces of user activities recorded in online social networks such as the creation, viewing and forwarding/sharing of information over time open new possibilities to quantitatively and systematically understand the information diffusion process on social networks.
2	BACKGROUND	From an online social network like WeChat, we could collect a large number of information cascade trees, each of which tells the spreading trajectory of a message/information such as which user creates the information and which users view or forward the information shared by which neighbors.
3	OBJECTIVE	In this work, we propose two heterogeneous non-linear models.
4	METHODS	Both models are validated by the WeChat data in reproducing and explaining key features of cascade trees.
5	METHODS	Specifically, we firstly apply the Random Recursive Tree (RRT) to model the cascade tree topologies, capturing key features, i.e. the average path length and degree variance of a cascade tree in relation to the number of nodes (size) of the tree.
6	METHODS	The RRT model with a single parameter $\theta$ describes the growth mechanism of a tree, where a node in the existing tree has a probability $d_i^{\theta}$ of being connected to a newly added node that depends on the degree $d_i$ of the existing node.
7	METHODS	The identified parameter $\theta$ quantifies the relative depth or broadness of the cascade trees, indicating that information propagates via a star-like broadcasting or viral-like hop by hop spreading.
8	RESULTS	The RRT model explains the appearance of hubs, thus a possibly smaller average path length as the cascade size increases, as observed in WeChat.
9	OBJECTIVE	We further propose the stochastic Susceptible View Forward Removed (SVFR) model to depict the dynamic user behaviors including creating, viewing, forwarding and ignoring a message on a given social network.
1	BACKGROUND	An-ever increasing number of social media websites, electronic newspapers and Internet forums allow visitors to leave comments for others to read and interact.
2	BACKGROUND	This exchange is not free from participants with malicious intentions, which do not contribute with the written conversation.
3	BACKGROUND	Among different communities users adopt strategies to handle such users.
4	OBJECTIVE	In this paper we present a comprehensive categorization of the trolling phenomena resource, inspired by politeness research and propose a model that jointly predicts four crucial aspects of trolling: intention, interpretation, intention disclosure and response strategy.
5	RESULTS	Finally, we present a new annotated dataset containing excerpts of conversations involving trolls and the interactions with other users that we hope will be a useful resource for the research community.
1	OBJECTIVE	The paper addresses a method for spreading messages in social networks through an initial acceleration by Spreading Groups.
2	BACKGROUND	These groups start the spread which eventually reaches a larger portion of the network.
3	BACKGROUND	The use of spreading groups creates a final flow which resembles the spread through the nodes with the highest level of influence (opinion leaders).
4	BACKGROUND	While harnessing opinion leaders to spread messages is generally costly, the formation of spreading groups is merely a technical issue, and can be done by computerized bots.
5	METHODS	The paper presents an information flow model and inspects the model through a dataset of Nasdaq-related tweets.
1	BACKGROUND	Over the past decade, online social networks (OSNs) such as Twitter and Facebook have thrived and experienced rapid growth to over 1 billion users.
2	CONCLUSIONS	A major evolution would be to leverage the characteristics of OSNs to evaluate the effectiveness of the many routing schemes developed by the research community in real-world scenarios.
3	OBJECTIVE	In this paper, we showcase the Secure Opportunistic Schemes (SOS) middleware which allows different routing schemes to be easily implemented relieving the burden of security and connection establishment.
4	CONCLUSIONS	The feasibility of creating a delay tolerant social network is demonstrated by using SOS to power AlleyOop Social, a secure delay tolerant networking research platform that serves as a real-life mobile social networking application for iOS devices.
5	CONCLUSIONS	SOS and AlleyOop Social allow users to interact, publish messages, and discover others that share common interests in an intermittent network using Bluetooth, peer-to-peer WiFi, and infrastructure WiFi.
1	BACKGROUND	With the widespread adoption of social media sites like Twitter and Facebook, there has been a shift in the way information is produced and consumed.
2	BACKGROUND	Earlier, the only producers of information were traditional news organizations, which broadcast the same carefully-edited information to all consumers over mass media channels.
3	BACKGROUND	Whereas, now, in online social media, any user can be a producer of information, and every user selects which other users she connects to, thereby choosing the information she consumes.
4	BACKGROUND	Moreover, the personalized recommendations that most social media sites provide also contribute towards the information consumed by individual users.
5	OBJECTIVE	In this work, we define a concept of information diet -- which is the topical distribution of a given set of information items (e.g., tweets) -- to characterize the information produced and consumed by various types of users in the popular Twitter social media.
6	RESULTS	At a high level, we find that (i) popular users mostly produce very specialized diets focusing on only a few topics; in fact, news organizations (e.g., NYTimes) produce much more focused diets on social media as compared to their mass media diets, (ii) most users' consumption diets are primarily focused towards one or two topics of their interest, and (iii) the personalized recommendations provided by Twitter help to mitigate some of the topical imbalances in the users' consumption diets, by adding information on diverse topics apart from the users' primary topics of interest.
1	BACKGROUND	Search systems in online social media sites are frequently used to find information about ongoing events and people.
2	BACKGROUND	For topics with multiple competing perspectives, such as political events or political candidates, bias in the top ranked results significantly shapes public opinion.
3	BACKGROUND	However, bias does not emerge from an algorithm alone.
4	BACKGROUND	It is important to distinguish between the bias that arises from the data that serves as the input to the ranking system and the bias that arises from the ranking system itself.
5	OBJECTIVE	In this paper, we propose a framework to quantify these distinct biases and apply this framework to politics-related queries on Twitter.
6	RESULTS	We found that both the input data and the ranking system contribute significantly to produce varying amounts of bias in the search results and in different ways.
7	OBJECTIVE	We discuss the consequences of these biases and possible mechanisms to signal this bias in social media search systems' interfaces.
1	BACKGROUND	Named entity recognition, and other information extraction tasks, frequently use linguistic features such as part of speech tags or chunkings.
2	BACKGROUND	For languages where word boundaries are not readily identified in text, word segmentation is a key first step to generating features for an NER system.
3	BACKGROUND	While using word boundary tags as features are helpful, the signals that aid in identifying these boundaries may provide richer information for an NER system.
4	BACKGROUND	New state-of-the-art word segmentation systems use neural models to learn representations for predicting word boundaries.
5	RESULTS	We show that these same representations, jointly trained with an NER system, yield significant improvements in NER for Chinese social media.
6	RESULTS	In our experiments, jointly training NER and word segmentation with an LSTM-CRF model yields nearly 5% absolute improvement over previously published results.
1	BACKGROUND	Over the past decade, online social networks (OSNs) such as Twitter and Facebook have thrived and experienced rapid growth to over 1 billion users.
2	BACKGROUND	A major evolution would be to leverage the characteristics of OSNs to evaluate the effectiveness of the many routing schemes developed by the research community in real-world scenarios.
3	OBJECTIVE	In this demo, we showcase AlleyOop Social, a secure delay tolerant networking research platform that serves as a real-life mobile social networking application for iOS devices.
4	RESULTS	AlleyOop Social allows users to interact, publish messages, and discover others that share common interests in an intermittent network using Bluetooth, peer-to-peer WiFi, and infrastructure WiFi.
5	RESULTS	The research platform serves as an overlay application for the Secure Opportunistic Schemes (SOS) middleware which allows different routing schemes to be easily implemented relieving the burden of security and connection establishment.
1	BACKGROUND	It is known that individuals in social networks tend to exhibit homophily (a.k.a. assortative mixing) in their social ties, which implies that they prefer bonding with others of their own kind.
2	BACKGROUND	But what are the reasons for this phenomenon?
3	BACKGROUND	Is it that such relations are more convenient and easier to maintain?
4	BACKGROUND	Or are there also some more tangible benefits to be gained from this collective behaviour?
5	OBJECTIVE	The current work takes a game-theoretic perspective on this phenomenon, and studies the conditions under which different assortative mixing strategies lead to equilibrium in an evolving social network.
6	METHODS	We focus on a biased preferential attachment model where the strategy of each group (e.g., political or social minority) determines the level of bias of its members toward other group members and non-members.
7	RESULTS	Our first result is that if the utility function that the group attempts to maximize is the degree centrality of the group, interpreted as the sum of degrees of the group members in the network, then the only strategy achieving Nash equilibrium is a perfect homophily, which implies that cooperation with other groups is harmful to this utility function.
8	RESULTS	A second, and perhaps more surprising, result is that if a reward for inter-group cooperation is added to the utility function (e.g., externally enforced by an authority as a regulation), then there are only two possible equilibria, namely, perfect homophily or perfect heterophily, and it is possible to characterize their feasibility spaces.
9	RESULTS	Interestingly, these results hold regardless of the minority-majority ratio in the population.
10	CONCLUSIONS	We believe that these results, as well as the game-theoretic perspective presented herein, may contribute to a better understanding of the forces that shape the groups and communities of our society.
1	BACKGROUND	Centrality is an important notion in complex networks; it could be used to characterize how influential a node or an edge is in the network.
2	BACKGROUND	It plays an important role in several other network analysis tools including community detection.
3	BACKGROUND	Even though there are a small number of axiomatic frameworks associated with this notion, the existing formalizations are not generic in nature.
4	OBJECTIVE	In this paper we propose a generic axiomatic framework to capture all the intrinsic properties of a centrality measure (a.k.a. centrality index).
5	METHODS	We analyze popular centrality measures along with other novel measures of centrality using this framework.
6	RESULTS	We observed that none of the centrality measures considered satisfies all the axioms.
1	BACKGROUND	Social media expose millions of users every day to information campaigns --- some emerging organically from grassroots activity, others sustained by advertising or other coordinated efforts.
2	BACKGROUND	These campaigns contribute to the shaping of collective opinions.
3	BACKGROUND	While most information campaigns are benign, some may be deployed for nefarious purposes.
4	BACKGROUND	It is therefore important to be able to detect whether a meme is being artificially promoted at the very moment it becomes wildly popular.
5	BACKGROUND	This problem has important social implications and poses numerous technical challenges.
6	METHODS	As a first step, here we focus on discriminating between trending memes that are either organic or promoted by means of advertisement.
7	METHODS	The classification is not trivial: ads cause bursts of attention that can be easily mistaken for those of organic trends.
8	METHODS	We designed a machine learning framework to classify memes that have been labeled as trending on Twitter.
9	METHODS	After trending, we can rely on a large volume of activity data.
10	METHODS	Early detection, occurring immediately at trending time, is a more challenging problem due to the minimal volume of activity data that is available prior to trending.
11	METHODS	Our supervised learning framework exploits hundreds of time-varying features to capture changing network and diffusion patterns, content and sentiment information, timing signals, and user meta-data.
12	METHODS	We explore different methods for encoding feature time series.
13	METHODS	Using millions of tweets containing trending hashtags, we achieve 75% AUC score for early detection, increasing to above 95% after trending.
14	METHODS	We evaluate the robustness of the algorithms by introducing random temporal shifts on the trend time series.
15	RESULTS	Feature selection analysis reveals that content cues provide consistently useful signals; user features are more informative for early detection, while network and timing features are more helpful once more data is available.
1	OBJECTIVE	This paper investigates when users create profiles in different social networks, whether they are redundant expressions of the same persona, or they are adapted to each platform.
2	METHODS	Using the personal webpages of 116,998 users on About.me, we identify and extract matched user profiles on several major social networks including Facebook, Twitter, LinkedIn, and Instagram.
3	RESULTS	We find evidence for distinct site-specific norms, such as differences in the language used in the text of the profile self-description, and the kind of picture used as profile image.
4	RESULTS	By learning a model that robustly identifies the platform given a user's profile image (0.657--0.829 AUC) or self-description (0.608--0.847 AUC), we confirm that users do adapt their behaviour to individual platforms in an identifiable and learnable manner.
5	RESULTS	However, different genders and age groups adapt their behaviour differently from each other, and these differences are, in general, consistent across different platforms.
6	RESULTS	We show that differences in social profile construction correspond to differences in how formal or informal the platform is.
1	BACKGROUND	Language in social media is extremely dynamic: new words emerge, trend and disappear, while the meaning of existing words can fluctuate over time.
2	BACKGROUND	Such dynamics are especially notable during a period of crisis.
3	OBJECTIVE	This work addresses several important tasks of measuring, visualizing and predicting short term text representation shift, i.e. the change in a word's contextual semantics, and contrasting such shift with surface level word dynamics, or concept drift, observed in social media streams.
4	METHODS	Unlike previous approaches on learning word representations from text, we study the relationship between short-term concept drift and representation shift on a large social media corpus - VKontakte posts in Russian collected during the Russia-Ukraine crisis in 2014-2015.
5	METHODS	Our novel contributions include quantitative and qualitative approaches to (1) measure short-term representation shift and contrast it with surface level concept drift; (2) build predictive models to forecast short-term shifts in meaning from previous meaning as well as from concept drift; and (3) visualize short-term representation shift for example keywords to demonstrate the practical use of our approach to discover and track meaning of newly emerging terms in social media.
6	RESULTS	We show that short-term representation shift can be accurately predicted up to several weeks in advance.
7	CONCLUSIONS	Our unique approach to modeling and visualizing word representation shifts in social media can be used to explore and characterize specific aspects of the streaming corpus during crisis events and potentially improve other downstream classification tasks including real-time event detection.
1	BACKGROUND	"The friendship paradox states that in a social network, egos tend to have lower degree than their alters, or, ""your friends have more friends than you do""."
2	BACKGROUND	Most research has focused on the friendship paradox and its implications for information transmission, but treating the network as static and unweighted.
3	BACKGROUND	Yet, people can dedicate only a finite fraction of their attention budget to each social interaction: a high-degree individual may have less time to dedicate to individual social links, forcing them to modulate the quantities of contact made to their different social ties.
4	OBJECTIVE	Here we study the friendship paradox in the context of differing contact volumes between egos and alters, finding a connection between contact volume and the strength of the friendship paradox.
5	RESULTS	The most frequently contacted alters exhibit a less pronounced friendship paradox compared with the ego, whereas less-frequently contacted alters are more likely to be high degree and give rise to the paradox.
6	RESULTS	"We argue therefore for a more nuanced version of the friendship paradox: ""your closest friends have slightly more friends than you do"", and in certain networks even: ""your best friend has no more friends than you do""."
7	RESULTS	We demonstrate that this relationship is robust, holding in both a social media and a mobile phone dataset.
8	CONCLUSIONS	These results have implications for information transfer and influence in social networks, which we explore using a simple dynamical model.
1	BACKGROUND	Measuring centrality in a social network, especially in bipartite mode, poses several challenges such as requirement of full knowledge of the network topology and lack of properly detection of top-k behavioral representative users.
2	OBJECTIVE	In this paper, to overcome the aforementioned challenging issues, we propose an accurate centrality measure, called HellRank, to identify central nodes in bipartite social networks.
3	METHODS	HellRank is based on the Hellinger distance between two nodes on the same side of a bipartite network.
4	METHODS	We theoretically analyze the impact of the Hellinger distance on a bipartite network and find an upper and lower bounds for this distance.
5	METHODS	The computation of HellRank centrality measure can be distributed by letting each node uses only local information on its immediate neighbors and therefore do not need a central entity to have full knowledge of the network topological structure.
6	METHODS	We experimentally evaluate performance of the HellRank measure in correlation with other centrality measures on real-world networks.
7	RESULTS	The results show partial ranking similarity between the HellRank and the other conventional metrics according to the Kendall and Spearman rank correlation coefficient.
1	RESULTS	We explore how the polarization around controversial topics evolves on Twitter - over a long period of time (2011 to 2016), and also as a response to major external events that lead to increased related activity.
2	RESULTS	We find that increased activity is typically associated with increased polarization; however, we find no consistent long-term trend in polarization over time among the topics we study.
1	RESULTS	In this study we have investigated the relationship between different document characteristics and the number of Mendeley readership counts, tweets, Facebook posts, mentions in blogs and mainstream media for 1.3 million papers published in journals covered by the Web of Science (WoS).
2	OBJECTIVE	It aims to demonstrate that how factors affecting various social media-based indicators differ from those influencing citations and which document types are more popular across different platforms.
3	RESULTS	Our results highlight the heterogeneous nature of altmetrics, which encompasses different types of uses and user groups engaging with research on social media.
1	BACKGROUND	Social media has become an indispensable part of the everyday lives of millions of people around the world.
2	BACKGROUND	It provides a platform for expressing opinions and beliefs, communicated to a massive audience.
3	BACKGROUND	However, this ease with which people can express themselves has also allowed for the large scale spread of propaganda and hate speech.
4	BACKGROUND	To prevent violating the abuse policies of social media platforms and also to avoid detection by automatic systems like Google's Conversation AI, racists have begun to use a code (a movement termed Operation Google).
5	BACKGROUND	This involves substituting references to communities by benign words that seem out of context, in hate filled posts or Tweets.
6	BACKGROUND	For example, users have used the words Googles and Bings to represent the African-American and Asian communities, respectively.
7	BACKGROUND	By generating the list of users who post such content, we move a step forward from classifying tweets by allowing us to study the usage pattern of these concentrated set of users.
1	BACKGROUND	The risks of publishing privacy-sensitive data have received considerable attention recently.
2	BACKGROUND	Several de-anonymization attacks have been proposed to re-identify individuals even if data anonymization techniques were applied.
3	BACKGROUND	However, there is no theoretical quantification for relating the data utility that is preserved by the anonymization techniques and the data vulnerability against de-anonymization attacks.
4	OBJECTIVE	In this paper, we theoretically analyze the de-anonymization attacks and provide conditions on the utility of the anonymized data (denoted by anonymized utility) to achieve successful de-anonymization.
5	BACKGROUND	To the best of our knowledge, this is the first work on quantifying the relationships between anonymized utility and de-anonymization capability.
6	BACKGROUND	Unlike previous work, our quantification analysis requires no assumptions about the graph model, thus providing a general theoretical guide for developing practical de-anonymization/anonymization techniques.
7	METHODS	Furthermore, we evaluate state-of-the-art de-anonymization attacks on a real-world Facebook dataset to show the limitations of previous work.
8	METHODS	By comparing these experimental results and the theoretically achievable de-anonymization capability derived in our analysis, we further demonstrate the ineffectiveness of previous de-anonymization attacks and the potential of more powerful de-anonymization attacks in the future.
1	OBJECTIVE	The Wikipedia is a web portal created by users and its simplicity, references and also the inclusion as insets introductory paragraphs for their pages in Google search results have made it the go-to place to find out about current events or people featured in them.
2	BACKGROUND	Besides, its open application programming interface (API) allows any user to know about the number of visits some particular page has.
3	OBJECTIVE	In this paper, after certain events that made Copernicus a viral meme in Spain, we study the intensity and duration of the increment of visits to his page and other pages related to the event.
4	METHODS	Using pages related to other persons as a comparison, we try to establish a typical duration of notoriety achieved through social networks, mainly comparing with visits in previous years in the same dates.
5	CONCLUSIONS	We conclude that a 7 day duration is the statistical mode and that this duration is relatively independent of the initial increase in the number of visits.
1	BACKGROUND	The goal of cluster analysis in survival data is to identify clusters that are decidedly associated with the survival outcome.
2	BACKGROUND	Previous research has explored this problem primarily in the medical domain with relatively small datasets, but the need for such a clustering methodology could arise in other domains with large datasets, such as social networks.
3	OBJECTIVE	Concretely, we wish to identify different survival classes in a social network by clustering the users based on their lifespan in the network.
4	OBJECTIVE	In this paper, we propose a decision tree based algorithm that uses a global normalization of $p$-values to identify clusters with significantly different survival distributions.
5	RESULTS	We evaluate the clusters from our model with the help of a simple survival prediction task and show that our model outperforms other competing methods.
1	BACKGROUND	According to the DeGroot-Friedkin model of a social network, an individual's social power evolves as the network discusses individual opinions over a sequence of issues.
2	BACKGROUND	Under mild assumptions on the connectivity of the network, the social power of every individual converges to a constant strictly positive value as the number of issues discussed increases.
3	BACKGROUND	"If the network has a special topology, termed ""star topology"", then all social power accumulates with the individual at the centre of the star."
4	OBJECTIVE	This paper studies the strategic introduction of new individuals and/or interpersonal relationships into a social network with star topology to reduce the social power of the centre individual.
5	OBJECTIVE	In fact, several strategies are proposed.
6	METHODS	For each strategy, we derive necessary and sufficient conditions on the strength of the new interpersonal relationships, based on local information, which ensures that the centre individual no longer has the greatest social power within the social network.
7	CONCLUSIONS	Interpretations of these conditions show that the strategies are remarkably intuitive and that certain strategies are favourable compared to others, all of which is sociologically expected.
1	BACKGROUND	A person's weight status can have profound implications on their life, ranging from mental health, to longevity, to financial income.
2	BACKGROUND	"At the societal level, ""fat shaming"" and other forms of ""sizeism"" are a growing concern, while increasing obesity rates are linked to ever raising healthcare costs."
3	BACKGROUND	For these reasons, researchers from a variety of backgrounds are interested in studying obesity from all angles.
4	BACKGROUND	To obtain data, traditionally, a person would have to accurately self-report their body-mass index (BMI) or would have to see a doctor to have it measured.
5	OBJECTIVE	In this paper, we show how computer vision can be used to infer a person's BMI from social media images.
6	OBJECTIVE	We hope that our tool, which we release, helps to advance the study of social aspects related to body weight.
1	BACKGROUND	Signed networks have long been used to represent social relations of amity (+) and enmity (-) between individuals.
2	BACKGROUND	Group of individuals who are cyclically connected are said to be balanced if the number of negative edges in the cycle is even and unbalanced otherwise.
3	BACKGROUND	In its earliest and most natural formulation, the balance of a social network was thus defined from its simple cycles, cycles which do not visit any vertex more than once.
4	BACKGROUND	Because of the inherent difficulty associated with finding such cycles on very large networks, social balance has since then been studied via other means.
5	OBJECTIVE	In this article we present the balance as measured from the simple cycles and primitive orbits of social networks.
6	METHODS	We specifically provide two measures of balance: the proportion $R_\ell$ of negative simple cycles of length $\ell$ for each $\ell\leq 20$ which generalises the triangle index, and a ratio $K_\ell$ which extends the relative signed clustering coefficient introduced by Kunegis.
7	METHODS	To do so, we use a Monte Carlo implementation of a novel exact formula for counting the simple cycles on any weighted directed graph.
8	METHODS	Our method is free from the double-counting problem affecting previous cycle-based approaches, does not require edge-reciprocity of the underlying network, provides a gray-scale measure of balance for each cycle length separately and is sufficiently tractable that it can be implemented on a standard desktop computer.
9	RESULTS	We observe that social networks exhibit strong inter-edge correlations favouring balanced situations and we determine the corresponding correlation length $\xi$.
10	RESULTS	For longer simple cycles, $R_\ell$ undergoes a sharp transition to values expected from an uncorrelated model.
11	CONCLUSIONS	This transition is absent from synthetic random networks, strongly suggesting that it carries a sociological meaning warranting further research.
1	BACKGROUND	In Group Activity Selection Problem (GASP), players form coalitions to participate in activities and have preferences over pairs of the form (activity, group size).
2	BACKGROUND	Recently, Igarashi et al. have initiated the study of group activity selection problems on social networks (gGASP): a group of players can engage in the same activity if the members of the group form a connected subset of the underlying communication structure.
3	BACKGROUND	Igarashi et al. have primarily focused on Nash stable outcomes, and showed that many associated algorithmic questions are computationally hard even for very simple networks.
4	OBJECTIVE	In this paper we study the parameterized complexity of gGASP with respect to the number of activities as well as with respect to the number of players, for several solution concepts such as Nash stability, individual stability and core stability.
5	METHODS	The first parameter we consider in the number of activities.
6	METHODS	For this parameter, we propose an FPT algorithm for Nash stability for the case where the social network is acyclic and obtain a W[1]-hardness result for cliques (i.e., for classic GASP); similar results hold for individual stability.
7	METHODS	In contrast, finding a core stable outcome is hard even if the number of activities is bounded by a small constant, both for classic GASP and when the social network is a star.
8	RESULTS	Another parameter we study is the number of players.
9	RESULTS	While all solution concepts we consider become polynomial-time computable when this parameter is bounded by a constant, we prove W[1]-hardness results for cliques (i.e., for classic GASP).
1	BACKGROUND	Due to the proliferation of online social networks (OSNs), users find themselves participating in multiple OSNs.
2	CONCLUSIONS	These users leave their activity traces as they maintain friendships and interact with other users in these OSNs.
3	OBJECTIVE	In this work, we analyze how users maintain friendship in multiple OSNs by studying users who have accounts in both Twitter and Instagram.
4	OBJECTIVE	Specifically, we study the similarity of a user's friendship and the evenness of friendship distribution in multiple OSNs.
5	CONCLUSIONS	Our study shows that most users in Twitter and Instagram prefer to maintain different friendships in the two OSNs, keeping only a small clique of common friends in across the OSNs.
6	METHODS	Based upon our empirical study, we conduct link prediction experiments to predict missing friendship links in multiple OSNs using the neighborhood features, neighborhood friendship maintenance features and cross-link features.
7	RESULTS	Our link prediction experiments shows that un- supervised methods can yield good accuracy in predicting links in one OSN using another OSN data and the link prediction accuracy can be further improved using supervised method with friendship maintenance and others measures as features.
1	OBJECTIVE	In the problem of edge sign prediction, we are given a directed graph (representing a social network), and our task is to predict the binary labels of the edges (i.e., the positive or negative nature of the social relationships).
2	BACKGROUND	Many successful heuristics for this problem are based on the troll-trust features, estimating at each node the fraction of outgoing and incoming positive/negative edges.
3	CONCLUSIONS	We show that these heuristics can be understood, and rigorously analyzed, as approximators to the Bayes optimal classifier for a simple probabilistic model of the edge labels.
4	CONCLUSIONS	We then show that the maximum likelihood estimator for this model approximately corresponds to the predictions of a Label Propagation algorithm run on a transformed version of the original social graph.
5	BACKGROUND	Extensive experiments on a number of real-world datasets show that this algorithm is competitive against state-of-the-art classifiers in terms of both accuracy and scalability.
6	CONCLUSIONS	Finally, we show that troll-trust features can also be used to derive online learning algorithms which have theoretical guarantees even when edges are adversarially labeled.
1	BACKGROUND	Social media is often viewed as a sensor into various societal events such as disease outbreaks, protests, and elections.
2	BACKGROUND	We describe the use of social media as a crowdsourced sensor to gain insight into ongoing cyber-attacks.
3	OBJECTIVE	Our approach detects a broad range of cyber-attacks (e.g., distributed denial of service (DDOS) attacks, data breaches, and account hijacking) in an unsupervised manner using just a limited fixed set of seed event triggers.
4	METHODS	A new query expansion strategy based on convolutional kernels and dependency parses helps model reporting structure and aids in identifying key event characteristics.
5	CONCLUSIONS	Through a large-scale analysis over Twitter, we demonstrate that our approach consistently identifies and encodes events, outperforming existing methods.
1	OBJECTIVE	We introduce a new paradigm that is important for community detection in the realm of network analysis.
2	BACKGROUND	Networks contain a set of strong, dominant communities, which interfere with the detection of weak, natural community structure.
3	BACKGROUND	When most of the members of the weak communities also belong to stronger communities, they are extremely hard to be uncovered.
4	BACKGROUND	We call the weak communities the hidden community structure.
5	OBJECTIVE	We present a novel approach called HICODE (HIdden COmmunity DEtection) that identifies the hidden community structure as well as the dominant community structure.
6	METHODS	By weakening the strength of the dominant structure, one can uncover the hidden structure beneath.
7	OBJECTIVE	Likewise, by reducing the strength of the hidden structure, one can more accurately identify the dominant structure.
8	METHODS	In this way, HICODE tackles both tasks simultaneously.
9	RESULTS	Extensive experiments on real-world networks demonstrate that HICODE outperforms several state-of-the-art community detection methods in uncovering both the dominant and the hidden structure.
10	RESULTS	In the Facebook university social networks, we find multiple non-redundant sets of communities that are strongly associated with residential hall, year of registration or career position of the faculties or students, while the state-of-the-art algorithms mainly locate the dominant ground truth category.
11	RESULTS	In the Due to the difficulty of labeling all ground truth communities in real-world datasets, HICODE provides a promising approach to pinpoint the existing latent communities and uncover communities for which there is no ground truth.
12	CONCLUSIONS	Finding this unknown structure is an extremely important community detection problem.
1	OBJECTIVE	This paper proposes an alternative way to identify nodes with high betweenness centrality.
2	METHODS	It introduces a new metric, k-path centrality, and a randomized algorithm for estimating it, and shows empirically that nodes with high k-path centrality have high node betweenness centrality.
3	METHODS	The randomized algorithm runs in time $O(\kappa^{3}n^{2-2\alpha}\log n)$ and outputs, for each vertex v, an estimate of its k-path centrality up to additive error of $\pm n^{1/2+ \alpha}$ with probability $1-1/n^2$.
4	RESULTS	Experimental evaluations on real and synthetic social networks show improved accuracy in detecting high betweenness centrality nodes and significantly reduced execution time when compared with existing randomized algorithms.
1	BACKGROUND	Most studies on influence maximization focus on one-shot propagation, i.e. the influence is propagated from seed users only once following a probabilistic diffusion model and users' activation are determined via single cascade.
2	BACKGROUND	In reality it is often the case that a user needs to be cumulatively impacted by receiving enough pieces of information propagated to her before she makes the final purchase decision.
3	OBJECTIVE	In this paper we model such cumulative activation as the following process: first multiple pieces of information are propagated independently in the social network following the classical independent cascade model, then the user will be activated (and adopt the product) if the cumulative pieces of information she received reaches her cumulative activation threshold.
4	METHODS	Two optimization problems are investigated under this framework: seed minimization with cumulative activation (SM-CA), which asks how to select a seed set with minimum size such that the number of cumulatively active nodes reaches a given requirement $\eta$; influence maximization with cumulative activation (IM-CA), which asks how to choose a seed set with fixed budget to maximize the number of cumulatively active nodes.
5	METHODS	For SM-CA problem, we design a greedy algorithm that yields a bicriteria $O(\ln n)$-approximation when $\eta=n$, where $n$ is the number of nodes in the network.
6	METHODS	For both SM-CA problem with $\eta<n$ and IM-CA problem, we prove strong inapproximability results.
7	METHODS	Despite the hardness results, we propose two efficient heuristic algorithms for SM-CA and IM-CA respectively based on the reverse reachable set approach.
8	RESULTS	Experimental results on different real-world social networks show that our algorithms significantly outperform baseline algorithms.
1	BACKGROUND	This paper studies an auction design problem for a seller to sell a commodity in a social network, where each individual (the seller or a buyer) can only communicate with her neighbors.
2	BACKGROUND	The challenge to the seller is to design a mechanism to incentivize the buyers, who are aware of the auction, to further propagate the information to their neighbors so that more buyers will participate in the auction and hence, the seller will be able to make a higher revenue.
3	OBJECTIVE	We propose a novel auction mechanism, called information diffusion mechanism (IDM), which incentivizes the buyers to not only truthfully report their valuations on the commodity to the seller, but also further propagate the auction information to all their neighbors.
4	RESULTS	In comparison, the direct extension of the well-known Vickrey-Clarke-Groves (VCG) mechanism in social networks can also incentivize the information diffusion, but it will decrease the seller's revenue or even lead to a deficit sometimes.
5	CONCLUSIONS	The formalization of the problem has not yet been addressed in the literature of mechanism design and our solution is very significant in the presence of large-scale online social networks.
1	OBJECTIVE	Using a dataset of over 1.9 million messages posted on Twitter by about 25,000 ISIS members, we explore how ISIS makes use of social media to spread its propaganda and to recruit militants from the Arab world and across the globe.
2	METHODS	By distinguishing between violence-driven, theological, and sectarian content, we trace the connection between online rhetoric and key events on the ground.
3	BACKGROUND	To the best of our knowledge, ours is one of the first studies to focus on Arabic content, while most literature focuses on English content.
4	RESULTS	Our findings yield new important insights about how social media is used by radical militant groups to target the Arab-speaking world, and reveal important patterns in their propaganda efforts.
1	BACKGROUND	Widespread use of social media has led to the generation of substantial amounts of information about individuals, including health-related information.
2	BACKGROUND	Social media provides the opportunity to study health-related information about selected population groups who may be of interest for a particular study.
3	OBJECTIVE	In this paper, we explore the possibility of utilizing social media to perform targeted data collection and analysis from a particular population group -- pregnant women.
4	METHODS	We hypothesize that we can use social media to identify cohorts of pregnant women and follow them over time to analyze crucial health-related information.
5	METHODS	To identify potentially pregnant women, we employ simple rule-based searches that attempt to detect pregnancy announcements with moderate precision.
6	METHODS	To further filter out false positives and noise, we employ a supervised classifier using a small number of hand-annotated data.
7	METHODS	We then collect their posts over time to create longitudinal health timelines and attempt to divide the timelines into different pregnancy trimesters.
8	METHODS	Finally, we assess the usefulness of the timelines by performing a preliminary analysis to estimate drug intake patterns of our cohort at different trimesters.
9	METHODS	Our rule-based cohort identification technique collected 53,820 users over thirty months from Twitter.
10	RESULTS	Our pregnancy announcement classification technique achieved an F-measure of 0.81 for the pregnancy class, resulting in 34,895 user timelines.
11	RESULTS	Analysis of the timelines revealed that pertinent health-related information, such as drug-intake and adverse reactions can be mined from the data.
12	CONCLUSIONS	Our approach to using user timelines in this fashion has produced very encouraging results and can be employed for other important tasks where cohorts, for which health-related information may not be available from other sources, are required to be followed over time to derive population-based estimates.
1	OBJECTIVE	In this paper, we study crucial elements of a complex network, namely its nodes and connections, which play a key role in maintaining the network's structure and function under unexpected structural perturbations of nodes and edges removal.
2	OBJECTIVE	Specifically, we want to identify vital nodes and edges whose failure (either random or intentional) will break the most number of connected triples (or triangles) in the network.
3	BACKGROUND	This problem is extremely important because connected triples form the foundation of strong connections in many real-world systems, such as mutual relationships in social networks, reliable data transmission in communication networks, and stable routing strategies in mobile networks.
4	BACKGROUND	Disconnected triples, analog to broken mutual connections, can greatly affect the network's structure and disrupt its normal function, which can further lead to the corruption of the entire system.
5	BACKGROUND	The analysis of such crucial elements will shed light on key factors behind the resilience and robustness of many complex systems in practice.
6	METHODS	We formulate the analysis under multiple optimization problems and show their intractability.
7	RESULTS	We next propose efficient approximation algorithms, namely DAK-n and DAK-e, which guarantee an $(1-1/e)$-approximate ratio (compared to the overall optimal solutions) while having the same time complexity as the best triangle counting and listing algorithm on power-law networks.
8	RESULTS	This advantage makes our algorithms scale extremely well even for very large networks.
9	METHODS	In an application perspective, we perform comprehensive experiments on real social traces with millions of nodes and billions of edges.
10	CONCLUSIONS	These empirical experiments indicate that our approaches achieve comparably better results while are up to 100x faster than current state-of-the-art methods.
1	BACKGROUND	Use of social media has grown dramatically during the last few years.
2	BACKGROUND	Users follow informal languages in communicating through social media.
3	BACKGROUND	The language of communication is often mixed in nature, where people transcribe their regional language with English and this technique is found to be extremely popular.
4	BACKGROUND	Natural language processing (NLP) aims to infer the information from these text where Part-of-Speech (PoS) tagging plays an important role in getting the prosody of the written text.
5	METHODS	For the task of PoS tagging on Code-Mixed Indian Social Media Text, we develop a supervised system based on Conditional Random Field classifier.
6	METHODS	In order to tackle the problem effectively, we have focused on extracting rich linguistic features.
7	METHODS	We participate in three different language pairs, ie.
8	METHODS	English-Hindi, English-Bengali and English-Telugu on three different social media platforms, Twitter, Facebook & WhatsApp.
9	RESULTS	The proposed system is able to successfully assign coarse as well as fine-grained PoS tag labels for a given a code-mixed sentence.
10	CONCLUSIONS	Experiments show that our system is quite generic that shows encouraging performance levels on all the three language pairs in all the domains.
1	METHODS	We consider the Threshold Activation Problem (TAP): given social network $G$ and positive threshold $T$, find a minimum-size seed set $A$ that can trigger expected activation of at least $T$.
2	RESULTS	We introduce the first scalable, parallelizable algorithm with performance guarantee for TAP suitable for datasets with millions of nodes and edges; we exploit the bicriteria nature of solutions to TAP to allow the user to control the running time versus accuracy of our algorithm through a parameter $\alpha \in (0,1)$: given $\eta > 0$, with probability $1 - \eta$ our algorithm returns a solution $A$ with expected activation greater than $T - 2 \alpha T$, and the size of the solution $A$ is within factor $1 + 4 \alpha T + \log ( T )$ of the optimal size.
3	METHODS	The algorithm runs in time $O \left( \alpha^{-2}\log \left( n / \eta \right) (n + m) |A| \right)$, where $n$, $m$, refer to the number of nodes, edges in the network.
4	CONCLUSIONS	The performance guarantee holds for the general triggering model of internal influence and also incorporates external influence, provided a certain condition is met on the cost-effectivity of seed selection.
1	BACKGROUND	Networks describe a range of social, biological and technical phenomena.
2	BACKGROUND	An important property of a network is its degree correlation or assortativity, describing how nodes in the network associate based on their number of connections.
3	BACKGROUND	Social networks are typically thought to be distinct from other networks in being assortative (possessing positive degree correlations); well-connected individuals associate with other well-connected individuals, and poorly-connected individuals associate with each other.
4	OBJECTIVE	We review the evidence for this in the literature and find that, while social networks are more assortative than non-social networks, only when they are built using group-based methods do they tend to be positively assortative.
5	BACKGROUND	Non-social networks tend to be disassortative.
6	METHODS	We go on to show that connecting individuals due to shared membership of a group, a commonly used method, biases towards assortativity unless a large enough number of censuses of the network are taken.
7	RESULTS	We present a number of solutions to overcoming this bias by drawing on advances in sociological and biological fields.
8	CONCLUSIONS	Adoption of these methods across all fields can greatly enhance our understanding of social networks and networks in general.
1	OBJECTIVE	Motivated by applications in social network community analysis, we introduce a new clustering paradigm termed motif clustering.
2	BACKGROUND	"Unlike classical clustering, motif clustering aims to minimize the number of clustering errors associated with both edges and certain higher order graph structures (motifs) that represent ""atomic units"" of social organizations."
3	OBJECTIVE	"Our contributions are two-fold: We first introduce motif correlation clustering, in which the goal is to agnostically partition the vertices of a weighted complete graph so that certain predetermined ""important"" social subgraphs mostly lie within the same cluster, while ""less relevant"" social subgraphs are allowed to lie across clusters."
4	OBJECTIVE	We then proceed to introduce the notion of motif covers, in which the goal is to cover the vertices of motifs via the smallest number of (near) cliques in the graph.
5	BACKGROUND	Motif cover algorithms provide a natural solution for overlapping clustering and they also play an important role in latent feature inference of networks.
6	OBJECTIVE	For both motif correlation clustering and its extension introduced via the covering problem, we provide hardness results, algorithmic solutions and community detection results for two well-studied social networks.
1	BACKGROUND	Social network analysis is leveraged in a variety of applications such as identifying influential entities, detecting communities with special interests, and determining the flow of information and innovations.
2	BACKGROUND	However, existing approaches for extracting social networks from unstructured Web content do not scale well and are only feasible for small graphs.
3	OBJECTIVE	In this paper, we introduce novel methodologies for query-based search engine mining, enabling efficient extraction of social networks from large amounts of Web data.
4	METHODS	To this end, we use patterns in phrase queries for retrieving entity connections, and employ a bootstrapping approach for iteratively expanding the pattern set.
5	CONCLUSIONS	Our experimental evaluation in different domains demonstrates that our algorithms provide high quality results and allow for scalable and efficient construction of social graphs.
1	BACKGROUND	Information technology (IT) has been used widely in many aspects of our daily life.
2	BACKGROUND	After discuss politics related aspects for some articles.
3	OBJECTIVE	In this article author would like to discuss social media for students learning environment.
4	BACKGROUND	Social media as a leading application on the internet has changed many aspects of life become more globalized.
5	OBJECTIVE	This article discusses the use of social media to support learning activities for students in the faculty of computer science.
6	METHODS	The author uses Facebook and WordPress as an alternative to electronic learning: 1) online attendance tool, 2) media storage and dissemination of course materials, 3) event scheduling for the lectures.
7	RESULTS	Social media succeed to change the way of modern learning styles and environment.
8	RESULTS	The results of this study are some learning activities such as : 1) Preparation, 2) Weekly meeting activities, 3) Course Page, 4) Social Media as Online Attendance Tool, 5) Social Media as Learning Repository and Dissemination, and 6) Social Media as Online Event Scheduling.
1	BACKGROUND	Lifestyles are a valuable model for understanding individuals' physical and mental lives, comparing social groups, and making recommendations for improving people's lives.
2	OBJECTIVE	In this paper, we examine and compare lifestyle behaviors of people living in cities of different sizes, utilizing freely available social media data as a large-scale, low-cost alternative to traditional survey methods.
3	METHODS	We use the Greater New York City area as a representative for large cities, and the Greater Rochester area as a representative for smaller cities in the United States.
4	METHODS	We employed matrix factor analysis as an unsupervised method to extract salient mobility and work-rest patterns for a large population of users within each metropolitan area.
5	RESULTS	We discovered interesting human behavior patterns at both a larger scale and a finer granularity than is present in previous literature, some of which allow us to quantitatively compare the behaviors of individuals of living in big cities to those living in small cities.
6	CONCLUSIONS	We believe that our social media-based approach to lifestyle analysis represents a powerful tool for social computing in the big data age.
1	BACKGROUND	Given the huge impact that Online Social Networks (OSN) had in the way people get informed and form their opinion, they became an attractive playground for malicious entities that want to spread misinformation, and leverage their effect.
2	BACKGROUND	"In fact, misinformation easily spreads on OSN and is a huge threat for modern society, possibly influencing also the outcome of elections, or even putting people's life at risk (e.g., spreading ""anti-vaccines"" misinformation)."
3	BACKGROUND	"Therefore, it is of paramount importance for our society to have some sort of ""validation"" on information spreading through OSN."
4	BACKGROUND	The need for a wide-scale validation would greatly benefit from automatic tools.
5	OBJECTIVE	In this paper, we show that it is difficult to carry out an automatic classification of misinformation considering only structural properties of content propagation cascades.
6	METHODS	We focus on structural properties, because they would be inherently difficult to be manipulated, with the the aim of circumventing classification systems.
7	METHODS	To support our claim, we carry out an extensive evaluation on Facebook posts belonging to conspiracy theories (as representative of misinformation), and scientific news (representative of fact-checked content).
8	CONCLUSIONS	Our findings show that conspiracy content actually reverberates in a way which is hard to distinguish from the one scientific content does: for the classification mechanisms we investigated, classification F1-score never exceeds 0.65 during content propagation stages, and is still less than 0.7 even after propagation is complete.
1	BACKGROUND	Social graph construction from various sources has been of interest to researchers due to its application potential and the broad range of technical challenges involved.
2	BACKGROUND	The World Wide Web provides a huge amount of continuously updated data and information on a wide range of topics created by a variety of content providers, and makes the study of extracted people networks and their temporal evolution valuable for social as well as computer scientists.
3	OBJECTIVE	In this paper we present SocGraph - an extraction and exploration system for social relations from the content of around 2 billion web pages collected by the Internet Archive over the 17 years time period between 1996 and 2013.
4	METHODS	We describe methods for constructing large social graphs from extracted relations and introduce an interface to study their temporal evolution.
1	BACKGROUND	Recent approaches for sentiment lexicon induction have capitalized on pre-trained word embeddings that capture latent semantic properties.
2	BACKGROUND	However, embeddings obtained by optimizing performance of a given task (e.g. predicting contextual words) are sub-optimal for other applications.
3	OBJECTIVE	In this paper, we address this problem by exploiting task-specific representations, induced via embedding sub-space projection.
4	METHODS	This allows us to expand lexicons describing multiple semantic properties.
5	METHODS	For each property, our model jointly learns suitable representations and the concomitant predictor.
6	CONCLUSIONS	Experiments conducted over multiple subjective lexicons, show that our model outperforms previous work and other baselines; even in low training data regimes.
7	CONCLUSIONS	Furthermore, lexicon-based sentiment classifiers built on top of our lexicons outperform similar resources and yield performances comparable to those of supervised models.
1	BACKGROUND	Argumentation mining from social media content has attracted increasing attention.
2	BACKGROUND	The task is both challenging and rewarding.
3	BACKGROUND	The informal nature of user-generated content makes the task dauntingly difficult.
4	BACKGROUND	On the other hand, the insights that could be gained by a large-scale analysis of social media argumentation make it a very worthwhile task.
5	OBJECTIVE	In this position paper I discuss the motivation for social media argumentation mining, as well as the tasks and challenges involved.
1	BACKGROUND	Building Part-of-Speech (POS) taggers for code-mixed Indian languages is a particularly challenging problem in computational linguistics due to a dearth of accurately annotated training corpora.
2	BACKGROUND	ICON, as part of its NLP tools contest has organized this challenge as a shared task for the second consecutive year to improve the state-of-the-art.
3	OBJECTIVE	This paper describes the POS tagger built at Surukam to predict the coarse-grained and fine-grained POS tags for three language pairs - Bengali-English, Telugu-English and Hindi-English, with the text spanning three popular social media platforms - Facebook, WhatsApp and Twitter.
4	METHODS	We employed Conditional Random Fields as the sequence tagging algorithm and used a library called sklearn-crfsuite - a thin wrapper around CRFsuite for training our model.
5	METHODS	Among the features we used include - character n-grams, language information and patterns for emoji, number, punctuation and web-address.
6	RESULTS	Our submissions in the constrained environment,i.e., without making any use of monolingual POS taggers or the like, obtained an overall average F1-score of 76.45%, which is comparable to the 2015 winning score of 76.79%.
1	BACKGROUND	Thanks to the advent of the Internet, it is now possible to easily share vast amounts of electronic information and computer resources (which include hardware, computer services, etc.) in open distributed environments.
2	BACKGROUND	These environments serve as a common platform for heterogeneous users (e.g., corporate, individuals etc.) by hosting customized user applications and systems, providing ubiquitous access to the shared resources and requiring less administrative efforts; as a result, they enable users and companies to increase their productivity.
3	BACKGROUND	Unfortunately, sharing of resources in open environments has significantly increased the privacy threats to the users.
4	BACKGROUND	Indeed, shared electronic data may be exploited by third parties, such as Data Brokers, which may aggregate, infer and redistribute (sensitive) personal features, thus potentially impairing the privacy of the individuals.
5	BACKGROUND	A way to palliate this problem consists on controlling the access of users over the potentially sensitive resources.
6	BACKGROUND	Specifically, access control management regulates the access to the shared resources according to the credentials of the users, the type of resource and the privacy preferences of the resource/data owners.
7	BACKGROUND	The efficient management of access control is crucial in large and dynamic environments.
8	BACKGROUND	Moreover, in order to propose a feasible and scalable solution, we need to get rid of manual management of rules/constraints (in which most available solutions rely) that constitutes a serious burden for the users and the administrators.
9	BACKGROUND	Finally, access control management should be intuitive for the end users, who usually lack technical expertise, and they may find access control mechanism more difficult to understand and rigid to apply due to its complex configuration settings.
1	BACKGROUND	Social media websites, electronic newspapers and Internet forums allow visitors to leave comments for others to read and interact.
2	BACKGROUND	This exchange is not free from participants with malicious intentions, who troll others by positing messages that are intended to be provocative, offensive, or menacing.
3	OBJECTIVE	With the goal of facilitating the computational modeling of trolling, we propose a trolling categorization that is novel in the sense that it allows comment-based analysis from both the trolls' and the responders' perspectives, characterizing these two perspectives using four aspects, namely, the troll's intention and his intention disclosure, as well as the responder's interpretation of the troll's intention and her response strategy.
4	RESULTS	Using this categorization, we annotate and release a dataset containing excerpts of Reddit conversations involving suspected trolls and their interactions with other users.
5	CONCLUSIONS	Finally, we identify the difficult-to-classify cases in our corpus and suggest potential solutions for them.
1	BACKGROUND	Online social network analysis has attracted great attention with a vast number of users sharing information and availability of APIs that help to crawl online social network data.
2	OBJECTIVE	In this paper, we study the research studies that are helpful for user characterization as online users may not always reveal their true identity or attributes.
3	METHODS	We especially focused on user attribute determination such as gender, age, etc.; user behavior analysis such as motives for deception; mental models that are indicators of user behavior; user categorization such as bots vs. humans; and entity matching on different social networks.
4	RESULTS	We believe our summary of analysis of user characterization will provide important insights to researchers and better services to online users.
1	BACKGROUND	Increasing evidence suggests that, similar to face-to-face communications, human emotions also spread in online social media.
2	BACKGROUND	However, the mechanisms underlying this emotional contagion, for example, whether different feelings spread in unlikely ways or how the spread of emotions relates to the social network, is rarely investigated.
3	BACKGROUND	Indeed, because of high costs and spatio-temporal limitations, explorations of this topic are challenging using conventional questionnaires or controlled experiments.
4	BACKGROUND	Because they are collection points for natural affective responses of massive individuals, online social media sites offer an ideal proxy for tackling this issue from the perspective of computational social science.
5	BACKGROUND	In this paper, based on the analysis of millions of tweets in Weibo, surprisingly, we find that anger is more contagious than joy, indicating that it can spark more angry follow-up tweets.
6	BACKGROUND	Moreover, regarding dissemination in social networks, anger travels easily along weaker ties than joy, meaning that it can infiltrate different communities and break free of local traps because strangers share such content more often.
7	OBJECTIVE	Through a simple diffusion model, we reveal that greater contagion and weaker ties function cooperatively to speed up anger's spread.
8	RESULTS	The diffusion of real-world events with different dominant emotions provides further testimony to the findings.
9	RESULTS	To the best of our knowledge, this is the first time that quantitative long-term evidence has been presented that reveals a difference in the mechanism by which joy and anger are disseminated.
10	CONCLUSIONS	Our findings shed light on both personal anger management in human communications and on controlling collective outrage in cyberspace.
1	BACKGROUND	Automatic profiling of social media users is an important task for supporting a multitude of downstream applications.
2	BACKGROUND	While a number of studies have used social media content to extract and study collective social attributes, there is a lack of substantial research that addresses the detection of a user's industry.
3	METHODS	We frame this task as classification using both feature engineering and ensemble learning.
4	RESULTS	Our industry-detection system uses both posted content and profile information to detect a user's industry with 64.3% accuracy, significantly outperforming the majority baseline in a taxonomy of fourteen industry classes.
5	RESULTS	Our qualitative analysis suggests that a person's industry not only affects the words used and their perceived meanings, but also the number and type of emotions being expressed.
1	OBJECTIVE	In this work, we describe a conditional random fields (CRF) based system for Part-Of- Speech (POS) tagging of code-mixed Indian social media text as part of our participation in the tool contest on POS tagging for codemixed Indian social media text, held in conjunction with the 2016 International Conference on Natural Language Processing, IIT(BHU), India.
2	METHODS	We participated only in constrained mode contest for all three language pairs, Bengali-English, Hindi-English and Telegu-English.
3	RESULTS	Our system achieves the overall average F1 score of 79.99, which is the highest overall average F1 score among all 16 systems participated in constrained mode contest.
1	BACKGROUND	As more scholarly content is being born digital or digitized, digital libraries are becoming increasingly vital to researchers leveraging scholarly big data for scientific discovery.
2	BACKGROUND	Given the abundance of scholarly products-especially in environments created by the advent of social networking services-little is known about international scholarly information needs, information-seeking behavior, or information use.
3	OBJECTIVE	This paper aims to address these gaps by conducting an in-depth analysis of researchers in the United States and Qatar; learn about their research attitudes, practices, tactics, strategies, and expectations; and address the obstacles faced during research endeavors.
4	METHODS	Based on this analysis, the study identifies and describes new behavior patterns on the part of researchers as they engage in the information-seeking process.
5	RESULTS	The analysis reveals that the use of academic social networks has remarkable effects on various scholarly activities.
6	METHODS	Further, this study identifies differences between students and faculty members in regard to their use of academic social networks, and it identifies differences between researchers according to discipline.
7	METHODS	The researchers who participated in the present study represent a range of disciplinary and cultural backgrounds.
8	RESULTS	However, the study reports a number of similarities in terms of the researchers' scholarly activities.
9	RESULTS	Finally, the study illuminates some of the implications for the design of research platforms.
1	BACKGROUND	Profile images on social networks are users' opportunity to present themselves and to affect how others judge them.
2	OBJECTIVE	We examine what Facebook images say about users' perceived and measured intelligence.
3	BACKGROUND	1,122 Facebook users completed a matrices intelligence test and shared their current Facebook profile image.
4	BACKGROUND	Strangers also rated the images for perceived intelligence.
5	METHODS	We use automatically extracted image features to predict both measured and perceived intelligence.
6	RESULTS	Intelligence estimation from images is a difficult task even for humans, but experimental results show that human accuracy can be equalled using computing methods.
7	RESULTS	"We report the image features that predict both measured and perceived intelligence, and highlight misleading features such as ""smiling"" and ""wearing glasses"" that are correlated with perceived but not measured intelligence."
8	RESULTS	Our results give insights into inaccurate stereotyping from profile images and also have implications for privacy, especially since in most social networks profile images are public by default.
1	BACKGROUND	The main subject studied in this dissertation is a multi-layered social network (MSN) and its analysis.
2	BACKGROUND	One of the crucial problems in multi-layered social network analysis is community extraction.
3	BACKGROUND	To cope with this problem the CLECC measure (Cross Layered Edge Clustering Coefficient) was proposed in the thesis.
4	BACKGROUND	It is an edge measure which expresses how much the neighbors of two given users are similar each other.
5	BACKGROUND	Based on this measure the CLECC algorithm for community extraction in the multi-layered social networks was designed.
6	METHODS	The algorithm was tested on the real single-layered social networks (SSN) and multi-layered social networks (MSN), as well as on benchmark networks from GN Benchmark (SSN), LFR Benchmark (SSN) and mLFR Benchmark (MSN) a special extension of LFR Benchmark, designed as a part of this thesis, which is able to produce multi-layered benchmark networks.
7	OBJECTIVE	The second research problem considered in the thesis was group evolution discovery.
8	METHODS	Studies on this problem have led to the development of the inclusion measure and the Group Evolution Discovery (GED) method, which is designed to identify events between two groups in successive time frames in the social network.
9	METHODS	The method was tested on a real social network and compared with two well-known algorithms regarding accuracy, execution time, flexibility and ease of implementation.
10	METHODS	Finally, a new approach to prediction of group evolution in the social network was developed.
11	METHODS	The new approach involves usage of the outputs of the GED method.
12	OBJECTIVE	It is shown, that using even a simple sequence, which consists of several preceding groups sizes and events, as an input for the classifier, the learned model can produce very good results also for simple classifiers.
1	BACKGROUND	Influential node detection is a central research topic in social network analysis.
2	BACKGROUND	Many existing methods rely on the assumption that the network structure is completely known \textit{a priori}.
3	BACKGROUND	However, in many applications, network structure is unavailable to explain the underlying information diffusion phenomenon.
4	OBJECTIVE	To address the challenge of information diffusion analysis with incomplete knowledge of network structure, we develop a multi-task low rank linear influence model.
5	METHODS	By exploiting the relationships between contagions, our approach can simultaneously predict the volume (i.e. time series prediction) for each contagion (or topic) and automatically identify the most influential nodes for each contagion.
6	METHODS	The proposed model is validated using synthetic data and an ISIS twitter dataset.
7	OBJECTIVE	In addition to improving the volume prediction performance significantly, we show that the proposed approach can reliably infer the most influential users for specific contagions.
1	BACKGROUND	We consider pairwise Markov random fields which have a number of important applications in statistical physics, image processing and machine learning such as Ising model and labeling problem to name a couple.
2	OBJECTIVE	Our own motivation comes from the need to produce synthetic models for social networks with attributes.
3	METHODS	First, we give conditions for rapid mixing of the associated Glauber dynamics and consider interesting particular cases.
4	METHODS	Then, for pairwise Markov random fields with submodular energy functions we construct monotone perfect simulation.
1	OBJECTIVE	A large scale agent-based model of common Facebook users was designed to develop an understanding of the underlying mechanism of information diffusion within online social networks at a micro-level analysis.
2	METHODS	The agent-based model network structure is based on a sample from Facebook.
3	METHODS	Using an erased configuration model and the idea of common neighbours, a new correction procedure was investigated to overcome the problem of missing graph edges to construct a representative sample of the Facebook network graph.
4	METHODS	The model parameters are based on assumptions and general activity patterns (such as posting rate, time spent on Facebook etc.) taken from general data on Facebook.
5	OBJECTIVE	Using the agent-based model, the impact of post length, post score and publisher's friend count on the spread of wall posts in several scenarios was analyzed.
6	RESULTS	Findings indicated that post content has the highest impact on the success of post propagation.
7	RESULTS	However, amusing and absorbing but lengthy posts (e.g. a funny video) do not spread as well as short but unremarkable ones (e.g. an interesting photo).
8	CONCLUSIONS	"In contrast to product adoption and disease spread propagation models, the absence of a similar ""epidemic"" threshold in Facebook post diffusion is observed."
1	BACKGROUND	Many software projects are no longer done in-house by a single organization.
2	BACKGROUND	Instead, we are in a new age where software is developed by a networked community of individuals and organizations, which base their relations to each other on mutual interest.
3	BACKGROUND	Paradoxically, recent research suggests that software development can actually be jointly-developed by rival firms.
4	BACKGROUND	For instance, it is known that the mobile-device makers Apple and Samsung kept collaborating in open source projects while running expensive patent wars in the court.
5	OBJECTIVE	Taking a case study approach, we explore how rival firms collaborate in the open source arena by employing a multi-method approach that combines qualitative analysis of archival data (QA) with mining software repositories (MSR) and Social Network Analysis (SNA).
6	OBJECTIVE	While exploring collaborative processes within the OpenStack ecosystem, our research contributes to Software Engineering research by exploring the role of groups, sub-communities and business models within a high-networked open source ecosystem.
7	RESULTS	Surprising results point out that competition for the same revenue model (i.e., operating conflicting business models) does not necessary affect collaboration within the ecosystem.
8	CONCLUSIONS	Moreover, while detecting the different sub-communities of the OpenStack community, we found out that the expected social tendency of developers to work with developers from same firm (i.e., homophily) did not hold within the OpenStack ecosystem.
9	CONCLUSIONS	Furthermore, while addressing a novel, complex and unexplored open source case, this research also contributes to the management literature in coopetition strategy and high-tech entrepreneurship with a rich description on how heterogeneous actors within a high-networked ecosystem (involving individuals, startups, established firms and public organizations) joint-develop a complex infrastructure for big-data in the open source arena.
1	BACKGROUND	With the popularity of mobile devices, personalized speech recognizer becomes more realizable today and highly attractive.
2	BACKGROUND	Each mobile device is primarily used by a single user, so it's possible to have a personalized recognizer well matching to the characteristics of individual user.
3	BACKGROUND	Although acoustic model personalization has been investigated for decades, much less work have been reported on personalizing language model, probably because of the difficulties in collecting enough personalized corpora.
4	BACKGROUND	Previous work used the corpora collected from social networks to solve the problem, but constructing a personalized model for each user is troublesome.
5	OBJECTIVE	In this paper, we propose a universal recurrent neural network language model with user characteristic features, so all users share the same model, except each with different user characteristic features.
6	METHODS	These user characteristic features can be obtained by crowdsouring over social networks, which include huge quantity of texts posted by users with known friend relationships, who may share some subject topics and wording patterns.
7	RESULTS	The preliminary experiments on Facebook corpus showed that this proposed approach not only drastically reduced the model perplexity, but offered very good improvement in recognition accuracy in n-best rescoring tests.
8	RESULTS	This approach also mitigated the data sparseness problem for personalized language models.
1	BACKGROUND	This paper describes Centre for Development of Advanced Computing's (CDACM) submission to the shared task-'Tool Contest on POS tagging for Code-Mixed Indian Social Media (Facebook, Twitter, and Whatsapp) Text', collocated with ICON-2016.
2	BACKGROUND	The shared task was to predict Part of Speech (POS) tag at word level for a given text.
3	BACKGROUND	The code-mixed text is generated mostly on social media by multilingual users.
4	BACKGROUND	The presence of the multilingual words, transliterations, and spelling variations make such content linguistically complex.
5	OBJECTIVE	In this paper, we propose an approach to POS tag code-mixed social media text using Recurrent Neural Network Language Model (RNN-LM) architecture.
6	OBJECTIVE	We submitted the results for Hindi-English (hi-en), Bengali-English (bn-en), and Telugu-English (te-en) code-mixed data.
1	OBJECTIVE	Given a social network of experts, we address the problem of discovering a team of experts that collectively holds a set of skills required to complete a given project.
2	BACKGROUND	Most prior work ranks possible solutions by communication cost, represented by edge weights in the expert network.
3	METHODS	Our contribution is to take experts authority into account, represented by node weights.
4	METHODS	We formulate several problems that combine communication cost and authority, we prove that they are NP-hard, and we propose and experimentally evaluate greedy algorithms to solve them.
1	BACKGROUND	More than ever, social networks have become an important place in the interaction and behaviour of humans in the last decade.
2	OBJECTIVE	This valuable position makes it imperative to analyze different aspects of everyday life and science in general.
3	OBJECTIVE	This paper illustrates the process of capturing and storing information, the application of density-based clustering and improved nearest neighbor, and a review of the results.
4	RESULTS	The study also shows the elements used in the identification of areas of interest through clusters, circumferences and coverage radii obtained for a demographic segmentation analysis of the information procured from Twitter, Flickr and the like.
5	RESULTS	This results in more profound conclusions about a predefined topic or theme.
6	CONCLUSIONS	Finally, the need arises to develop an application that makes all the defined process automatic, allowing final users interested in those topics to have access to it and get important results for their organizations or interest.
1	OBJECTIVE	We analyze the problem of majority sentiment detection in Online Social Networks (OSN), and relate the detection error probability to the underlying graph of the OSN.
2	METHODS	Modeling the underlying social network as an Ising Markov random field prior based on a given graph, we show that in the case of the empty graph (independent sentiments) and the chain graph, the detection is always inaccurate, even when the number of users grow to infinity.
3	RESULTS	In the case of the complete graph, the detection is inaccurate if the connection strength is below a certain critical value, while it is asymptotically accurate if the strength is above that critical value, which is analogous to the phase transition phenomenon in statistical physics.
1	OBJECTIVE	We propose a new variant of the group activity selection problem (GASP), where the agents are placed on a social network and activities can only be assigned to connected subgroups.
2	METHODS	We show that if multiple groups can simultaneously engage in the same activity, finding a stable outcome is easy as long as the network is acyclic.
3	RESULTS	In contrast, if each activity can be assigned to a single group only, finding stable outcomes becomes intractable, even if the underlying network is very simple: the problem of determining whether a given instance of a GASP admits a Nash stable outcome turns out to be NP-hard when the social network is a path, a star, or if the size of each connected component is bounded by a constant.
4	RESULTS	On the other hand, we obtain fixed-parameter tractability results for this problem with respect to the number of activities.
1	OBJECTIVE	In this paper, we investigate the effectiveness of unsupervised feature learning techniques in predicting user engagement on social media.
2	METHODS	Specifically, we compare two methods to predict the number of feedbacks (i.e., comments) that a blog post is likely to receive.
3	METHODS	We compare Principal Component Analysis (PCA) and sparse Autoencoder to a baseline method where the data are only centered and scaled, on each of two models: Linear Regression and Regression Tree.
4	RESULTS	We find that unsupervised learning techniques significantly improve the prediction accuracy on both models.
5	RESULTS	For the Linear Regression model, sparse Autoencoder achieves the best result, with an improvement in the root mean squared error (RMSE) on the test set of 42% over the baseline method.
6	RESULTS	For the Regression Tree model, PCA achieves the best result, with an improvement in RMSE of 15% over the baseline.
1	OBJECTIVE	In this paper a new method for information hiding in open social networks is introduced.
2	METHODS	The method, called StegHash, is based on the use of hashtags in various open social networks to connect multimedia files (like images, movies, songs) with embedded hidden messages.
3	METHODS	The evaluation of the system was performed on two social media services (Twitter and Instagram) with a simple environment as a proof of concept.
4	CONCLUSIONS	The experiments proved that the initial idea was correct, thus the proposed system could create a completely new area of threats in social networks.
1	BACKGROUND	Live online social broadcasting services like YouTube Live and Twitch have steadily gained popularity due to improved bandwidth, ease of generating content and the ability to earn revenue on the generated content.
2	BACKGROUND	In contrast to traditional cable television, revenue in online services is generated solely through advertisements, and depends on the number of clicks generated.
3	BACKGROUND	Channel owners aim to opportunistically schedule advertisements so as to generate maximum revenue.
4	OBJECTIVE	This paper considers the problem of optimal scheduling of advertisements in live online social media.
5	METHODS	The problem is formulated as a multiple stopping problem and is addressed in a partially observed Markov decision process (POMDP) framework.
6	METHODS	Structural results are provided on the optimal advertisement scheduling policy.
7	METHODS	By exploiting the structure of the optimal policy, best linear thresholds are computed using stochastic approximation.
8	RESULTS	The proposed model and framework are validated on real datasets, and the following observations are made: (i) The policy obtained by the multiple stopping problem can be used to detect changes in ground truth from online search data (ii) Numerical results show a significant improvement in the expected revenue by opportunistically scheduling the advertisements.
9	CONCLUSIONS	The revenue can be improved by $20-30\%$ in comparison to currently employed periodic scheduling.
1	METHODS	This paper deals with the statistical signal pro- cessing over graphs for tracking infection diffusion in social networks.
2	METHODS	Infection (or Information) diffusion is modeled using the Susceptible-Infected-Susceptible (SIS) model.
3	METHODS	Mean field approximation is employed to approximate the discrete valued infected degree distribution evolution by a deterministic ordinary differential equation for obtaining a generative model for the infection diffusion.
4	RESULTS	The infected degree distribution is shown to follow polynomial dynamics and is estimated using an exact non- linear Bayesian filter.
5	METHODS	We compute posterior Cramer-Rao bounds to obtain the fundamental limits of the filter which depend on the structure of the network.
6	METHODS	Considering the time-varying nature of the real world networks, the relationship between the diffusion thresholds and the degree distribution is investigated using generative models for real world networks.
7	RESULTS	In addition, we validate the efficacy of our method with the diffusion data from a real-world online social system, Twitter.
8	CONCLUSIONS	We find that SIS model is a good fit for the information diffusion and the non-linear filter effectively tracks the information diffusion.
1	OBJECTIVE	This work proposes a novel framework for the development of new products and services in transportation through an open innovation approach based on automatic content analysis of social media data.
2	METHODS	The framework is able to extract users comments from Online Social Networks (OSN), to process and analyze text through information extraction and sentiment analysis techniques to obtain relevant information about product reception on the market.
3	METHODS	A use case was developed using the mobile application Uber, which is today one of the fastest growing technology companies in the world.
4	RESULTS	We measured how a controversial, highly diffused event influences the volume of tweets about Uber and the perception of its users.
5	CONCLUSIONS	While there is no change in the image of Uber, a large increase in the number of tweets mentioning the company is observed, which meant a free and important diffusion of its product.
1	METHODS	We consider a population of interconnected individuals that, with respect to a piece of information, at each time instant can be subdivided into three (time-dependent) categories: agnostics, influenced, and evangelists.
2	BACKGROUND	A dynamical process of information diffusion evolves among the individuals of the population according to the following rules.
3	METHODS	Initially, all individuals are agnostic.
4	METHODS	Then, a set of people is chosen from the outside and convinced to start evangelizing, i.e., to start spreading the information.
5	RESULTS	When a number of evangelists, greater than a given threshold, communicate with a node v, the node v becomes influenced, whereas, as soon as the individual v is contacted by a sufficiently much larger number of evangelists, it is itself converted into an evangelist and consequently it starts spreading the information.
6	METHODS	The question is: How to choose a bounded cardinality initial set of evangelists so as to maximize the final number of influenced individuals?
7	CONCLUSIONS	We prove that the problem is hard to solve, even in an approximate sense.
8	RESULTS	On the positive side, we present exact polynomial time algorithms for trees and complete graphs.
9	METHODS	For general graphs, we derive exact parameterized algorithms.
10	OBJECTIVE	We also investigate the problem when the objective is to select a minimum number of evangelists capable of influencing the whole network.
11	BACKGROUND	Our motivations to study these problems come from the areas of Viral Marketing and the analysis of quantitative models of spreading of influence in social networks.
1	BACKGROUND	Psychologists have demonstrated that pets have a positive impact on owners' happiness.
2	BACKGROUND	For example, lonely people are often advised to have a dog or cat to quell their social isolation.
3	BACKGROUND	Conventional psychological research methods of analyzing this phenomenon are mostly based on surveys or self-reported questionnaires, which are time-consuming and lack of scalability.
4	BACKGROUND	Utilizing social media as an alternative and complimentary resource could potentially address both issues and provide different perspectives on this psychological investigation.
5	OBJECTIVE	In this paper, we propose a novel and effective approach that exploits social media to study the effect of pets on owners' happiness.
6	METHODS	The proposed framework includes three major components: 1) collecting user-level data from Instagram consisting of about 300,000 images from 2905 users; 2) constructing a convolutional neural network (CNN) for pets classification, and combined with timeline information, further identifying pet owners and the control group; 3) measuring the confidence score of happiness by detecting and analyzing selfie images.
7	METHODS	Furthermore, various factors of demographics are employed to analyze the fine-grained effects of pets on happiness.
8	RESULTS	Our experimental results demonstrate the effectiveness of the proposed approach and we believe that this approach can be applied to other related domains as a large-scale, high-confidence methodology of user activity analysis through social media.
1	BACKGROUND	On-line social networks are complex ensembles of inter-linked communities that interact on different topics.
2	BACKGROUND	Some communities are characterized by what are usually referred to as deviant behaviors, conducts that are commonly considered inappropriate with respect to the society's norms or moral standards.
3	BACKGROUND	Eating disorders, drug use, and adult content consumption are just a few examples.
4	BACKGROUND	We refer to such communities as deviant networks.
5	BACKGROUND	It is commonly believed that such deviant networks are niche, isolated social groups, whose activity is well separated from the mainstream social-media life.
6	BACKGROUND	According to this assumption, research studies have mostly considered them in isolation.
7	OBJECTIVE	In this work we focused on adult content consumption networks, which are present in many on-line social media and in the Web in general.
8	BACKGROUND	We found that few small and densely connected communities are responsible for most of the content production.
9	OBJECTIVE	Differently from previous work, we studied how such communities interact with the whole social network.
10	RESULTS	We found that the produced content flows to the rest of the network mostly directly or through bridge-communities, reaching at least 450 times more users.
11	RESULTS	We also show that a large fraction of the users can be inadvertently exposed to such content through indirect content resharing.
12	RESULTS	We also discuss a demographic analysis of the producers and consumers networks.
13	RESULTS	Finally, we show that it is easily possible to identify a few core users to radically uproot the diffusion process.
14	CONCLUSIONS	We aim at setting the basis to study deviant communities in context.
1	BACKGROUND	Opinion polls mediated through a social network can give us, in addition to usual demographics data like age, gender and geographic location, a friendship structure between voters and the temporal dynamics of their activity during the voting process.
2	METHODS	Using a Facebook application we collected friendship relationships, demographics and votes of over ten thousand users on the referendum on the definition of marriage in Croatia held on 1st of December 2013.
3	METHODS	We also collected data on online news articles mentioning our application.
4	RESULTS	Publication of these articles align closely with large peaks of voting activity, indicating that these external events have a crucial influence in engaging the voters.
5	RESULTS	Also, existence of strongly connected friendship communities where majority of users vote during short time period, and the fact that majority of users in general tend to friend users that voted the same suggest that peer influence also has its role in engaging the voters.
6	CONCLUSIONS	As we are not able to track activity of our users at all times, and we do not know their motivations for expressing their votes through our application, the question is whether we can infer peer and external influence using friendship network of users and the times of their voting.
7	OBJECTIVE	We propose a new method for estimation of magnitude of peer and external influence in friendship network and demonstrate its validity on both simulated and actual data.
1	BACKGROUND	Online Social Networks explode with activity whenever a crisis event takes place.
2	BACKGROUND	Most content generated as part of this activity is a mixture of text and images, and is particularly useful for first responders to identify popular topics of interest and gauge the pulse and sentiment of citizens.
3	BACKGROUND	While multiple researchers have used text to identify, analyze and measure themes and public sentiment during such events, little work has explored visual themes floating on networks in the form of images, and the sentiment inspired by them.
4	OBJECTIVE	Given the potential of visual content for influencing users' thoughts and emotions, we perform a large scale analysis to compare popular themes and sentiment across images and textual content posted on Facebook during the terror attacks that took place in Paris in 2015.
5	METHODS	Using state-of-the-art image summarization techniques, we discovered multiple visual themes which were popular in images, but were not identifiable through text.
6	RESULTS	We uncovered instances of misinformation and false flag (conspiracy) theories among popular image themes, which were not prominent in user generated textual content, and can be of particular inter- est to first responders.
7	RESULTS	Our analysis also revealed that while textual content posted after the attacks reflected negative sentiment, images inspired positive sentiment.
8	BACKGROUND	To the best of our knowledge, this is the first large scale study of images posted on social networks during a crisis event.
1	BACKGROUND	In a social network, even about the same information the excitements between different pairs of users are different.
2	BACKGROUND	If you want to spread a piece of new information and maximize the expected total amount of excitements, which seed users should you choose?
3	BACKGROUND	This problem indeed is substantially different from the renowned influence maximization problem and cannot be tackled using the existing approaches.
4	OBJECTIVE	In this paper, motivated by the demand in a few interesting applications, we model the novel problem of activity maximization.
5	METHODS	We tackle the problem systematically.
6	METHODS	We first analyze the complexity and the approximability of the problem.
7	METHODS	We develop an upper bound and a lower bound that are submodular so that the Sandwich framework can be applied.
8	METHODS	We then devise a polling-based randomized algorithm that guarantees a data dependent approximation factor.
9	RESULTS	Our experiments on three real data sets clearly verify the effectiveness and scalability of our method, as well as the advantage of our method against the other heuristic methods.
1	BACKGROUND	Breaking news leads to situations of fast-paced reporting in social media, producing all kinds of updates related to news stories, albeit with the caveat that some of those early updates tend to be rumours, i.e., information with an unverified status at the time of posting.
2	BACKGROUND	Flagging information that is unverified can be helpful to avoid the spread of information that may turn out to be false.
3	BACKGROUND	Detection of rumours can also feed a rumour tracking system that ultimately determines their veracity.
4	OBJECTIVE	In this paper we introduce a novel approach to rumour detection that learns from the sequential dynamics of reporting during breaking news in social media to detect rumours in new stories.
5	METHODS	Using Twitter datasets collected during five breaking news stories, we experiment with Conditional Random Fields as a sequential classifier that leverages context learnt during an event for rumour detection, which we compare with the state-of-the-art rumour detection system as well as other baselines.
6	METHODS	In contrast to existing work, our classifier does not need to observe tweets querying a piece of information to deem it a rumour, but instead we detect rumours from the tweet alone by exploiting context learnt during the event.
7	RESULTS	Our classifier achieves competitive performance, beating the state-of-the-art classifier that relies on querying tweets with improved precision and recall, as well as outperforming our best baseline with nearly 40% improvement in terms of F1 score.
8	CONCLUSIONS	The scale and diversity of our experiments reinforces the generalisability of our classifier.
1	BACKGROUND	With the rapid growth of social media, rumors are also spreading widely on social media and bring harm to people's daily life.
2	BACKGROUND	Nowadays, information credibility evaluation has drawn attention from academic and industrial communities.
3	BACKGROUND	Current methods mainly focus on feature engineering and achieve some success.
4	BACKGROUND	However, feature engineering based methods require a lot of labor and cannot fully reveal the underlying relations among data.
5	BACKGROUND	"In our viewpoint, the key elements of user behaviors for evaluating credibility are concluded as ""who"", ""what"", ""when"", and ""how""."
6	BACKGROUND	These existing methods cannot model the correlation among different key elements during the spreading of microblogs.
7	OBJECTIVE	In this paper, we propose a novel representation learning method, Information Credibility Evaluation (ICE), to learn representations of information credibility on social media.
8	METHODS	In ICE, latent representations are learnt for modeling user credibility, behavior types, temporal properties, and comment attitudes.
9	METHODS	The aggregation of these factors in the microblog spreading process yields the representation of a user's behavior, and the aggregation of these dynamic representations generates the credibility representation of an event spreading on social media.
10	METHODS	Moreover, a pairwise learning method is applied to maximize the credibility difference between rumors and non-rumors.
11	RESULTS	To evaluate the performance of ICE, we conduct experiments on a Sina Weibo data set, and the experimental results show that our ICE model outperforms the state-of-the-art methods.
1	BACKGROUND	Methods for detecting and summarizing emergent keywords have been extensively studied since social media and microblogging activities have started to play an important role in data analysis and decision making.
2	OBJECTIVE	We present a system for monitoring emergent keywords and summarizing a document stream based on the dynamic semantic graphs of streaming documents.
3	OBJECTIVE	We introduce the notion of dynamic eigenvector centrality for ranking emergent keywords, and present an algorithm for summarizing emergent events that is based on the minimum weight set cover.
4	METHODS	We demonstrate our system with an analysis of streaming Twitter data related to public security events.
1	BACKGROUND	Online extremists in social networks pose a new form of threat to the general public.
2	BACKGROUND	These extremists range from cyberbullies who harass innocent users to terrorist organizations such as the Islamic State of Iraq and Syria (ISIS) that use social networks to recruit and incite violence.
3	BACKGROUND	Currently social networks suspend the accounts of such extremists in response to user complaints.
4	BACKGROUND	The challenge is that these extremist users simply create new accounts and continue their activities.
5	OBJECTIVE	In this work we present a new set of operational capabilities to deal with the threat posed by online extremists in social networks.
6	METHODS	Using data from several hundred thousand extremist accounts on Twitter, we develop a behavioral model for these users, in particular what their accounts look like and who they connect with.
7	METHODS	This model is used to identify new extremist accounts by predicting if they will be suspended for extremist activity.
8	METHODS	We also use this model to track existing extremist users as they create new accounts by identifying if two accounts belong to the same user.
9	RESULTS	Finally, we present a model for searching the social network to efficiently find suspended users' new accounts based on a variant of the classic Polya's urn setup.
10	RESULTS	We find a simple characterization of the optimal search policy for this model under fairly general conditions.
11	RESULTS	Our urn model and main theoretical results generalize easily to search problems in other fields.
1	BACKGROUND	We present the Civique system for emergency detection in urban areas by monitoring micro blogs like Tweets.
2	OBJECTIVE	"The system detects emergency related events, and classifies them into appropriate categories like ""fire"", ""accident"", ""earthquake"", etc."
3	METHODS	We demonstrate our ideas by classifying Twitter posts in real time, visualizing the ongoing event on a map interface and alerting users with options to contact relevant authorities, both online and offline.
4	METHODS	We evaluate our classifiers for both the steps, i.e., emergency detection and categorization, and obtain F-scores exceeding 70% and 90%, respectively.
5	RESULTS	We demonstrate Civique using a web interface and on an Android application, in realtime, and show its use for both tweet detection and visualization.
1	BACKGROUND	Releasing connection data from social networking services can pose a significant threat to user privacy.
2	BACKGROUND	In our work, we consider structural social network de-anonymization attacks, which are used when a malicious party uses connections in a public or other identified network to re-identify users in an anonymized social network release that he obtained previously.
3	OBJECTIVE	In this paper we design and evaluate a novel social de-anonymization attack.
4	METHODS	In particular, we argue that the similarity function used to re-identify nodes is a key component of such attacks, and we design a novel measure tailored for social networks.
5	METHODS	We incorporate this measure in an attack called Bumblebee.
6	RESULTS	We evaluate Bumblebee in depth, and show that it significantly outperforms the state-of-the-art, for example it has higher re-identification rates with high precision, robustness against noise, and also has better error control.
1	BACKGROUND	Rumour stance classification, the task that determines if each tweet in a collection discussing a rumour is supporting, denying, questioning or simply commenting on the rumour, has been attracting substantial interest.
2	OBJECTIVE	Here we introduce a novel approach that makes use of the sequence of transitions observed in tree-structured conversation threads in Twitter.
3	BACKGROUND	The conversation threads are formed by harvesting users' replies to one another, which results in a nested tree-like structure.
4	BACKGROUND	Previous work addressing the stance classification task has treated each tweet as a separate unit.
5	METHODS	Here we analyse tweets by virtue of their position in a sequence and test two sequential classifiers, Linear-Chain CRF and Tree CRF, each of which makes different assumptions about the conversational structure.
6	METHODS	We experiment with eight Twitter datasets, collected during breaking news, and show that exploiting the sequential structure of Twitter conversations achieves significant improvements over the non-sequential methods.
7	BACKGROUND	Our work is the first to model Twitter conversations as a tree structure in this manner, introducing a novel way of tackling NLP tasks on Twitter conversations.
1	BACKGROUND	For many European countries, in 2015 the refugee situation developed from a remote tragedy reported upon in the news to a situation they have to deal with in their own neighborhood.
2	OBJECTIVE	Driven by this observation, we investigated the development of the perception of the refugee situation during 2015 in Twitter.
3	METHODS	Starting from a dataset of 1.7 Million tweets covering refugee-related topics from May to December 2015, we investigated how the discussion on refugees changed over time, in different countries as well as in relationship with the evolution of the actual situation.
4	RESULTS	In this paper we report and discuss our findings from checking a set of hypotheses, such as that the closeness to the actual situation would influence the intensity and polarity of discussions and that news media takes a mediating role between the actual and perceived refugee situation.
1	BACKGROUND	Online social networks represent a main source of communication and information exchange in today's life.
2	BACKGROUND	They facilitate exquisitely news sharing, knowledge elicitation, and forming groups of same interests.
3	BACKGROUND	Researchers in the last two decades studied the growth dynamics of the online social networks extensively questing a clear understanding of the behavior of humans in online social networks that helps in many directions, like engineering better recommendation systems and attracting new members.
4	BACKGROUND	However, not all of social networks achieved the desired growth, for example, online social networks like MySpace, Orkut, and Friendster are out of service today.
5	OBJECTIVE	In this work, we present a probabilistic theoretical model that captures the dynamics of the social decay due to the inactivity of the members of a social network.
6	RESULTS	The model is proved to have some interesting mathematical properties, namely \textit{submodularity}, which imply achieving the model optimization in a reasonable performance.
7	RESULTS	That means the maximization problem can be approximated within a factor of $(1-1/e)$ and the minimization problem can be achieved in polynomial time.
1	BACKGROUND	During natural or man-made disasters, humanitarian response organizations look for useful information to support their decision-making processes.
2	BACKGROUND	Social media platforms such as Twitter have been considered as a vital source of useful information for disaster response and management.
3	BACKGROUND	Despite advances in natural language processing techniques, processing short and informal Twitter messages is a challenging task.
4	OBJECTIVE	In this paper, we propose to use Deep Neural Network (DNN) to address two types of information needs of response organizations: 1) identifying informative tweets and 2) classifying them into topical classes.
5	OBJECTIVE	DNNs use distributed representation of words and learn the representation as well as higher level features automatically for the classification task.
6	OBJECTIVE	We propose a new online algorithm based on stochastic gradient descent to train DNNs in an online fashion during disaster situations.
7	METHODS	We test our models using a crisis-related real-world Twitter dataset.
1	OBJECTIVE	This paper develops an active sensing method to estimate the relative weight (or trust) agents place on their neighbors' information in a social network.
2	METHODS	The model used for the regression is based on the steady state equation in the linear DeGroot model under the influence of stubborn agents, i.e., agents whose opinions are not influenced by their neighbors.
3	METHODS	This method can be viewed as a \emph{social RADAR}, where the stubborn agents excite the system and the latter can be estimated through the reverberation observed from the analysis of the agents' opinions.
4	BACKGROUND	The social network sensing problem can be interpreted as a blind compressed sensing problem with a sparse measurement matrix.
5	CONCLUSIONS	We prove that the network structure will be revealed when a sufficient number of stubborn agents independently influence a number of ordinary (non-stubborn) agents.
6	METHODS	We investigate the scenario with a deterministic or randomized DeGroot model and propose a consistent estimator of the steady states for the latter scenario.
7	RESULTS	Simulation results on synthetic and real world networks support our findings.
1	BACKGROUND	Twitter data is extremely noisy -- each tweet is short, unstructured and with informal language, a challenge for current topic modeling.
2	BACKGROUND	On the other hand, tweets are accompanied by extra information such as authorship, hashtags and the user-follower network.
3	OBJECTIVE	Exploiting this additional information, we propose the Twitter-Network (TN) topic model to jointly model the text and the social network in a full Bayesian nonparametric way.
4	METHODS	The TN topic model employs the hierarchical Poisson-Dirichlet processes (PDP) for text modeling and a Gaussian process random function model for social network modeling.
5	RESULTS	We show that the TN topic model significantly outperforms several existing nonparametric models due to its flexibility.
6	RESULTS	Moreover, the TN topic model enables additional informative inference such as authors' interests, hashtag analysis, as well as leading to further applications such as author recommendation, automatic topic labeling and hashtag suggestion.
7	CONCLUSIONS	Note our general inference framework can readily be applied to other topic models with embedded PDP nodes.
1	BACKGROUND	First responders are increasingly using social media to identify and reduce crime for well-being and safety of the society.
2	BACKGROUND	Images shared on social media hurting religious, political, communal and other sentiments of people, often instigate violence and create law & order situations in society.
3	BACKGROUND	This results in the need for first responders to inspect the spread of such images and users propagating them on social media.
4	OBJECTIVE	In this paper, we present a comparison between different hand-crafted features and a Convolutional Neural Network (CNN) model to retrieve similar images, which outperforms state-of-art hand-crafted features.
5	OBJECTIVE	We propose an Open-Source-Intelligent (OSINT) real-time image search system, robust to retrieve modified images that allows first responders to analyze the current spread of images, sentiments floating and details of users propagating such content.
6	RESULTS	The system also aids officials to save time of manually analyzing the content by reducing the search space on an average by 67%.
1	BACKGROUND	Social media content shared today in cities, such as Instagram images, their tags and descriptions, is the key form of contemporary city life.
2	BACKGROUND	It tells people where activities and locations that interest them are and it allows them to share their urban experiences and self-representations.
3	BACKGROUND	Therefore, any analysis of urban structures and cultures needs to consider social media activity.
4	OBJECTIVE	In our paper, we introduce the novel concept of social media inequality.
5	BACKGROUND	This concept allows us to quantitatively compare patterns in social media activities between parts of a city, a number of cities, or any other spatial areas.
6	BACKGROUND	We define this concept using an analogy with the concept of economic inequality.
7	BACKGROUND	Economic inequality indicates how some economic characteristics or material resources, such as income, wealth or consumption are distributed in a city, country or between countries.
8	BACKGROUND	Accordingly, we can define social media inequality as the measure of the distribution of characteristics from social media content shared in a particular geographic area or between areas.
9	BACKGROUND	An example of such characteristics is the number of photos shared by all users of a social network such as Instagram in a given city or city area, or the content of these photos.
10	METHODS	We propose that the standard inequality measures used in other disciplines, such as the Gini coefficient, can also be used to characterize social media inequality.
11	METHODS	To test our ideas, we use a dataset of 7,442,454 public geo-coded Instagram images shared in Manhattan during five months (March-July) in 2014, and also selected data for 287 Census tracts in Manhattan.
12	METHODS	We compare patterns in Instagram sharing for locals and for visitors for all tracts, and also for hours in a 24-hour cycle.
13	METHODS	We also look at relations between social media inequality and socio-economic inequality using selected indicators for Census tracts.
1	BACKGROUND	Unlike many complex networks studied in the literature, social networks rarely exhibit unanimous behavior, or consensus.
2	BACKGROUND	This requires a development of mathematical models that are sufficiently simple to be examined and capture, at the same time, the complex behavior of real social groups, where opinions and actions related to them may form clusters of different size.
3	BACKGROUND	One such model, proposed by Friedkin and Johnsen, extends the idea of conventional consensus algorithm (also referred to as the iterative opinion pooling) to take into account the actors' prejudices, caused by some exogenous factors and leading to disagreement in the final opinions.
4	OBJECTIVE	In this paper, we offer a novel multidimensional extension, describing the evolution of the agents' opinions on several topics.
5	BACKGROUND	Unlike the existing models, these topics are interdependent, and hence the opinions being formed on these topics are also mutually dependent.
6	METHODS	We rigorous examine stability properties of the proposed model, in particular, convergence of the agents' opinions.
7	RESULTS	"Although our model assumes synchronous communication among the agents, we show that the same final opinions may be reached ""on average"" via asynchronous gossip-based protocols."
1	BACKGROUND	For a broad range of research, governmental and commercial applications it is important to understand the allegiances, communities and structure of key players in society.
2	BACKGROUND	One promising direction towards extracting this information is to exploit the rich relational data in digital social networks (the social graph).
3	BACKGROUND	As social media data sets are very large, most approaches make use of distributed computing systems for this purpose.
4	BACKGROUND	Distributing graph processing requires solving many difficult engineering problems, which has lead some researchers to look at single-machine solutions that are faster and easier to maintain.
5	OBJECTIVE	In this article, we present a single-machine real-time system for large-scale graph processing that allows analysts to interactively explore graph structures.
6	OBJECTIVE	The key idea is that the aggregate actions of large numbers of users can be compressed into a data structure that encapsulates user similarities while being robust to noise and queryable in real-time.
7	RESULTS	We achieve single machine real-time performance by compressing the neighbourhood of each vertex using minhash signatures and facilitate rapid queries through Locality Sensitive Hashing.
8	RESULTS	These techniques reduce query times from hours using industrial desktop machines operating on the full graph to milliseconds on standard laptops.
9	RESULTS	Our method allows exploration of strongly associated regions (i.e. communities) of large graphs in real-time on a laptop.
10	CONCLUSIONS	It has been deployed in software that is actively used by social network analysts and offers another channel for media owners to monetise their data, helping them to continue to provide free services that are valued by billions of people globally.
1	BACKGROUND	Mining topical experts on social media is a problem that has gained significant attention due to its wide-ranging applications.
2	OBJECTIVE	Here we present the first study that combines data from four major social networks -- Twitter, Facebook, Google+ and LinkedIn, along with the Wikipedia graph and internet webpage text and metadata, to rank topical experts across the global population of users.
3	METHODS	We perform an in-depth analysis of 37 features derived from various data sources such as message text, user lists, webpages, social graphs and wikipedia.
4	METHODS	This large-scale study includes more than 12 billion messages over a 90-day sliding window and 58 billion social graph edges.
5	RESULTS	Comparison reveals that features derived from Twitter Lists, Wikipedia, internet webpages and Twitter Followers are especially good indicators of expertise.
6	METHODS	We train an expertise ranking model using these features on a large ground truth dataset containing almost 90,000 labels.
7	METHODS	This model is applied within a production system that ranks over 650 million experts in more than 9,000 topical domains on a daily basis.
8	METHODS	We provide results and examples on the effectiveness of our expert ranking system, along with empirical validation.
9	METHODS	Finally, we make the topical expertise data available through open REST APIs for wider use.
1	BACKGROUND	Though dialectal language is increasingly abundant on social media, few resources exist for developing NLP tools to handle such language.
2	OBJECTIVE	We conduct a case study of dialectal language in online conversational text by investigating African-American English (AAE) on Twitter.
3	METHODS	We propose a distantly supervised model to identify AAE-like language from demographics associated with geo-located messages, and we verify that this language follows well-known AAE linguistic phenomena.
4	METHODS	In addition, we analyze the quality of existing language identification and dependency parsing tools on AAE-like text, demonstrating that they perform poorly on such text compared to text associated with white speakers.
5	METHODS	We also provide an ensemble classifier for language identification which eliminates this disparity and release a new corpus of tweets containing AAE-like language.
1	OBJECTIVE	We present a dictionary-based approach to racism detection in Dutch social media comments, which were retrieved from two public Belgian social media sites likely to attract racist reactions.
2	METHODS	These comments were labeled as racist or non-racist by multiple annotators.
3	METHODS	For our approach, three discourse dictionaries were created: first, we created a dictionary by retrieving possibly racist and more neutral terms from the training data, and then augmenting these with more general words to remove some bias.
4	METHODS	A second dictionary was created through automatic expansion using a \texttt{word2vec} model trained on a large corpus of general Dutch text.
5	METHODS	Finally, a third dictionary was created by manually filtering out incorrect expansions.
6	METHODS	We trained multiple Support Vector Machines, using the distribution of words over the different categories in the dictionaries as features.
7	RESULTS	The best-performing model used the manually cleaned dictionary and obtained an F-score of 0.46 for the racist class on a test set consisting of unseen Dutch comments, retrieved from the same sites used for the training set.
8	RESULTS	The automated expansion of the dictionary only slightly boosted the model's performance, and this increase in performance was not statistically significant.
9	RESULTS	The fact that the coverage of the expanded dictionaries did increase indicates that the words that were automatically added did occur in the corpus, but were not able to meaningfully impact performance.
10	RESULTS	The dictionaries, code, and the procedure for requesting the corpus are available at: https://github.com/clips/hades
1	BACKGROUND	With the constant growth of the World Wide Web and the number of documents in different languages accordingly, the need for reliable language detection tools has increased as well.
2	BACKGROUND	Platforms such as Twitter with predominantly short texts are becoming important information resources, which additionally imposes the need for short texts language detection algorithms.
3	OBJECTIVE	In this paper, we show how incorporating personalized user-specific information into the language detection algorithm leads to an important improvement of detection results.
4	METHODS	To choose the best algorithm for language detection for short text messages, we investigate several machine learning approaches.
5	METHODS	These approaches include the use of the well-known classifiers such as SVM and logistic regression, a dictionary based approach, and a probabilistic model based on modified Kneser-Ney smoothing.
6	METHODS	Furthermore, the extension of the probabilistic model to include additional user-specific information such as evidence accumulation per user and user interface language is explored, with the goal of improving the classification performance.
7	METHODS	The proposed approaches are evaluated on randomly collected Twitter data containing Latin as well as non-Latin alphabet languages and the quality of the obtained results is compared, followed by the selection of the best performing algorithm.
8	METHODS	This algorithm is then evaluated against two already existing general language detection tools: Chromium Compact Language Detector 2 (CLD2) and langid, where our method significantly outperforms the results achieved by both of the mentioned methods.
9	METHODS	Additionally, a preview of benefits and possible applications of having a reliable language detection algorithm is given.
1	BACKGROUND	In our paper we would like to make a cross-disciplinary leap and use the tools of network theory to understand and explore narrative structure in literary fiction, an approach that is still underestimated.
2	BACKGROUND	However, the systems in fiction are sensitive to readers subjectivity and attention must to be paid to different methods of extracting networks.
3	OBJECTIVE	The project aims at investigating into different ways social interactions are read in texts by comparing networks produced by automated algorithms-natural language processing with those created by surveying more subjective human responses.
4	BACKGROUND	Conversation networks from fiction have been already extracted by scientists, but the more general framework surrounding these interactions was missing.
5	OBJECTIVE	We propose several NLP methods for detecting interactions and test them against a range of human perceptions.
6	RESULTS	In doing so, we have pointed to some limitations of using network analysis to test literary theory, e.g. interaction, which corresponds to the plot, does not form climax.
1	OBJECTIVE	The study explores whether the use of Twitter in Massive Open Online Courses (MOOCs) promotes the interaction among learners.
2	RESULTS	The social network analysis shows that instructors still play a very central role in the social media communication and the communication network between students shrinking over time.
3	METHODS	The mere use of social media fails to promote learner-learner interaction.
4	CONCLUSIONS	More research is needed for understanding learner motivation and how instructional design can help increase their engagement and participation.
1	BACKGROUND	'Health utilities' measure patient preferences for perfect health compared to specific unhealthy states, such as asthma, a fractured hip, or colon cancer.
2	BACKGROUND	When integrated over time, these estimations are called quality adjusted life years (QALYs).
3	BACKGROUND	Until now, characterizing health utilities (HUs) required detailed patient interviews or written surveys.
4	BACKGROUND	While reliable and specific, this data remained costly due to efforts to locate, enlist and coordinate participants.
5	BACKGROUND	Thus the scope, context and temporality of diseases examined has remained limited.
6	OBJECTIVE	Now that more than a billion people use social media, we propose a novel strategy: use natural language processing to analyze public online conversations for signals of the severity of medical conditions and correlate these to known HUs using machine learning.
7	METHODS	In this work, we filter a dataset that originally contained 2 billion tweets for relevant content on 60 diseases.
8	RESULTS	Using this data, our algorithm successfully distinguished mild from severe diseases, which had previously been categorized only by traditional techniques.
9	CONCLUSIONS	This represents progress towards two related applications: first, predicting HUs where such information is nonexistent; and second, (where rich HU data already exists) estimating temporal or geographic patterns of disease severity through data mining.
1	BACKGROUND	The role of social media, in particular microblogging platforms such as Twitter, as a conduit for actionable and tactical information during disasters is increasingly acknowledged.
2	BACKGROUND	However, time-critical analysis of big crisis data on social media streams brings challenges to machine learning techniques, especially the ones that use supervised learning.
3	BACKGROUND	The Scarcity of labeled data, particularly in the early hours of a crisis, delays the machine learning process.
4	BACKGROUND	The current state-of-the-art classification methods require a significant amount of labeled data specific to a particular event for training plus a lot of feature engineering to achieve best results.
5	OBJECTIVE	In this work, we introduce neural network based classification methods for binary and multi-class tweet classification task.
6	RESULTS	We show that neural network based models do not require any feature engineering and perform better than state-of-the-art methods.
7	RESULTS	In the early hours of a disaster when no labeled data is available, our proposed method makes the best use of the out-of-event data and achieves good results.
1	OBJECTIVE	In the present work, we study the advertising competition of several marketing campaigns who need to determine how many resources to allocate to potential customers to advertise their products through direct marketing while taking into account that competing marketing campaigns are trying to do the same.
2	BACKGROUND	Potential customers rank marketing campaigns according to the offers, promotions or discounts made to them.
3	METHODS	Taking into account the intrinsic value of potential customers as well as the peer influence that they exert over other potential customers we consider the network value as a measure of their importance in the market and we find an analytical expression for it.
4	METHODS	We analyze the marketing campaigns competition from a game theory point of view, finding a closed form expression of the symmetric equilibrium offer strategy for the marketing campaigns from which no campaign has any incentive to deviate.
5	METHODS	We also present several scenarios, such as Winner-takes-all and Borda, but not the only possible ones for which our results allow us to retrieve in a simple way the corresponding equilibrium strategy.
1	BACKGROUND	When a piece of information (microblog, photograph, video, link, etc.) starts to spread in a social network, an important question arises: will it spread to viral proportions - where viral can be defined as an order-of-magnitude increase.
2	BACKGROUND	However, several previous studies have established that cascade size and frequency are related through a power-law - which leads to a severe imbalance in this classification problem.
3	OBJECTIVE	In this paper, we devise a suite of measurements based on structural diversity - the variety of social contexts (communities) in which individuals partaking in a given cascade engage.
4	RESULTS	We demonstrate these measures are able to distinguish viral from non-viral cascades, despite the severe imbalance of the data for this problem.
5	RESULTS	Further, we leverage these measurements as features in a classification approach, successfully predicting microblogs that grow from 50 to 500 reposts with precision of 0.69 and recall of 0.52 for the viral class - despite this class comprising under 2% of samples.
6	RESULTS	This significantly outperforms our baseline approach as well as the current state-of-the-art.
7	RESULTS	We also show this approach also performs well for identifying if cascades observed for 60 minutes will grow to 500 reposts as well as demonstrate how we can tradeoff between precision and recall.
1	BACKGROUND	The challenge of associating entities across multiple domains is a key problem in social media understanding.
2	BACKGROUND	Successful cross-domain entity resolution provides integration of information from multiple sites to create a complete picture of user and community activities, characteristics, and trends.
3	OBJECTIVE	In this work, we examine the problem of entity resolution across Twitter and Instagram using general techniques.
4	METHODS	Our methods fall into three categories: profile, content, and graph based.
5	METHODS	For the profile-based methods, we consider techniques based on approximate string matching.
6	METHODS	For content-based methods, we perform author identification.
7	METHODS	Finally, for graph-based methods, we apply novel cross-domain community detection methods and generate neighborhood-based features.
8	METHODS	The three categories of methods are applied to a large graph of users in Twitter and Instagram to understand challenges, determine performance, and understand fusion of multiple methods.
9	RESULTS	Final results demonstrate an equal error rate less than 1%.
1	BACKGROUND	The discovery of community structure in networks is a problem of considerable interest in recent years.
2	BACKGROUND	In online social networks, often times, users are simultaneously involved in multiple social media sites, some of which share common social relationships.
3	BACKGROUND	It is of great interest to uncover a shared community structure across these networks.
4	BACKGROUND	However, in reality, users typically identify themselves with different usernames across social media sites.
5	BACKGROUND	This creates a great difficulty in detecting the community structure.
6	OBJECTIVE	In this paper, we explore several approaches for community detection across online social networks with limited knowledge of username alignment across the networks.
7	METHODS	We refer to the known alignment of usernames as seeds.
8	METHODS	We investigate strategies for seed selection and its impact on networks with a different fraction of overlapping vertices.
9	METHODS	The goal is to study the interplay between network topologies and seed selection strategies, and to understand how it affects the detected community structure.
10	METHODS	We also propose several measures to assess the performance of community detection and use them to measure the quality of the detected communities in both Twitter-Twitter networks and Twitter-Instagram networks.
1	BACKGROUND	Scholarly articles are discussed and shared on social media, which generates altmetrics.
2	BACKGROUND	On the opposite side, what is the impact of social media on the dissemination of scholarly articles and how to measure it?
3	BACKGROUND	What are the visiting patterns?
4	OBJECTIVE	Investigating these issues, the purpose of this study is to seek a solution to fill the research gap, specifically, to explore the dynamic visiting patterns directed by social media, and examine the effects of social buzz on the article visits.
5	METHODS	Using the unique real referral data of 110 scholarly articles, which are daily updated in a 90-day period, this paper proposes a novel method to make analysis.
6	RESULTS	We find that visits from social media are fast to accumulate but decay rapidly.
7	RESULTS	Twitter and Facebook are the two most important social referrals that directing people to scholarly articles, the two are about the same and account for over 95% of the total social referral directed visits.
8	RESULTS	There is synchronism between tweets and tweets resulted visits.
9	CONCLUSIONS	Social media and open access are playing important roles in disseminating scholarly articles and promoting public understanding science, which are confirmed quantitatively for the first time with real data in this study.
1	BACKGROUND	The Internet and social media have fueled enormous interest in social network analysis.
2	BACKGROUND	New tools continue to be developed and used to analyse our personal connections, with particular emphasis on detecting communities or identifying key individuals in a social network.
3	BACKGROUND	This raises privacy concerns that are likely to exacerbate in the future.
4	OBJECTIVE	With this in mind, we ask the question: Can individuals or groups actively manage their connections to evade social network analysis tools?
5	BACKGROUND	By addressing this question, the general public may better protect their privacy, oppressed activist groups may better conceal their existence, and security agencies may better understand how terrorists escape detection.
6	METHODS	"We first study how an individual can evade ""network centrality"" analysis without compromising his or her influence within the network."
7	RESULTS	We prove that an optimal solution to this problem is hard to compute.
8	RESULTS	Despite this hardness, we demonstrate that even a simple heuristic, whereby attention is restricted to the individual's immediate neighbourhood, can be surprisingly effective in practice.
9	RESULTS	For instance, it could disguise Mohamed Atta's leading position within the WTC terrorist network, and that is by rewiring a strikingly-small number of connections.
10	OBJECTIVE	Next, we study how a community can increase the likelihood of being overlooked by community-detection algorithms.
11	OBJECTIVE	"We propose a measure of concealment, expressing how well a community is hidden, and use it to demonstrate the effectiveness of a simple heuristic, whereby members of the community either ""unfriend"" certain other members, or ""befriend"" some non-members, in a coordinated effort to camouflage their community."
1	BACKGROUND	People usually get involved in multiple social networks to enjoy new services or to fulfill their needs.
2	BACKGROUND	Many new social networks try to attract users of other existing networks to increase the number of their users.
3	BACKGROUND	Once a user (called source user) of a social network (called source network) joins a new social network (called target network), a new inter-network link (called anchor link) is formed between the source and target networks.
4	OBJECTIVE	In this paper, we concentrated on predicting the formation of such anchor links between heterogeneous social networks.
5	BACKGROUND	Unlike conventional link prediction problems in which the formation of a link between two existing users within a single network is predicted, in anchor link prediction, the target user is missing and will be added to the target network once the anchor link is created.
6	METHODS	To solve this problem, we use meta-paths as a powerful tool for utilizing heterogeneous information in both the source and target networks.
7	OBJECTIVE	To this end, we propose an effective general meta-path-based approach called Connector and Recursive Meta-Paths (CRMP).
8	METHODS	By using those two different categories of meta-paths, we model different aspects of social factors that may affect a source user to join the target network, resulting in the formation of a new anchor link.
9	RESULTS	Extensive experiments on real-world heterogeneous social networks demonstrate the effectiveness of the proposed method against the recent methods.
1	BACKGROUND	Anomalies in online social networks can signify irregular, and often illegal behaviour.
2	BACKGROUND	Anomalies in online social networks can signify irregular, and often illegal behaviour.
3	BACKGROUND	Detection of such anomalies has been used to identify malicious individuals, including spammers, sexual predators, and online fraudsters.
4	OBJECTIVE	In this paper we survey existing computational techniques for detecting anomalies in online social networks.
5	METHODS	We characterise anomalies as being either static or dynamic, and as being labelled or unlabelled, and survey methods for detecting these different types of anomalies.
6	METHODS	We suggest that the detection of anomalies in online social networks is composed of two sub-processes; the selection and calculation of network features, and the classification of observations from this feature space.
7	RESULTS	In addition, this paper provides an overview of the types of problems that anomaly detection can address and identifies key areas of future research.
1	BACKGROUND	As we shift more of our lives into the virtual domain, the volume of data shared on the web keeps increasing and presents a threat to our privacy.
2	OBJECTIVE	This works contributes to the understanding of privacy implications of such data sharing by analysing how well people are recognisable in social media data.
3	METHODS	To facilitate a systematic study we define a number of scenarios considering factors such as how many heads of a person are tagged and if those heads are obfuscated or not.
4	METHODS	We propose a robust person recognition system that can handle large variations in pose and clothing, and can be trained with few training samples.
5	RESULTS	Our results indicate that a handful of images is enough to threaten users' privacy, even in the presence of obfuscation.
6	RESULTS	We show detailed experimental results, and discuss their implications.
1	BACKGROUND	The serious privacy and security problems related to online social networks (OSNs) are what fueled two complementary studies as part of this thesis.
2	OBJECTIVE	In the first study, we developed a general algorithm for the mining of data of targeted organizations by using Facebook (currently the most popular OSN) and socialbots.
3	RESULTS	By friending employees in a targeted organization, our active socialbots were able to find new employees and informal organizational links that we could not find by crawling with passive socialbots.
4	METHODS	We evaluated our method on the Facebook OSN and were able to reconstruct the social networks of employees in three distinct, actual organizations.
5	RESULTS	Furthermore, in the crawling process with our active socialbots we discovered up to 13.55% more employees and 22.27% more informal organizational links in contrast to the crawling process that was performed by passive socialbots with no company associations as friends.
6	METHODS	In our second study, we developed a general algorithm for reaching specific OSN users who declared themselves to be employees of targeted organizations, using the topologies of organizational social networks and utilizing socialbots.
7	METHODS	We evaluated the proposed method on targeted users from three actual organizations on Facebook, and two actual organizations on the Xing OSN (another popular OSN platform).
8	RESULTS	Eventually, our socialbots were able to reach specific users with a success rate of up to 70% on Facebook, and up to 60% on Xing.
1	BACKGROUND	The proliferation of Internet-enabled devices and services has led to a shifting balance between digital and analogue aspects of our everyday lives.
2	BACKGROUND	In the face of this development there is a growing demand for the study of privacy hazards, the potential for unique user de-anonymization and information leakage between the various social media profiles many of us maintain.
3	OBJECTIVE	To enable the structured study of such adversarial effects, this paper presents a dedicated dataset of cross-platform social network personas (i.e., the same person has accounts on multiple platforms).
4	METHODS	The corpus comprises 850 users who generate predominantly English content.
5	METHODS	Each user object contains the online footprint of the same person in three distinct social networks: Twitter, Instagram and Foursquare.
6	METHODS	In total, it encompasses over 2.5M tweets, 340k check-ins and 42k Instagram posts.
7	METHODS	We describe the collection methodology, characteristics of the dataset, and how to obtain it.
8	METHODS	Finally, we discuss a common use case, cross-platform user identification.
1	OBJECTIVE	We consider a collaborative online learning paradigm, wherein a group of agents connected through a social network are engaged in playing a stochastic multi-armed bandit game.
2	METHODS	Each time an agent takes an action, the corresponding reward is instantaneously observed by the agent, as well as its neighbours in the social network.
3	METHODS	We perform a regret analysis of various policies in this collaborative learning setting.
4	RESULTS	A key finding of this paper is that natural extensions of widely-studied single agent learning policies to the network setting need not perform well in terms of regret.
5	RESULTS	In particular, we identify a class of non-altruistic and individually consistent policies, and argue by deriving regret lower bounds that they are liable to suffer a large regret in the networked setting.
6	RESULTS	We also show that the learning performance can be substantially improved if the agents exploit the structure of the network, and develop a simple learning algorithm based on dominating sets of the network.
7	METHODS	Specifically, we first consider a star network, which is a common motif in hierarchical social networks, and show analytically that the hub agent can be used as an information sink to expedite learning and improve the overall regret.
8	METHODS	We also derive networkwide regret bounds for the algorithm applied to general networks.
9	METHODS	We conduct numerical experiments on a variety of networks to corroborate our analytical results.
1	BACKGROUND	Threshold graphs are recursive deterministic network models that capture properties of social and economic interactions.
2	BACKGROUND	One drawback of these graph families is that they have limited constrained generative attachment rules.
3	OBJECTIVE	To mitigate this problem, we introduce a new class of graphs termed Doubly Threshold (DT) graphs which may be succinctly described through vertex weights that govern the existence of edges via two inequalities.
4	METHODS	One inequality imposes the constraint that the sum of weights of adjacent vertices has to exceed a specified threshold.
5	METHODS	The second inequality ensures that adjacent vertices have a bounded difference of their weights.
6	METHODS	We provide a conceptually simple characterization and decomposition of DT graphs and analyze their forbidden induced subgraphs which we compare to those of prototypical social networks.
7	METHODS	We also present a method for performing vertex weight assignments on DT graphs that satisfy the defining constraints and conclude our exposition with an analysis of the intersection number, diameter and clustering coefficient of DT graphs.
1	OBJECTIVE	We introduce a deep neural network for automated sarcasm detection.
2	BACKGROUND	Recent work has emphasized the need for models to capitalize on contextual features, beyond lexical and syntactic cues present in utterances.
3	BACKGROUND	For example, different speakers will tend to employ sarcasm regarding different subjects and, thus, sarcasm detection models ought to encode such speaker information.
4	BACKGROUND	Current methods have achieved this by way of laborious feature engineering.
5	METHODS	By contrast, we propose to automatically learn and then exploit user embeddings, to be used in concert with lexical signals to recognize sarcasm.
6	RESULTS	Our approach does not require elaborate feature engineering (and concomitant data scraping); fitting user embeddings requires only the text from their previous posts.
7	RESULTS	The experimental results show that our model outperforms a state-of-the-art approach leveraging an extensive set of carefully crafted features.
1	BACKGROUND	Computer systems need to be able to react to stress in order to perform optimally on some tasks.
2	OBJECTIVE	This article describes TensiStrength, a system to detect the strength of stress and relaxation expressed in social media text messages.
3	METHODS	TensiStrength uses a lexical approach and a set of rules to detect direct and indirect expressions of stress or relaxation, particularly in the context of transportation.
4	RESULTS	It is slightly more effective than a comparable sentiment analysis program, although their similar performances occur despite differences on almost half of the tweets gathered.
5	RESULTS	The effectiveness of TensiStrength depends on the nature of the tweets classified, with tweets that are rich in stress-related terms being particularly problematic.
6	RESULTS	Although generic machine learning methods can give better performance than TensiStrength overall, they exploit topic-related terms in a way that may be undesirable in practical applications and that may not work as well in more focused contexts.
7	CONCLUSIONS	In conclusion, TensiStrength and generic machine learning approaches work well enough to be practical choices for intelligent applications that need to take advantage of stress information, and the decision about which to use depends on the nature of the texts analysed and the purpose of the task.
1	BACKGROUND	In online social networks (OSN), users quite usually disclose sensitive information about themselves by publishing messages.
2	BACKGROUND	At the same time, they are (in many cases) unable to properly manage the access to this sensitive information due to the following issues: i) the rigidness of the access control mechanism implemented by the OSN, and ii) many users lack of technical knowledge about data privacy and access control.
3	OBJECTIVE	To tackle these limitations, in this paper, we propose a dynamic, transparent and privacy-driven access control mechanism for textual messages published in OSNs.
4	METHODS	The notion of privacy-driven is achieved by analyzing the semantics of the messages to be published and, according to that, assessing the degree of sensitiveness of their contents.
5	METHODS	For this purpose, the proposed system relies on an automatic semantic annotation mechanism that, by using knowledge bases and linguistic tools, is able to associate a meaning to the information to be published.
6	METHODS	By means of this annotation, our mechanism automatically detects the information that is sensitive according to the privacy requirements of the publisher of data, with regard to the type of reader that may access such data.
7	METHODS	Finally, our access control mechanism automatically creates sanitized versions of the users' publications according to the type of reader that accesses them.
8	RESULTS	As a result, our proposal, which can be integrated in already existing social networks, provides an automatic, seamless and content-driven protection of user publications, which are coherent with her privacy requirements and the type of readers that access them.
9	CONCLUSIONS	Complementary to the system design, we also discuss the feasibility of the system by illustrating it through a real example and evaluate its accuracy and effectiveness over standard approaches.
1	BACKGROUND	Traditional viral marketing problems aim at selecting a subset of seed users for one single product to maximize its awareness in social networks.
2	BACKGROUND	However, in real scenarios, multiple products can be promoted in social networks at the same time.
3	BACKGROUND	At the product level, the relationships among these products can be quite intertwined, e.g., competing, complementary and independent.
4	OBJECTIVE	"In this paper, we will study the ""interTwined Influence Maximization"" (i.e., TIM) problem for one product that we target on in online social networks, where multiple other competing/complementary/independent products are being promoted simultaneously."
5	BACKGROUND	The TIM problem is very challenging to solve due to (1) few existing models can handle the intertwined diffusion procedure of multiple products concurrently, and (2) optimal seed user selection for the target product may depend on other products' marketing strategies a lot.
6	OBJECTIVE	To address the TIM problem, a unified greedy framework TIER (interTwined Influence EstimatoR) is proposed in this paper.
7	RESULTS	Extensive experiments conducted on four different types of real-world social networks demonstrate that TIER can outperform all the comparison methods with significant advantages in solving the TIM problem.
1	OBJECTIVE	In this paper we present a SOA (Service Oriented Architecture)-based platform, enabling the retrieval and analysis of big datasets stemming from social networking (SN) sites and Internet of Things (IoT) devices, collected by smart city applications and socially-aware data aggregation services.
2	BACKGROUND	A large set of city applications in the areas of Participating Urbanism, Augmented Reality and Sound-Mapping throughout participating cities is being applied, resulting into produced sets of millions of user-generated events and online SN reports fed into the RADICAL platform.
3	OBJECTIVE	Moreover, we study the application of data analytics such as sentiment analysis to the combined IoT and SN data saved into an SQL database, further investigating algorithmic and configurations to minimize delays in dataset processing and results retrieval.
1	BACKGROUND	STEM (Science, Technology, Engineering, and Mathematics) fields have become increasingly central to U.S. economic competitiveness and growth.
2	BACKGROUND	The shortage in the STEM workforce has brought promoting STEM education upfront.
3	BACKGROUND	The rapid growth of social media usage provides a unique opportunity to predict users' real-life identities and interests from online texts and photos.
4	OBJECTIVE	In this paper, we propose an innovative approach by leveraging social media to promote STEM education: matching Twitter college student users with diverse LinkedIn STEM professionals using a ranking algorithm based on the similarities of their demographics and interests.
5	BACKGROUND	We share the belief that increasing STEM presence in the form of introducing career role models who share similar interests and demographics will inspire students to develop interests in STEM related fields and emulate their models.
6	METHODS	Our evaluation on 2,000 real college students demonstrated the accuracy of our ranking algorithm.
7	OBJECTIVE	We also design a novel implementation that recommends matched role models to the students.
1	BACKGROUND	Recently in Online Social Networks (OSNs), the Least Cost Influence (LCI) problem has become one of the central research topics.
2	BACKGROUND	It aims at identifying a minimum number of seed users who can trigger a wide cascade of information propagation.
3	BACKGROUND	Most of existing literature investigated the LCI problem only based on an individual network.
4	BACKGROUND	However, nowadays users often join several OSNs such that information could be spread across different networks simultaneously.
5	BACKGROUND	Therefore, in order to obtain the best set of seed users, it is crucial to consider the role of overlapping users under this circumstances.
6	OBJECTIVE	In this article, we propose a unified framework to represent and analyze the influence diffusion in multiplex networks.
7	METHODS	More specifically, we tackle the LCI problem by mapping a set of networks into a single one via lossless and lossy coupling schemes.
8	METHODS	The lossless coupling scheme preserves all properties of original networks to achieve high quality solutions, while the lossy coupling scheme offers an attractive alternative when the running time and memory consumption are of primary concern.
9	RESULTS	Various experiments conducted on both real and synthesized datasets have validated the effectiveness of the coupling schemes, which also provide some interesting insights into the process of influence propagation in multiplex networks.
1	OBJECTIVE	In this paper, we investigate the discount allocation problem in social networks.
2	BACKGROUND	It has been reported that 40\% of consumers will share an email offer with their friend and 28\% of consumers will share deals via social media platforms.
3	BACKGROUND	What does this mean for a business?
4	BACKGROUND	Essentially discounts should not just be treated as short term solutions to attract individual customer, instead, allocating discounts to a small fraction of users (called seed users) may trigger a large cascade in a social network.
5	BACKGROUND	This motivates us to study the influence maximization discount allocation problem: given a social network and budget, we need to decide to which initial set users should offer the discounts, and how much should the discounts be worth.
6	OBJECTIVE	Our goal is to maximize the number of customers who finally adopt the target product.
7	METHODS	We investigate this problem under both non-adaptive and adaptive settings.
8	METHODS	In the first setting, we have to commit the set of seed users and corresponding discounts all at once in advance.
9	METHODS	In the latter case, the decision process is performed in a sequential manner, and each seed user that is picked provides the feedback on the discount, or, in other words, reveals whether or not she will adopt the discount.
10	METHODS	We propose a simple greedy policy with an approximation ratio of $\frac{1}{2}(1 - 1/e)$ in non-adaptive setting.
11	METHODS	For the significantly more complex adaptive setting, we propose an adaptive greedy policy with bounded approximation ratio in terms of expected utility.
1	OBJECTIVE	We study a revenue maximization problem in the context of social networks.
2	METHODS	Namely, we consider a model introduced by Alon, Mansour, and Tennenholtz (EC 2013) that captures inequity aversion, i.e., prices offered to neighboring vertices should not be significantly different.
3	METHODS	We first provide approximation algorithms for a natural class of instances, referred to as the class of single-value revenue functions.
4	RESULTS	Our results improve on the current state of the art, especially when the number of distinct prices is small.
5	RESULTS	This applies, for example, to settings where the seller will only consider a fixed number of discount types or special offers.
6	RESULTS	We then resolve one of the open questions posed in Alon et al., by establishing APX-hardness for the problem.
7	RESULTS	Surprisingly, we further show that the problem is NP-complete even when the price differences are allowed to be relatively large.
8	RESULTS	Finally, we also provide some extensions of the model of Alon et al., regarding either the allowed set of prices, or the demand type of the clients.
1	BACKGROUND	Many real-world relations can be represented by signed networks with positive and negative links, as a result of which signed network analysis has attracted increasing attention from multiple disciplines.
2	BACKGROUND	With the increasing prevalence of social media networks, signed network analysis has evolved from developing and measuring theories to mining tasks.
3	OBJECTIVE	In this article, we present a review of mining signed networks in the context of social media and discuss some promising research directions and new frontiers.
4	METHODS	We begin by giving basic concepts and unique properties and principles of signed networks.
5	METHODS	Then we classify and review tasks of signed network mining with representative algorithms.
6	METHODS	We also delineate some tasks that have not been extensively studied with formal definitions and also propose research directions to expand the field of signed network mining.
1	BACKGROUND	Campaigners are increasingly using online social networking platforms for promoting products, ideas and information.
2	BACKGROUND	A popular method of promoting a product or even an idea is incentivizing individuals to evangelize the idea vigorously by providing them with referral rewards in the form of discounts, cash backs, or social recognition.
3	BACKGROUND	Due to budget constraints on scarce resources such as money and manpower, it may not be possible to provide incentives for the entire population, and hence incentives need to be allocated judiciously to appropriate individuals for ensuring the highest possible outreach size.
4	OBJECTIVE	We aim to do the same by formulating and solving an optimization problem using percolation theory.
5	METHODS	In particular, we compute the set of individuals that are provided incentives for minimizing the expected cost while ensuring a given outreach size.
6	METHODS	We also solve the problem of computing the set of individuals to be incentivized for maximizing the outreach size for given cost budget.
7	RESULTS	The optimization problem turns out to be non trivial; it involves quantities that need to be computed by numerically solving a fixed point equation.
8	RESULTS	Our primary contribution is, that for a fairly general cost structure, we show that the optimization problems can be solved by solving a simple linear program.
9	CONCLUSIONS	We believe that our approach of using percolation theory to formulate an optimization problem is the first of its kind.
1	BACKGROUND	Campaigners, advertisers and activists are increasingly turning to social recommendation mechanisms, provided by social media, for promoting their products, services, brands and even ideas.
2	BACKGROUND	However, many times, such social network based campaigns perform poorly in practice because the intensity of the recommendations drastically reduces beyond a few hops from the source.
3	BACKGROUND	A natural strategy for maintaining the intensity is to provide incentives.
4	OBJECTIVE	In this paper, we address the problem of minimizing the cost incurred by the campaigner for incentivizing a fraction of individuals in the social network, while ensuring that the campaign message reaches a given expected fraction of individuals.
5	OBJECTIVE	We also address the dual problem of maximizing the campaign penetration for a resource constrained campaigner.
6	METHODS	To help us understand and solve the above mentioned problems, we use percolation theory to formally state them as optimization problems.
7	METHODS	These problems are not amenable to traditional approaches because of a fixed point equation that needs to be solved numerically.
8	METHODS	However, we use results from reliability theory to establish some key properties of the fixed point, which in turn enables us to solve these problems using algorithms that are linearithmic in maximum node degree.
9	METHODS	Furthermore, we evaluate the efficacy of the analytical solution by performing simulations on real world networks.
1	OBJECTIVE	We consider the problem of how to optimize multi-stage campaigning over social networks.
2	METHODS	The dynamic programming framework is employed to balance the high present reward and large penalty on low future outcome in the presence of extensive uncertainties.
3	METHODS	In particular, we establish theoretical foundations of optimal campaigning over social networks where the user activities are modeled as a multivariate Hawkes process, and we derive a time dependent linear relation between the intensity of exogenous events and several commonly used objective functions of campaigning.
4	METHODS	We further develop a convex dynamic programming framework for determining the optimal intervention policy that prescribes the required level of external drive at each stage for the desired campaigning result.
5	RESULTS	Experiments on both synthetic data and the real-world MemeTracker dataset show that our algorithm can steer the user activities for optimal campaigning much more accurately than baselines.
1	BACKGROUND	Broadband internet access is a major enabling technology for building social capital (SC) by better connecting rural and regional communities which are often geographically dispersed both locally nationally and internationally.
2	OBJECTIVE	The main objectives of this paper were determine to what extent Social Networking Sites (SNS) can build SC for households in a rural and regional context of rural household adoption and use of broadband internet.
3	METHODS	A large scale survey of households was used to collect empirical data regarding household adoption and use of Broadband internet services including SNSs and their contribution to building SC in rural communities.
4	RESULTS	The results of this study confirmed that SNSs would appear to build SC two high level dimensions bonding and bridging for households in rural communities such as Western Downs Region.
5	RESULTS	Moreover SNS users would appear to have significantly higher levels of SC than Non-SNS users in rural communities.
1	BACKGROUND	Spammer detection on social network is a challenging problem.
2	BACKGROUND	"The rigid anti-spam rules have resulted in emergence of ""smart"" spammers."
3	BACKGROUND	They resemble legitimate users who are difficult to identify.
4	OBJECTIVE	In this paper, we present a novel spammer classification approach based on Latent Dirichlet Allocation(LDA), a topic model.
5	METHODS	Our approach extracts both the local and the global information of topic distribution patterns, which capture the essence of spamming.
6	RESULTS	Tested on one benchmark dataset and one self-collected dataset, our proposed method outperforms other state-of-the-art methods in terms of averaged F1-score.
1	OBJECTIVE	We consider the problem of modeling competitive diffusion in real world social networks via the notion of ChoiceGAPs which combine choice logic programs due to Sacca` and Zaniolo and Generalized Annotated Programs due to Kifer and Subrahmanian.
2	METHODS	We assume that each vertex in a social network is a player in a multi-player game (with a huge number of players) - the choice part of the ChoiceGAPs describe utilities of players for acting in various ways based on utilities of their neighbors in those and other situations.
3	METHODS	We define multi-player Nash equilibrium for such programs - but because they require some conditions that are hard to satisfy in the real world, we introduce a new model-theoretic concept of strong equilibrium.
4	RESULTS	We show that stable equilibria can capture all Nash equilibria.
5	RESULTS	We prove a host of complexity (intractability) results for checking existence of strong equilibria (as well as related counting complexity results), together with algorithms to find them.
6	METHODS	We then identify a class of ChoiceGAPs for which stable equilibria can be polynomially computed.
7	METHODS	We develop algorithms for computing these equilibria under various restrictions.
8	RESULTS	We come up with the important concept of an estimation query which can compute quantities w.r.t. a given strong equilibrium, and approximate ranges of values (answers) across the space of strong equilibria.
9	RESULTS	Even though we show that computing range answers to estimation queries exactly is intractable, we are able to identify classes of estimation queries that can be answered in polynomial time.
10	RESULTS	We report on experiments we conducted with a real-world FaceBook data set surrounding the 2013 Italian election showing that our algorithms have good predictive accuracy with an Area Under a ROC Curve that, on average, is over 0.76.
1	BACKGROUND	With the recent emergence and the explosion of users in social networks, Internet users have come to know more about other people or companies through information obtained from online groups or communities and therefore meet new opportunities.
2	BACKGROUND	An avalanche of diverse and unstructured information is created every minute, for billions of devices connected to the Internet all the time.
3	BACKGROUND	Analyze, process, understand and evaluate these data, it is a challenging task, given the volume, velocity and variety of information from these social networks.
4	BACKGROUND	However, a better understanding of the process of monitoring networks and the use of tools of this kind are essential for people, companies and the academic world.
5	BACKGROUND	The application of monitoring systems, information management and the possibility of bringing brands to people, are some positives that this research will provide better knowledge of the problems.
6	OBJECTIVE	In this research will be analyzed monitoring tool of social networks SCUP, its details, its features and the tool related to business management.
7	CONCLUSIONS	In conclusion, we present all the peculiarities of the software and the possibilities applicable in the corporate environment, as aid to decision making.
1	BACKGROUND	As the security landscape evolves over time, where thousands of species of malicious codes are seen every day, antivirus vendors strive to detect and classify malware families for efficient and effective responses against malware campaigns.
2	OBJECTIVE	To enrich this effort, and by capitalizing on ideas from the social network analysis domain, we build a tool that can help classify malware families using features driven from the graph structure of their system calls.
3	METHODS	To achieve that, we first construct a system call graph that consists of system calls found in the execution of the individual malware families.
4	METHODS	To explore distinguishing features of various malware species, we study social network properties as applied to the call graph, including the degree distribution, degree centrality, average distance, clustering coefficient, network density, and component ratio.
5	METHODS	We utilize features driven from those properties to build a classifier for malware families.
6	RESULTS	Our experimental results show that influence-based graph metrics such as the degree centrality are effective for classifying malware, whereas the general structural metrics of malware are less effective for classifying malware.
7	CONCLUSIONS	Our experiments demonstrate that the proposed system performs well in detecting and classifying malware families within each malware class with accuracy greater than 96%.
1	BACKGROUND	Social media technologies are increasingly utilized by patients, leading to development of online social groups where patients share experiences and offer support to their peers on these platforms.
2	BACKGROUND	There is limited research investigating actual use of social media platforms by patients, issues faced in using such platforms and how appropriation of these platforms impact patient outcomes.
3	OBJECTIVE	A conceptual model based on social support theory and model of technology appropriation is proposed in order to investigate factors that influence this phenomenon.
4	METHODS	The authors propose that social support theory and model of technology appropriation could explain the determining factors, both enablers and barriers that drive appropriation and knowledge sharing behaviours of patients on social media platforms.
1	BACKGROUND	Many foreign companies see social media as a low cost marketing space for entering the vast Chinese market.
2	BACKGROUND	This is fraught with complexity, requiring an understanding of social media behaviour, social media marketing, and the Chinese context.
3	OBJECTIVE	In this exploratory pilot study, we develop the notion of franding (online freinding of brands) as a unifying metaphor, and suggest that effective social media brand strategies resemble effective online friend behaviours.
4	METHODS	Based on this we develop some propositions and evaluate them qualitatively in interviews with young Chinese consumers.
5	RESULTS	Our study suggests that conceptualizing brand social media relationships as a type of online friendship can assist in harmonizing disparate literature and provide useful insights for organizations operating in this complex area.
1	BACKGROUND	To date, much research has been conducted on the positive and negative effects of online social networking (OSN).
2	BACKGROUND	However, how users perceive others and themselves being subject to these effects and the consequences of users' perceptions are understudied.
3	OBJECTIVE	Drawing from the third-person effect theory, this study examines the self-other perceptual gap for positive and negative effects of OSN and the consequences of perceptions for negative effects.
4	RESULTS	Findings from our online survey (N=187) and interviews (N=8) suggested a significant difference between the perceived positive and negative effects on self and on others.
5	RESULTS	Furthermore, the link between the third-person perception for usage risks of OSN and support for taking privacy protection actions was confirmed.
6	RESULTS	We also found that the self-other discrepant perceptions were not influenced by age, time spent on OSN, number of OSN friends.
7	CONCLUSIONS	However, gender emerged as a key difference in the third-person effects gap for privacy risks.
1	BACKGROUND	In emergency management for mass gathering, the knowledge about crowd types can highly assist with providing timely response and effective resource allocation.
2	BACKGROUND	Crowd monitoring can be achieved using computer vision based approaches and sensory data analysis.
3	BACKGROUND	The emergence of social media platforms presents an opportunity to capture valuable information about how people feel and think.
4	BACKGROUND	However, reviewing current works shows that there are a limited number of studies that use social media in crowd monitoring and/or incorporate a unified crowd model for consistency and interoperability.
5	OBJECTIVE	This presents a novel framework for crowd monitoring using social media.
6	METHODS	It includes a standard crowd model to represent different types of crowds.
7	METHODS	The proposed framework considers the effect of emotion on crowd behaviour and uses the emotion analysis of social media to identify the crowd types in an event.
8	METHODS	An experiment using historical data of a past event to validate our framework and model is described.
1	BACKGROUND	The identification of distinct user roles is an important theme in social media research.
2	BACKGROUND	However, for Enterprise Social Networks (ESN), the use of social media within organisations, research identifying such roles is still lacking.
3	BACKGROUND	Yet, understanding user roles, in particular regarding their knowledge contributions and communication behaviour, might usefully support companies in managing critical knowledge resources.
4	OBJECTIVE	Against this backdrop, in this research-in-progress paper we derive 16 metrics characterising the participation behaviour, message content and structural position of ESN users of an Australian professional services firm.
5	METHODS	Based on a factor analysis, we identify four distinct dimensions of ESN user behaviour: Contribution & networking, information provision, contact dispersion and invisible usage.
6	RESULTS	With this research we contribute to the literature by transferring concepts and methods of organisation science and social media research to an ESN context.
7	CONCLUSIONS	Further, our approach forms the basis for the identification of different types of knowledge actors, which might ultimately help to improve organisational knowledge transparency.
1	OBJECTIVE	This paper presents a method to validate the true patrons of a brand, group, artist or any other entity on the social networking site Twitter.
2	METHODS	We analyze the trend of total number of tweets, average retweets and total number of followers for various nodes for different social and political backgrounds.
3	RESULTS	We argue that average retweets to follower ratio reveals the overall value of the individual accounts and helps estimate the true to fake account ratio.
1	BACKGROUND	Social media and social networking sites have become a global pinboard for exposition and discussion of news, topics, and ideas, where social media users often update their opinions about a particular topic by learning from the opinions shared by their friends.
2	BACKGROUND	In this context, can we learn a data-driven model of opinion dynamics that is able to accurately forecast opinions from users?
3	OBJECTIVE	In this paper, we introduce SLANT, a probabilistic modeling framework of opinion dynamics, which represents users opinions over time by means of marked jump diffusion stochastic differential equations, and allows for efficient model simulation and parameter estimation from historical fine grained event data.
4	METHODS	We then leverage our framework to derive a set of efficient predictive formulas for opinion forecasting and identify conditions under which opinions converge to a steady state.
5	RESULTS	Experiments on data gathered from Twitter show that our model provides a good fit to the data and our formulas achieve more accurate forecasting than alternatives.
1	BACKGROUND	Lurking is a complex user-behavioral phenomenon that occurs in all large-scale online communities and social networks.
2	BACKGROUND	It generally refers to the behavior characterizing users that benefit from the information produced by others in the community without actively contributing back to the production of social content.
3	BACKGROUND	The amount and evolution of lurkers may strongly affect an online social environment, therefore understanding the lurking dynamics and identifying strategies to curb this trend are relevant problems.
4	OBJECTIVE	In this regard, we introduce the Lurker Game, i.e., a model for analyzing the transitions from a lurking to a non-lurking (i.e., active) user role, and vice versa, in terms of evolutionary game theory.
5	METHODS	We evaluate the proposed Lurker Game by arranging agents on complex networks and analyzing the system evolution, seeking relations between the network topology and the final equilibrium of the game.
6	RESULTS	Results suggest that the Lurker Game is suitable to model the lurking dynamics, showing how the adoption of rewarding mechanisms combined with the modeling of hypothetical heterogeneity of users' interests may lead users in an online community towards a cooperative behavior.
1	OBJECTIVE	A class of dynamic threshold models is proposed, for describing the upset of collective actions in social networks.
2	METHODS	The agents of the network have to decide whether to undertake a certain action or not.
3	METHODS	They make their decision by comparing the activity level of their neighbors with a time-varying threshold, evolving according to a time-invariant opinion dynamic model.
4	METHODS	Key features of the model are a parameter representing the degree of self-confidence of the agents, and the mechanism adopted by the agents to evaluate the activity level of their neighbors.
5	METHODS	The case in which a radical agent, initially eager to undertake the action, interacts with a group of ordinary agents, is considered.
6	RESULTS	The main contribution of the paper is the complete analytic characterization of the asymptotic behaviors of the network, for three different graph topologies.
7	METHODS	The asymptotic activity patterns are determined as a function of the self-confidence parameter and of the initial threshold of the ordinary agents.
1	BACKGROUND	Text from social media provides a set of challenges that can cause traditional NLP approaches to fail.
2	BACKGROUND	Informal language, spelling errors, abbreviations, and special characters are all commonplace in these posts, leading to a prohibitively large vocabulary size for word-level approaches.
3	OBJECTIVE	We propose a character composition model, tweet2vec, which finds vector-space representations of whole tweets by learning complex, non-local dependencies in character sequences.
4	RESULTS	The proposed model outperforms a word-level baseline at predicting user-annotated hashtags associated with the posts, doing significantly better when the input contains many out-of-vocabulary words or unusual character sequences.
5	RESULTS	Our tweet2vec encoder is publicly available.
1	BACKGROUND	There is an ever growing number of users with accounts on multiple social media and networking sites.
2	BACKGROUND	Consequently, there is increasing interest in matching user accounts and profiles across different social networks in order to create aggregate profiles of users.
3	OBJECTIVE	In this paper, we present models for Digital Stylometry, which is a method for matching users through stylometry inspired techniques.
4	METHODS	We experimented with linguistic, temporal, and combined temporal-linguistic models for matching user accounts, using standard and novel techniques.
5	RESULTS	Using publicly available data, our best model, a combined temporal-linguistic one, was able to correctly match the accounts of 31% of 5,612 distinct users across Twitter and Facebook.
1	BACKGROUND	Twitter has become one of the main sources of news for many people.
2	BACKGROUND	As real-world events and emergencies unfold, Twitter is abuzz with hundreds of thousands of stories about the events.
3	BACKGROUND	Some of these stories are harmless, while others could potentially be life-saving or sources of malicious rumors.
4	BACKGROUND	Thus, it is critically important to be able to efficiently track stories that spread on Twitter during these events.
5	OBJECTIVE	In this paper, we present a novel semi-automatic tool that enables users to efficiently identify and track stories about real-world events on Twitter.
6	RESULTS	We ran a user study with 25 participants, demonstrating that compared to more conventional methods, our tool can increase the speed and the accuracy with which users can track stories about real-world events.
1	BACKGROUND	Simple, short, and compact hashtags cover a wide range of information on social networks.
2	BACKGROUND	Although many works in the field of natural language processing (NLP) have demonstrated the importance of hashtag recommendation, hashtag recommendation for images has barely been studied.
3	OBJECTIVE	In this paper, we introduce the HARRISON dataset, a benchmark on hashtag recommendation for real world images in social networks.
4	OBJECTIVE	The HARRISON dataset is a realistic dataset, composed of 57,383 photos from Instagram and an average of 4.5 associated hashtags for each photo.
5	METHODS	To evaluate our dataset, we design a baseline framework consisting of visual feature extractor based on convolutional neural network (CNN) and multi-label classifier based on neural network.
6	METHODS	Based on this framework, two single feature-based models, object-based and scene-based model, and an integrated model of them are evaluated on the HARRISON dataset.
7	RESULTS	Our dataset shows that hashtag recommendation task requires a wide and contextual understanding of the situation conveyed in the image.
8	CONCLUSIONS	As far as we know, this work is the first vision-only attempt at hashtag recommendation for real world images in social networks.
9	CONCLUSIONS	We expect this benchmark to accelerate the advancement of hashtag recommendation.
1	OBJECTIVE	In this paper, we aim to model the formation of data dissemination in online social networks (OSNs), and measure the transport difficulty of generated data traffic.
2	METHODS	We focus on a usual type of interest-driven social sessions in OSNs, called \emph{Social-InterestCast}, under which a user will autonomously determine whether to view the content from his followees depending on his interest.
3	BACKGROUND	It is challenging to figure out the formation mechanism of such a Social-InterestCast, since it involves multiple interrelated factors such as users' social relationships, users' interests, and content semantics.
4	OBJECTIVE	We propose a four-layered system model, consisting of physical layer, social layer, content layer, and session layer.
5	METHODS	By this model we successfully obtain the geographical distribution of Social-InterestCast sessions, serving as the precondition for quantifying data transport difficulty.
6	METHODS	We define the fundamental limit of \emph{transport load} as a new metric, called \emph{transport complexity}, i.e., the \emph{minimum required} transport load for an OSN over a given carrier network.
7	METHODS	Specifically, we derive the transport complexity for Social-InterestCast sessions in a large-scale OSN over the carrier network with optimal communication architecture.
8	RESULTS	The results can act as the common lower bounds on transport load for Social-InterestCast over any carrier networks.
9	CONCLUSIONS	To the best of our knowledge, this is the first work to measure the transport difficulty for data dissemination in OSNs by modeling session patterns with the interest-driven characteristics.
1	OBJECTIVE	In this paper, we investigate the profit-aware team grouping problem in social networks.
2	METHODS	We consider a setting in which people possess different skills and compatibility among these individuals is captured by a social network.
3	METHODS	Here, we assume a collection of tasks, where each task requires a specific set of skills, and yields a different profit upon completion.
4	METHODS	Active and qualified individuals may collaborate with each other in the form of \emph{teams} to accomplish a set of tasks.
5	OBJECTIVE	Our goal is to find a grouping method that maximizes the total profit of the tasks that these teams can complete.
6	METHODS	Any feasible grouping must satisfy the following three conditions: (i) each team possesses all skills required by the task, (ii) individuals within the same team are social compatible, and (iii) each individual is not overloaded.
7	METHODS	We refer to this as the \textsc{TeamGrouping} problem.
8	METHODS	Our work presents a detailed analysis of the computational complexity of the problem, and propose a LP-based approximation algorithm to tackle it and its variants.
9	RESULTS	Although we focus on team grouping in this paper, our results apply to a broad range of optimization problems that can be formulated as a cover decomposition problem.
1	BACKGROUND	As businesses increasingly rely on social networking sites to engage with their customers, it is crucial to understand and counter reputation manipulation activities, including fraudulently boosting the number of Facebook page likes using like farms.
2	BACKGROUND	To this end, several fraud detection algorithms have been proposed and some deployed by Facebook that use graph co-clustering to distinguish between genuine likes and those generated by farm-controlled profiles.
3	BACKGROUND	However, as we show in this paper, these tools do not work well with stealthy farms whose users spread likes over longer timespans and like popular pages, aiming to mimic regular users.
4	OBJECTIVE	We present an empirical analysis of the graph-based detection tools used by Facebook and highlight their shortcomings against more sophisticated farms.
5	METHODS	Next, we focus on characterizing content generated by social networks accounts on their timelines, as an indicator of genuine versus fake social activity.
6	METHODS	We analyze a wide range of features extracted from timeline posts, which we group into two main classes: lexical and non-lexical.
7	RESULTS	We postulate and verify that like farm accounts tend to often re-share content, use fewer words and poorer vocabulary, and more often generate duplicate comments and likes compared to normal users.
8	RESULTS	We extract relevant lexical and non-lexical features and and use them to build a classifier to detect like farms accounts, achieving significantly higher accuracy, namely, at least 99% precision and 93% recall.
1	OBJECTIVE	We show that three basic actor characteristics, namely normalized reciprocity, three cycles, and triplets, can be expressed using an unified framework that is based on computing the similarity index between two sets associated with the actor: the set of her/his friends and the set of those considering her/him as a friend.
2	METHODS	These metrics are extended to multiplex networks and then computed for two friendship networks generated by collecting data from two groups of undergraduate students.
3	RESULTS	We found that in offline communication strong and weak ties are (almost) equally presented, while in online communication weak ties are dominant.
4	RESULTS	Moreover, weak ties are much less reciprocal than strong ties.
5	RESULTS	However, across different layers of the multiplex network reciprocities are preserved, while triads (measured with normalized three cycles and triplets) are not significant.
1	OBJECTIVE	We propose an analytical framework able to investigate discussions about polarized topics in online social networks from many different angles.
2	METHODS	The framework supports the analysis of social networks along several dimensions: time, space and sentiment.
3	RESULTS	We show that the proposed analytical framework and the methodology can be used to mine knowledge about the perception of complex social phenomena.
4	METHODS	We selected the refugee crisis discussions over Twitter as the case study.
5	BACKGROUND	This difficult and controversial topic is an increasingly important issue for the EU.
6	METHODS	The raw stream of tweets is enriched with space information (user and mentioned locations), and sentiment (positive vs. negative) w.r.t. refugees.
7	RESULTS	Our study shows differences in positive and negative sentiment in EU countries, in particular in UK, and by matching events, locations and perception it underlines opinion dynamics and common prejudices regarding the refugees.
1	BACKGROUND	This paper presents a secure communication application called DiscoverFriends.
2	OBJECTIVE	Its purpose is to securely communicate to a group of online friends while bypassing their respective social networking servers under a mobile ad hoc network environment.
3	METHODS	DiscoverFriends leverages Bloom filters and a hybrid encryption technique with a self-organized public-key management scheme to securely identify friends and provide authentication.
4	METHODS	Additionally, DiscoverFriends enables anonymous location check-ins by utilizing a new cryptographic primitive called Function Secret Sharing.
5	METHODS	Finally, to the best of our knowledge, DiscoverFriends implements and evaluates the first Android multi-hop WiFi direct protocol using IPv6.
1	OBJECTIVE	In this paper, we propose a novel social network aware approach for user association in wireless small cell networks.
2	METHODS	The proposed approach exploits social relationships between user equipments (UEs) and their physical proximity to optimize the network throughput.
3	METHODS	We formulate the problem as a matching game between UEs and their serving nodes (SNs).
4	METHODS	In our proposed game, the serving node can be a small cell base station (SCBS) or an important node with device-to-device capabilities.
5	METHODS	In this game, the SCBSs and UEs maximize their respective utility functions capturing both the spatial and social structures of the network.
6	METHODS	We show that the proposed game belongs to the class of matching games with externalities.
7	METHODS	Subsequently, we propose a distributed algorithm using which the SCBSs and UEs interact and reach a stable matching.
8	RESULTS	We show the convergence of the proposed algorithm and study the properties of the resulting matching.
9	RESULTS	Simulation results show that the proposed socially-aware user association approach can efficiently offload traffic while yielding a significant gain reaching up to 63% in terms of data rates as compared to the classical (social-unaware) approach.
1	BACKGROUND	Most previous work on influence maximization in social networks is limited to the non-adaptive setting in which the marketer is supposed to select all of the seed users, to give free samples or discounts to, up front.
2	BACKGROUND	A disadvantage of this setting is that the marketer is forced to select all the seeds based solely on a diffusion model.
3	BACKGROUND	If some of the selected seeds do not perform well, there is no opportunity to course-correct.
4	BACKGROUND	A more practical setting is the adaptive setting in which the marketer initially selects a batch of users and observes how well seeding those users leads to a diffusion of product adoptions.
5	BACKGROUND	Based on this market feedback, she formulates a policy for choosing the remaining seeds.
6	OBJECTIVE	In this paper, we study adaptive offline strategies for two problems: (a) MAXSPREAD -- given a budget on number of seeds and a time horizon, maximize the spread of influence and (b) MINTSS -- given a time horizon and an expected number of target users to be influenced, minimize the number of seeds that will be required.
7	METHODS	In particular, we present theoretical bounds and empirical results for an adaptive strategy and quantify its practical benefit over the non-adaptive strategy.
8	METHODS	We evaluate adaptive and non-adaptive policies on three real data sets.
9	CONCLUSIONS	We conclude that while benefit of going adaptive for the MAXSPREAD problem is modest, adaptive policies lead to significant savings for the MINTSS problem.
1	OBJECTIVE	In this paper we study the relationship between the resources of social networks by exploring the Web as big data based on a simple search engine.
2	METHODS	We have used set theory by utilizing the occurrence and co-occurrence for defining the singleton or doubleton spaces of event in a search engine model, and then provided them as representation of social actors and their relationship in clusters.
3	RESULTS	Thus, there are behaviors of social actors and their relation based on Web.
1	OBJECTIVE	We introduce a simple network formation model for social networks.
2	METHODS	Agents are nodes, connecting to another agent by building a directed edge (or accepting a connection from another agent) has a cost, and reaching (or being reached by) other agents via short directed paths has a benefit; in effect, an agent wants to reach others quickly, but without the cost of directly connecting each and every one.
3	RESULTS	We prove that asynchronous edge dynamics always converge to a stable network; in fact, for nontrivial ranges of parameters this convergence is fast.
4	RESULTS	Moreover, the set of fixed points of the dynamics form a nontrivial class of networks.
5	METHODS	For the static game, we give classes of efficient networks for nontrivial parameter ranges and further study their stability.
6	CONCLUSIONS	We close several problems, and leave many interesting ones open.
1	BACKGROUND	Most prior algorithms for influence maximization focused are designed for Online Social Networks (OSNs) and require centralized computation.
2	BACKGROUND	Directly deploying the above algorithms in distributed Mobile Social Networks (MSNs) will overwhelm the networks due to an enormous number of messages required for seed selection.
3	OBJECTIVE	In this paper, therefore, we design a new cross-layer strategy to jointly examine MSN and mobile ad hoc networks (MANETs) to facilitate efficient seed selection, by extracting a subset of nodes as agents to represent nearby friends during the distributed computation.
4	METHODS	Specifically, we formulate a new optimization problem, named Agent Selection Problem (ASP), to minimize the message overhead transmitted in MANET.
5	METHODS	We prove that ASP is NP-Hard and design an effectively distributed algorithm.
6	RESULTS	Simulation results in real and synthetic datasets manifest that the message overhead can be significantly reduced compared with the existing approaches.
1	OBJECTIVE	In this study, the problem of shallow parsing of Hindi-English code-mixed social media text (CSMT) has been addressed.
2	METHODS	We have annotated the data, developed a language identifier, a normalizer, a part-of-speech tagger and a shallow parser.
3	BACKGROUND	To the best of our knowledge, we are the first to attempt shallow parsing on CSMT.
4	RESULTS	The pipeline developed has been made available to the research community with the goal of enabling better text analysis of Hindi English CSMT.
5	RESULTS	The pipeline is accessible at http://bit.ly/csmt-parser-api .
1	BACKGROUND	Online Social Networking may be a way to support health professionals' need for continuous learning through interaction with peers and experts.
2	BACKGROUND	Understanding and evaluating such learning is important but difficult, and Social Network Analysis (SNA) offers a solution.
3	OBJECTIVE	This paper demonstrates how SNA can be used to study levels of participation as well as the patterns of interactions that take place among health professionals in a large online professional learning network.
4	RESULTS	Our analysis has shown that their learning network is highly centralised and loosely connected.
5	RESULTS	The level of participation is low in general, and most interactions are structured around a small set of users consisting of moderators and core members.
6	RESULTS	The structural patterns of interaction indicates there is a chance of small group learning occurring and requires further investigation to identify those potential learning groups.
7	CONCLUSIONS	This first stage of analysis, to be followed by longitudinal study of the dynamics of interaction and complemented by content analysis of their discussion, may contribute to greater sophistication in the analysis and utilisation of new environments for health professional learning.
1	BACKGROUND	Social status refers to the relative position within the society.
2	BACKGROUND	It is an important notion in sociology and related research.
3	BACKGROUND	The problem of measuring social status has been studied for many years.
4	BACKGROUND	Various indicators are proposed to assess social status of individuals, including educational attainment, occupation, and income/wealth.
5	BACKGROUND	However, these indicators are sometimes difficult to collect or measure.
6	OBJECTIVE	We investigate social networks for alternative measures of social status.
7	BACKGROUND	Online activities expose certain traits of users in the real world.
8	BACKGROUND	We are interested in how these activities are related to social status, and how social status can be predicted with social network data.
9	BACKGROUND	To the best of our knowledge, this is the first study on connecting online activities with social status in reality.
10	OBJECTIVE	In particular, we focus on the network structure of microblogs in this study.
11	BACKGROUND	A user following another implies some kind of status.
12	METHODS	"We cast the predicted social status of users to the ""status"" of real-world entities, e.g., universities, occupations, and regions, so that we can compare and validate predicted results with facts in the real world."
13	METHODS	We propose an efficient algorithm for this task and evaluate it on a dataset consisting of 3.4 million users from Sina Weibo.
14	RESULTS	The result shows that it is possible to predict social status with reasonable accuracy using social network data.
15	RESULTS	We also point out challenges and limitations of this approach, e.g., inconsistence between online popularity and real-world status for certain users.
16	CONCLUSIONS	Our findings provide insights on analyzing online social status and future designs of ranking schemes for social networks.
1	BACKGROUND	Predicting the future popularity of online content is highly important in many applications.
2	BACKGROUND	Preferential attachment phenomena is encountered in scale free networks.
3	BACKGROUND	Under it's influece popular items get more popular thereby resulting in long tailed distribution problem.
4	BACKGROUND	Consequently, new items which can be popular (potential ones), are suppressed by the already popular items.
5	OBJECTIVE	This paper proposes a novel model which is able to identify potential items.
6	METHODS	It identifies the potentially popular items by considering the number of links or ratings it has recieved in recent past along with it's popularity decay.
7	METHODS	For obtaining an effecient model we consider only temporal features of the content, avoiding the cost of extracting other features.
8	RESULTS	We have found that people follow recent behaviours of their peers.
9	RESULTS	In presence of fit or quality items already popular items lose it's popularity.
10	METHODS	Prediction accuracy is measured on three industrial datasets namely Movielens, Netflix and Facebook wall post.
11	RESULTS	Experimental results show that compare to state-of-the-art model our model have better prediction accuracy.
1	BACKGROUND	The emergence and popularization of online social networks suddenly made available a large amount of data from social organization, interaction and human behavior.
2	BACKGROUND	All this information opens new perspectives and challenges to the study of social systems, being of interest to many fields.
3	BACKGROUND	Although most online social networks are recent (less than fifteen years old), a vast amount of scientific papers was already published on this topic, dealing with a broad range of analytical methods and applications.
4	OBJECTIVE	This work describes how computational researches have approached this subject and the methods used to analyze such systems.
5	METHODS	Founded on a wide though non-exaustive review of the literature, a taxonomy is proposed to classify and describe different categories of research.
6	METHODS	Each research category is described and the main works, discoveries and perspectives are highlighted.
1	BACKGROUND	One major feature of social networks (e.g., massive online social networks) is the dissemination of information, such as news, rumors and opinions.
2	BACKGROUND	Information can be propagated via natural connections in written, oral or electronic forms.
3	BACKGROUND	The physics of information diffusion has been changed with the mainstream adoption of the Internet and Web.
4	BACKGROUND	Until a few years ago, the major barrier for someone who wanted a piece of information to spread through a community was the cost of the technical infrastructure required to reach a large number of people.
5	BACKGROUND	Today, with widespread access to the Internet, this bottleneck has largely been removed.
6	BACKGROUND	Information diffusion has been one of the focuses in social network research area, due to its importance in social interactions and everyday life.
7	BACKGROUND	More recently, during the last twenty to thirty years, there has been interest and attention not just in observing information and innovation flow, but also in influencing and creating them.
8	OBJECTIVE	Modeling information diffusion in networks enables us to reason about its spread.
1	BACKGROUND	Recent years saw an increased interest in modeling and understanding the mechanisms of opinion and innovation spread through human networks.
2	BACKGROUND	Using analysis of real-world social data, researchers are able to gain a better understanding of the dynamics of social networks and subsequently model the changes in such networks over time.
3	OBJECTIVE	We developed a social network model that both utilizes an agent-based approach with a dynamic update of opinions and connections between agents and reflects opinion propagation and structural changes over time as observed in real-world data.
4	METHODS	We validate the model using data from the Social Evolution dataset of the MIT Human Dynamics Lab describing changes in friendships and health self-perception in a targeted student population over a nine-month period.
5	METHODS	We demonstrate the effectiveness of the approach by predicting changes in both opinion spread and connectivity of the network.
6	METHODS	We also use the model to evaluate how the network parameters, such as the level of `openness' and willingness to incorporate opinions of neighboring agents, affect the outcome.
7	RESULTS	The model not only provides insight into the dynamics of ever changing social networks, but also presents a tool with which one can investigate opinion propagation strategies for networks of various structures and opinion distributions.
1	BACKGROUND	Social media systems allow Internet users a congenial platform to freely express their thoughts and opinions.
2	BACKGROUND	Although this property represents incredible and unique communication opportunities, it also brings along important challenges.
3	BACKGROUND	Online hate speech is an archetypal example of such challenges.
4	BACKGROUND	Despite its magnitude and scale, there is a significant gap in understanding the nature of hate speech on social media.
5	OBJECTIVE	In this paper, we provide the first of a kind systematic large scale measurement study of the main targets of hate speech in online social media.
6	METHODS	To do that, we gather traces from two social media systems: Whisper and Twitter.
7	METHODS	We then develop and validate a methodology to identify hate speech on both these systems.
8	RESULTS	Our results identify online hate speech forms and offer a broader understanding of the phenomenon, providing directions for prevention and detection approaches.
1	BACKGROUND	Numerous real-world relations can be represented by signed networks with positive links (e.g., trust) and negative links (e.g., distrust).
2	BACKGROUND	Link analysis plays a crucial role in understanding the link formation and can advance various tasks in social network analysis such as link prediction.
3	BACKGROUND	The majority of existing works on link analysis have focused on unsigned social networks.
4	BACKGROUND	The existence of negative links determines that properties and principles of signed networks are substantially distinct from those of unsigned networks, thus we need dedicated efforts on link analysis in signed social networks.
5	OBJECTIVE	In this paper, following social theories in link analysis in unsigned networks, we adopt three social science theories, namely Emotional Information, Diffusion of Innovations and Individual Personality, to guide the task of link analysis in signed networks.
1	BACKGROUND	Social media sites are information marketplaces, where users produce and consume a wide variety of information and ideas.
2	BACKGROUND	In these sites, users typically choose their information sources, which in turn determine what specific information they receive, how much information they receive and how quickly this information is shown to them.
3	BACKGROUND	In this context, a natural question that arises is how efficient are social media users at selecting their information sources.
4	OBJECTIVE	In this work, we propose a computational framework to quantify users' efficiency at selecting information sources.
5	METHODS	Our framework is based on the assumption that the goal of users is to acquire a set of unique pieces of information.
6	METHODS	To quantify user's efficiency, we ask if the user could have acquired the same pieces of information from another set of sources more efficiently.
7	METHODS	We define three different notions of efficiency -- link, in-flow, and delay -- corresponding to the number of sources the user follows, the amount of (redundant) information she acquires and the delay with which she receives the information.
8	METHODS	Our definitions of efficiency are general and applicable to any social media system with an underlying information network, in which every user follows others to receive the information they produce.
9	METHODS	In our experiments, we measure the efficiency of Twitter users at acquiring different types of information.
10	RESULTS	We find that Twitter users exhibit sub-optimal efficiency across the three notions of efficiency, although they tend to be more efficient at acquiring non-popular than popular pieces of information.
11	RESULTS	We then show that this lack of efficiency is a consequence of the triadic closure mechanism by which users typically discover and follow other users in social media.
12	METHODS	Finally, we develop a heuristic algorithm that enables users to be significantly more efficient at acquiring the same unique pieces of information.
1	OBJECTIVE	An active line of research has studied the detection and representation of trends in social media content.
2	BACKGROUND	There is still relatively little understanding, however, of methods to characterize the early adopters of these trends: who picks up on these trends at different points in time, and what is their role in the system?
3	OBJECTIVE	We develop a framework for analyzing the population of users who participate in trending topics over the course of these topics' lifecycles.
4	METHODS	"Central to our analysis is the notion of a ""status gradient"", describing how users of different activity levels adopt a trend at different points in time."
5	RESULTS	Across multiple datasets, we find that this methodology reveals key differences in the nature of the early adopters in different domains.
1	OBJECTIVE	We study discrete preference games in heterogeneous social networks.
2	BACKGROUND	These games model the interplay between a player's private belief and his/her publicly stated opinion (which could be different from the player's belief) as a strategic game in which the players' strategies are the opinions and the cost of an opinion in a state is a convex combination through a parameter $\alpha\in[0,1]$ of two factors: the disagreement between the player's opinion and his/her internal belief and the number of neighbors whose opinions differ from the one of the player.
3	METHODS	The parameter $\alpha$ models how stubborn a player is: players with large $\alpha$ change their opinion only if many neighbors disagree with his/her belief.
4	METHODS	We consider social networks that are heterogeneous in the sense that the parameter $\alpha$ can vary from player to player.
5	METHODS	We ask if it is possible that the belief shared by the majority of the players does not coincide with the opinion that is publicly announced by the majority of the players in an equilibrium state.
6	RESULTS	Our main result is a characterization of the social networks that admit an initial belief assignment for which there exists a sequence of best response moves that reach an equilibrium in which the initial majority is subverted.
7	RESULTS	Our characterization is effective in the sense that can be tested efficiently and the initial belief assignment that can be subverted can be computed in time polynomial in the number of players.
8	RESULTS	Our result is actually stronger as we show that in each initial belief assignment that can be subverted, subversion is actually obtained in a very strong way: it only takes one move of a single player, the swing player, to lead the social network to a point of no return in which any rational move from any player leads to a subverted majority.
1	OBJECTIVE	In this paper, we mine and learn to predict how similar a pair of users' interests towards videos are, based on demographic (age, gender and location) and social (friendship, interaction and group membership) information of these users.
2	OBJECTIVE	We use the video access patterns of active users as ground truth (a form of benchmark).
3	METHODS	We adopt tag-based user profiling to establish this ground truth, and justify why it is used instead of video-based methods, or many latent topic models such as LDA and Collaborative Filtering approaches.
4	METHODS	We then show the effectiveness of the different demographic and social features, and their combinations and derivatives, in predicting user interest similarity, based on different machine-learning methods for combining multiple features.
5	METHODS	We propose a hybrid tree-encoded linear model for combining the features, and show that it out-performs other linear and treebased models.
6	RESULTS	Our methods can be used to predict user interest similarity when the ground-truth is not available, e.g. for new users, or inactive users whose interests may have changed from old access data, and is useful for video recommendation.
7	METHODS	Our study is based on a rich dataset from Tencent, a popular service provider of social networks, video services, and various other services in China.
1	OBJECTIVE	The paper proposes a way to add marketing into the standard threshold model of social networks.
2	OBJECTIVE	Within this framework, the paper studies logical properties of the influence relation between sets of agents in social networks.
3	METHODS	Two different forms of this relation are considered: one for promotional marketing and the other for preventive marketing.
4	METHODS	In each case a sound and complete logical system describing properties of the influence relation is proposed.
5	BACKGROUND	Both systems could be viewed as extensions of Armstrong's axioms of functional dependency from the database theory.
1	BACKGROUND	An increasing number of people use wearables and other smart devices to quantify various health conditions, ranging from sleep patterns, to body weight, to heart rates.
2	BACKGROUND	Of these Quantified Selfs many choose to openly share their data via online social networks such as Twitter and Facebook.
3	OBJECTIVE	In this study, we use data for users who have chosen to connect their smart scales to Twitter, providing both a reliable time series of their body weight, as well as insights into their social surroundings and general online behavior.
4	METHODS	Concretely, we look at which social media features are predictive of physical status, such as body weight at the individual level, and activity patterns at the population level.
5	RESULTS	We show that it is possible to predict an individual's weight using their online social behaviors, such as their self-description and tweets.
6	RESULTS	Weekly and monthly patterns of quantified-self behaviors are also discovered.
7	RESULTS	These findings could contribute to building models to monitor public health and to have more customized personal training interventions.
8	CONCLUSIONS	While there are many studies using either quantified self or social media data in isolation, this is one of the few that combines the two data sources and, to the best of our knowledge, the only one that uses public data.
1	BACKGROUND	As breaking news unfolds people increasingly rely on social media to stay abreast of the latest updates.
2	BACKGROUND	The use of social media in such situations comes with the caveat that new information being released piecemeal may encourage rumours, many of which remain unverified long after their point of release.
3	BACKGROUND	Little is known, however, about the dynamics of the life cycle of a social media rumour.
4	OBJECTIVE	In this paper we present a methodology that has enabled us to collect, identify and annotate a dataset of 330 rumour threads (4,842 tweets) associated with 9 newsworthy events.
5	METHODS	We analyse this dataset to understand how users spread, support, or deny rumours that are later proven true or false, by distinguishing two levels of status in a rumour life cycle i.e., before and after its veracity status is resolved.
6	METHODS	The identification of rumours associated with each event, as well as the tweet that resolved each rumour as true or false, was performed by a team of journalists who tracked the events in real time.
7	RESULTS	Our study shows that rumours that are ultimately proven true tend to be resolved faster than those that turn out to be false.
8	RESULTS	Whilst one can readily see users denying rumours once they have been debunked, users appear to be less capable of distinguishing true from false rumours when their veracity remains in question.
9	RESULTS	In fact, we show that the prevalent tendency for users is to support every unverified rumour.
10	RESULTS	We also analyse the role of different types of users, finding that highly reputable users such as news organisations endeavour to post well-grounded statements, which appear to be certain and accompanied by evidence.
11	RESULTS	Nevertheless, these often prove to be unverified pieces of information that give rise to false rumours.
12	CONCLUSIONS	Our study reinforces the need for developing robust machine learning techniques that can provide assistance for assessing the veracity of rumours.
1	BACKGROUND	Items shared through Social Media may affect more than one user's privacy --- e.g., photos that depict multiple users, comments that mention multiple users, events in which multiple users are invited, etc.
2	BACKGROUND	The lack of multi-party privacy management support in current mainstream Social Media infrastructures makes users unable to appropriately control to whom these items are actually shared or not.
3	BACKGROUND	Computational mechanisms that are able to merge the privacy preferences of multiple users into a single policy for an item can help solve this problem.
4	BACKGROUND	However, merging multiple users' privacy preferences is not an easy task, because privacy preferences may conflict, so methods to resolve conflicts are needed.
5	BACKGROUND	Moreover, these methods need to consider how users' would actually reach an agreement about a solution to the conflict in order to propose solutions that can be acceptable by all of the users affected by the item to be shared.
6	BACKGROUND	Current approaches are either too demanding or only consider fixed ways of aggregating privacy preferences.
7	OBJECTIVE	In this paper, we propose the first computational mechanism to resolve conflicts for multi-party privacy management in Social Media that is able to adapt to different situations by modelling the concessions that users make to reach a solution to the conflicts.
8	RESULTS	We also present results of a user study in which our proposed mechanism outperformed other existing approaches in terms of how many times each approach matched users' behaviour.
1	BACKGROUND	Social networks have well documented effects at the individual and aggregate level.
2	BACKGROUND	Consequently it is often useful to understand how an attempt to influence a network will change its structure and consequently achieve other goals.
3	OBJECTIVE	We develop a framework for network modification that allows for arbitrary objective functions, types of modification (e.g. edge weight addition, edge weight removal, node removal, and covariate value change), and recovery mechanisms (i.e. how a network responds to interventions).
4	OBJECTIVE	The framework outlined in this paper helps both to situate the existing work on network interventions but also opens up many new possibilities for intervening in networks.
5	METHODS	In particular use two case studies to highlight the potential impact of empirically calibrating the objective function and network recovery mechanisms as well as showing how interventions beyond node removal can be optimised.
6	METHODS	First, we simulate an optimal removal of nodes from the Noordin terrorist network in order to reduce the expected number of attacks (based on empirically predicting the terrorist collaboration network from multiple types of network ties).
7	METHODS	Second, we simulate optimally strengthening ties within entrepreneurial ecosystems in six developing countries.
8	METHODS	In both cases we estimate ERGM models to simulate how a network will endogenously evolve after intervention.
1	BACKGROUND	Social media anomaly detection is of critical importance to prevent malicious activities such as bullying, terrorist attack planning, and fraud information dissemination.
2	BACKGROUND	With the recent popularity of social media, new types of anomalous behaviors arise, causing concerns from various parties.
3	BACKGROUND	While a large amount of work have been dedicated to traditional anomaly detection problems, we observe a surge of research interests in the new realm of social media anomaly detection.
4	OBJECTIVE	In this paper, we present a survey on existing approaches to address this problem.
5	METHODS	We focus on the new type of anomalous phenomena in the social media and review the recent developed techniques to detect those special types of anomalies.
6	METHODS	We provide a general overview of the problem domain, common formulations, existing methodologies and potential directions.
7	OBJECTIVE	With this work, we hope to call out the attention from the research community on this challenging problem and open up new directions that we can contribute in the future.
1	BACKGROUND	Real-world social and/or operational networks consist of agents with associated states, whose connectivity forms complex topologies.
2	BACKGROUND	This complexity is further compounded by interconnected information layers, consisting, for instance, documents/resources of the agents which mutually share topical similarities.
3	OBJECTIVE	Our goal in this work is to predict the specific states of the agents, as their observed resources evolve in time and get updated.
4	METHODS	The information diffusion among the agents and the publications themselves effectively result in a dynamic process which we capture by an interconnected system of networks (i.e. layered).
5	METHODS	"More specifically, we use a notion of a supra-Laplacian matrix to address such a generalized diffusion of an interconnected network starting with the classical ""graph Laplacian""."
6	METHODS	The auxiliary and external input update is modeled by a multidimensional Brownian process, yielding two contributions to the variations in the states of the agents: one that is due to the intrinsic interactions in the network system, and the other due to the external inputs or innovations.
7	METHODS	A variation on this theme, a priori knowledge of a fraction of the agents' states is shown to lead to a Kalman predictor problem.
8	METHODS	This helps us refine the predicted states exploiting the error in estimating the states of agents.
9	METHODS	Three real-world datasets are used to evaluate and validate the information diffusion process in this novel layered network approach.
10	RESULTS	Our results demonstrate a lower prediction error when using the interconnected network rather than the single connectivity layer between the agents.
11	METHODS	The prediction error is further improved by using the estimated diffusion connection and by applying the Kalman approach with partial observations.
1	BACKGROUND	The friendship paradox is the phenomenon that in social networks, people on average have fewer friends than their friends do.
2	BACKGROUND	The generalized friendship paradox is an extension to attributes other than the number of friends.
3	BACKGROUND	The friendship paradox and its generalized version have gathered recent attention due to the information they provide about network structure and local inequalities.
4	OBJECTIVE	In this paper, we propose several measures of nodal qualities which capture different aspects of their activities and influence in online social networks.
5	METHODS	Using these measures we analyse the prevalence of the generalized friendship paradox over Twitter and we report high levels of prevalence (up to over 90\% of nodes).
6	METHODS	We contend that this prevalence of the friendship paradox and its generalized version arise because of the hierarchical nature of the connections in the network.
7	METHODS	This hierarchy is nested as opposed to being star-like.
8	RESULTS	We conclude that these paradoxes are collective phenomena not created merely by a minority of well-connected or high-attribute nodes.
9	RESULTS	Moreover, our results show that a large fraction of individuals can experience the generalized friendship paradox even in the absence of a significant correlation between degrees and attributes.
1	OBJECTIVE	We study the strategic aspects of social influence in a society of agents linked by a trust network, introducing a new class of games called games of influence.
2	METHODS	A game of influence is an infinite repeated game with incomplete information in which, at each stage of interaction, an agent can make her opinions visible (public) or invisible (private) in order to influence other agents' opinions.
3	METHODS	The influence process is mediated by a trust network, as we assume that the opinion of a given agent is only affected by the opinions of those agents that she considers trustworthy (i.e., the agents in the trust network that are directly linked to her).
4	METHODS	Each agent is endowed with a goal, expressed in a suitable temporal language inspired from linear temporal logic (LTL).
5	RESULTS	We show that games of influence provide a simple abstraction to explore the effects of the trust network structure on the agents' behaviour, by considering solution concepts from game-theory such as Nash equilibrium, weak dominance and winning strategies.
1	BACKGROUND	Predicting human mobility flows at different spatial scales is challenged by the heterogeneity of individual trajectories and the multi-scale nature of transportation networks.
2	BACKGROUND	As vast amounts of digital traces of human behaviour become available, an opportunity arises to improve mobility models by integrating into them proxy data on mobility collected by a variety of digital platforms and location-aware services.
3	OBJECTIVE	Here we propose a hybrid model of human mobility that integrates a large-scale publicly available dataset from a popular photo-sharing system with the classical gravity model, under a stacked regression procedure.
4	METHODS	We validate the performance and generalizability of our approach using two ground-truth datasets on air travel and daily commuting in the United States: using two different cross-validation schemes we show that the hybrid model affords enhanced mobility prediction at both spatial scales.
1	BACKGROUND	Social network research has begun to take advantage of fine-grained communications regarding coordination, decision-making, and knowledge sharing.
2	BACKGROUND	These studies, however, have not generally analyzed how external events are associated with a social network's structure and communicative properties.
3	OBJECTIVE	Here, we study how external events are associated with a network's change in structure and communications.
4	METHODS	Analyzing a complete dataset of millions of instant messages among the decision-makers in a large hedge fund and their network of outside contacts, we investigate the link between price shocks, network structure, and change in the affect and cognition of decision-makers embedded in the network.
5	RESULTS	When price shocks occur the communication network tends not to display structural changes associated with adaptiveness.
6	RESULTS	"Rather, the network ""turtles up""."
7	RESULTS	It displays a propensity for higher clustering, strong tie interaction, and an intensification of insider vs. outsider communication.
8	RESULTS	Further, we find changes in network structure predict shifts in cognitive and affective processes, execution of new transactions, and local optimality of transactions better than prices, revealing the important predictive relationship between network structure and collective behavior within a social network.
1	BACKGROUND	With the rapid growth in multimedia services and the enormous offers of video contents in online social networks, users have difficulty in obtaining their interests.
2	BACKGROUND	Therefore, various personalized recommendation systems have been proposed.
3	BACKGROUND	However, they ignore that the accelerated proliferation of social media data has led to the big data era, which has greatly impeded the process of video recommendation.
4	BACKGROUND	In addition, none of them has considered both the privacy of users' contexts (e,g., social status, ages and hobbies) and video service vendors' repositories, which are extremely sensitive and of significant commercial value.
5	OBJECTIVE	To handle the problems, we propose a cloud-assisted differentially private video recommendation system based on distributed online learning.
6	METHODS	In our framework, service vendors are modeled as distributed cooperative learners, recommending videos according to user's context, while simultaneously adapting the video-selection strategy based on user-click feedback to maximize total user clicks (reward).
7	METHODS	Considering the sparsity and heterogeneity of big social media data, we also propose a novel geometric differentially private model, which can greatly reduce the performance (recommendation accuracy) loss.
8	RESULTS	Our simulation shows the proposed algorithms outperform other existing methods and keep a delicate balance between computing accuracy and privacy preserving level.
1	OBJECTIVE	This paper presents HEALER, a software agent that recommends sequential intervention plans for use by homeless shelters, who organize these interventions to raise awareness about HIV among homeless youth.
2	METHODS	HEALER's sequential plans (built using knowledge of social networks of homeless youth) choose intervention participants strategically to maximize influence spread, while reasoning about uncertainties in the network.
3	BACKGROUND	While previous work presents influence maximizing techniques to choose intervention participants, they do not address three real-world issues: (i) they completely fail to scale up to real-world sizes; (ii) they do not handle deviations in execution of intervention plans; (iii) constructing real-world social networks is an expensive process.
4	METHODS	HEALER handles these issues via four major contributions: (i) HEALER casts this influence maximization problem as a POMDP and solves it using a novel planner which scales up to previously unsolvable real-world sizes; (ii) HEALER allows shelter officials to modify its recommendations, and updates its future plans in a deviation-tolerant manner; (iii) HEALER constructs social networks of homeless youth at low cost, using a Facebook application.
5	RESULTS	Finally, (iv) we show hardness results for the problem that HEALER solves.
6	BACKGROUND	HEALER will be deployed in the real world in early Spring 2016 and is currently undergoing testing at a homeless shelter.
1	BACKGROUND	Social media can be viewed as a social system where the currency is attention.
2	BACKGROUND	People post content and interact with others to attract attention and gain new followers.
3	OBJECTIVE	In this paper, we examine the distribution of attention across a large sample of users of a popular social media site Twitter.
4	METHODS	Through empirical analysis of these data we conclude that attention is very unequally distributed: the top 20\% of Twitter users own more than 96\% of all followers, 93\% of the retweets, and 93\% of the mentions.
5	METHODS	"We investigate the mechanisms that lead to attention inequality and find that it results from the ""rich-get-richer"" and ""poor-get-poorer"" dynamics of attention diffusion."
6	METHODS	"Namely, users who are ""rich"" in attention, because they are often mentioned and retweeted, are more likely to gain new followers, while those who are ""poor"" in attention are likely to lose followers."
7	METHODS	We develop a phenomenological model that quantifies attention diffusion and network dynamics, and solve it to study how attention inequality grows over time in a dynamic environment of social media.
1	OBJECTIVE	We study the optimal control problem of allocating campaigning resources over the campaign duration and degree classes in a social network.
2	METHODS	Information diffusion is modeled as a Susceptible-Infected epidemic and direct recruitment of susceptible nodes to the infected (informed) class is used as a strategy to accelerate the spread of information.
3	METHODS	We formulate an optimal control problem for optimizing a net reward function, a linear combination of the reward due to information spread and cost due to application of controls.
4	METHODS	The time varying resource allocation and seeds for the epidemic are jointly optimized.
5	METHODS	A problem variation includes a fixed budget constraint.
6	RESULTS	We prove the existence of a solution for the optimal control problem, provide conditions for uniqueness of the solution, and prove some structural results for the controls (e.g. controls are non-increasing functions of time).
7	METHODS	The solution technique uses Pontryagin's Maximum Principle and the forward-backward sweep algorithm (and its modifications) for numerical computations.
8	RESULTS	Our formulations lead to large optimality systems with up to about 200 differential equations and allow us to study the effect of network topology (Erdos-Renyi/scale-free) on the controls.
9	RESULTS	Results reveal that the allocation of campaigning resources to various degree classes depends not only on the network topology but also on system parameters such as cost/abundance of resources.
10	RESULTS	The optimal strategies lead to significant gains over heuristic strategies for various model parameters.
11	CONCLUSIONS	Our modeling approach assumes uncorrelated network, however, we find the approach useful for real networks as well.
12	CONCLUSIONS	This work is useful in product advertising, political and crowdfunding campaigns in social networks.
1	OBJECTIVE	We present a new network model accounting for multidimensional assortativity.
2	METHODS	Each node is characterized by a number of features and the probability of a link between two nodes depends on common features.
3	METHODS	We do not fix a priori the total number of possible features.
4	METHODS	The bipartite network of the nodes and the features evolves according to a stochastic dynamics that depends on three parameters that respectively regulate the preferential attachment in the transmission of the features to the nodes, the number of new features per node, and the power-law behavior of the total number of observed features.
5	METHODS	Our model also takes into account a mechanism of triadic closure.
6	RESULTS	We provide theoretical results and statistical estimators for the parameters of the model.
7	METHODS	We validate our approach by means of simulations and an empirical analysis of a network of scientific collaborations.
1	OBJECTIVE	"We present a corpus-based analysis of the effects of age, gender and region of origin on the production of both ""netspeak"" or ""chatspeak"" features and regional speech features in Flemish Dutch posts that were collected from a Belgian online social network platform."
2	RESULTS	The present study shows that combining quantitative and qualitative approaches is essential for understanding non-standard linguistic variation in a CMC corpus.
3	RESULTS	It also presents a methodology that enables the systematic study of this variation by including all non-standard words in the corpus.
4	RESULTS	The analyses resulted in a convincing illustration of the Adolescent Peak Principle.
5	RESULTS	In addition, our approach revealed an intriguing correlation between the use of regional speech features and chatspeak features.
1	BACKGROUND	With the growing popularity of mobile smart devices, the existing networks are unable to meet the requirement of many complex scenarios; current network architectures and protocols do not work well with the network with high latency and frequent disconnections.
2	BACKGROUND	To improve the performance of these networks some scholars opened up a new research field, delay-tolerant networks, in which one of the important research subjects is the forwarding and routing mechanism of data packets.
3	OBJECTIVE	This paper presents a routing scheme based on social networks owing to the fact that nodes in computer networks and social networks have high behavioural similarity.
4	OBJECTIVE	To further improve efficiency this paper also suggests a mechanism, which is the improved version of an existing betweenness centrality based routing algorithm.
5	RESULTS	The experiments showed that the proposed scheme has better performance than the existing friendship routing algorithms.
1	OBJECTIVE	This paper discusses the experiments carried out by us at Jadavpur University as part of the participation in ICON 2015 task: POS Tagging for Code-mixed Indian Social Media Text.
2	METHODS	The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information from dictionary as well as some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens.
3	METHODS	We submitted runs for Bengali-English, Hindi-English and Tamil-English Language pairs.
4	METHODS	Our system has been trained and tested on the datasets released for ICON 2015 shared task: POS Tagging For Code-mixed Indian Social Media Text.
5	RESULTS	In constrained mode, our system obtains average overall accuracy (averaged over all three language pairs) of 75.60% which is very close to other participating two systems (76.79% for IIITH and 75.79% for AMRITA_CEN) ranked higher than our system.
6	RESULTS	In unconstrained mode, our system obtains average overall accuracy of 70.65% which is also close to the system (72.85% for AMRITA_CEN) which obtains the highest average overall accuracy.
1	BACKGROUND	A large amount of social media hosted on platforms like Flickr and Instagram is related to social events.
2	BACKGROUND	The task of social event classification refers to the distinction of event and non-event-related content as well as the classification of event types (e.g. sports events, concerts, etc.).
3	OBJECTIVE	In this paper, we provide an extensive study of textual, visual, as well as multimodal representations for social event classification.
4	METHODS	We investigate strengths and weaknesses of the modalities and study synergy effects between the modalities.
5	RESULTS	Experimental results obtained with our multimodal representation outperform state-of-the-art methods and provide a new baseline for future research.
1	BACKGROUND	Sparsification reduces the size of networks while preserving structural and statistical properties of interest.
2	BACKGROUND	Various sparsifying algorithms have been proposed in different contexts.
3	OBJECTIVE	We contribute the first systematic conceptual and experimental comparison of \textit{edge sparsification} methods on a diverse set of network properties.
4	RESULTS	It is shown that they can be understood as methods for rating edges by importance and then filtering globally or locally by these scores.
5	RESULTS	We show that applying a local filtering technique improves the preservation of all kinds of properties.
6	OBJECTIVE	In addition, we propose a new sparsification method (\textit{Local Degree}) which preserves edges leading to local hub nodes.
7	METHODS	All methods are evaluated on a set of social networks from Facebook, Google+, Twitter and LiveJournal with respect to network properties including diameter, connected components, community structure, multiple node centrality measures and the behavior of epidemic simulations.
8	METHODS	In order to assess the preservation of the community structure, we also include experiments on synthetically generated networks with ground truth communities.
9	RESULTS	Experiments with our implementations of the sparsification methods (included in the open-source network analysis tool suite NetworKit) show that many network properties can be preserved down to about 20\% of the original set of edges for sparse graphs with a reasonable density.
10	CONCLUSIONS	The experimental results allow us to differentiate the behavior of different methods and show which method is suitable with respect to which property.
11	CONCLUSIONS	While our Local Degree method is best for preserving connectivity and short distances, other newly introduced local variants are best for preserving the community structure.
1	BACKGROUND	Online social networks (OSN) contain extensive amount of information about the underlying society that is yet to be explored.
2	BACKGROUND	One of the most feasible technique to fetch information from OSN, crawling through Application Programming Interface (API) requests, poses serious concerns over the the guarantees of the estimates.
3	OBJECTIVE	In this work, we focus on making reliable statistical inference with limited API crawls.
4	OBJECTIVE	Based on regenerative properties of the random walks, we propose an unbiased estimator for the aggregated sum of functions over edges and proved the connection between variance of the estimator and spectral gap.
5	METHODS	In order to facilitate Bayesian inference on the true value of the estimator, we derive the approximate posterior distribution of the estimate.
6	METHODS	Later the proposed ideas are validated with numerical experiments on inference problems in real-world networks.
1	BACKGROUND	Most sampling techniques for online social networks (OSNs) are based on a particular sampling method on a single graph, which is referred to as a statistics.
2	BACKGROUND	However, various realizing methods on different graphs could possibly be used in the same OSN, and they may lead to different sampling efficiencies, i.e., asymptotic variances.
3	OBJECTIVE	To utilize multiple statistics for accurate measurements, we formulate a mixture sampling problem, through which we construct a mixture unbiased estimator which minimizes asymptotic variance.
4	METHODS	Given fixed sampling budgets for different statistics, we derive the optimal weights to combine the individual estimators; given fixed total budget, we show that a greedy allocation towards the most efficient statistics is optimal.
5	BACKGROUND	In practice, the sampling efficiencies of statistics can be quite different for various targets and are unknown before sampling.
6	METHODS	To solve this problem, we design a two-stage framework which adaptively spends a partial budget to test different statistics and allocates the remaining budget to the inferred best statistics.
7	RESULTS	We show that our two-stage framework is a generalization of 1) randomly choosing a statistics and 2) evenly allocating the total budget among all available statistics, and our adaptive algorithm achieves higher efficiency than these benchmark strategies in theory and experiment.
1	OBJECTIVE	This paper presents the experiments carried out by us at Jadavpur University as part of the participation in FIRE 2015 task: Entity Extraction from Social Media Text - Indian Languages (ESM-IL).
2	METHODS	The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information like gazetteer list, POS tag and some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens.
3	METHODS	We submitted runs for English only.
4	METHODS	A statistical HMM (Hidden Markov Models) based model has been used to implement our system.
5	METHODS	The system has been trained and tested on the datasets released for FIRE 2015 task: Entity Extraction from Social Media Text - Indian Languages (ESM-IL).
6	RESULTS	Our system is the best performer for English language and it obtains precision, recall and F-measures of 61.96, 39.46 and 48.21 respectively.
1	OBJECTIVE	The structure of close communication, contacts and association in social networks is studied in the form of maximal subgraphs of diameter 2 (2-clubs), corresponding to three types of close communities: hamlets, social circles and coteries.
2	METHODS	The concept of borough of a graph is defined and introduced.
3	METHODS	Each borough is a chained union of 2-clubs of the network and any 2-club of the network belongs to one borough.
4	METHODS	Thus the set of boroughs of a network, together with the 2-clubs held by them, are shown to contain the structure of close communication in a network.
5	METHODS	Applications are given with examples from real world network data.
1	BACKGROUND	Suicide is a global public health problem.
2	BACKGROUND	Early detection of individual suicide risk plays a key role in suicide prevention.
3	OBJECTIVE	In this paper, we propose to look into individual suicide risk through time series analysis of personal linguistic expression on social media (Weibo).
4	METHODS	We examined temporal patterns of the linguistic expression of individuals on Chinese social media (Weibo).
5	METHODS	Then, we used such temporal patterns as predictor variables to build classification models for estimating levels of individual suicide risk.
6	METHODS	Characteristics of time sequence curves to linguistic features including parentheses, auxiliary verbs, personal pronouns and body words are reported to affect performance of suicide most, and the predicting model has a accuracy higher than 0.60, shown by the results.
7	RESULTS	This paper confirms the efficiency of the social media data in detecting individual suicide risk.
8	CONCLUSIONS	Results of this study may be insightful for improving the performance of suicide prevention programs.
1	BACKGROUND	Research shows that various social media platforms on Internet such as Twitter, Tumblr (micro-blogging websites), Facebook (a popular social networking website), YouTube (largest video sharing and hosting website), Blogs and discussion forums are being misused by extremist groups for spreading their beliefs and ideologies, promoting radicalization, recruiting members and creating online virtual communities sharing a common agenda.
2	BACKGROUND	Popular microblogging websites such as Twitter are being used as a real-time platform for information sharing and communication during planning and mobilization if civil unrest related events.
3	BACKGROUND	Applying social media intelligence for predicting and identifying online radicalization and civil unrest oriented threats is an area that has attracted several researchers' attention over past 10 years.
4	BACKGROUND	There are several algorithms, techniques and tools that have been proposed in existing literature to counter and combat cyber-extremism and predicting protest related events in much advance.
5	OBJECTIVE	In this paper, we conduct a literature review of all these existing techniques and do a comprehensive analysis to understand state-of-the-art, trends and research gaps.
6	METHODS	We present a one class classification approach to collect scholarly articles targeting the topics and subtopics of our research scope.
7	METHODS	We perform characterization, classification and an in-depth meta analysis meta-anlaysis of about 100 conference and journal papers to gain a better understanding of existing literature.
1	BACKGROUND	Working adults spend nearly one third of their daily time at their jobs.
2	OBJECTIVE	In this paper, we study job-related social media discourse from a community of users.
3	METHODS	We use both crowdsourcing and local expertise to train a classifier to detect job-related messages on Twitter.
4	METHODS	Additionally, we analyze the linguistic differences in a job-related corpus of tweets between individual users vs. commercial accounts.
5	RESULTS	The volumes of job-related tweets from individual users indicate that people use Twitter with distinct monthly, daily, and hourly patterns.
6	CONCLUSIONS	We further show that the moods associated with jobs, positive and negative, have unique diurnal rhythms.
1	BACKGROUND	"Given the ever increasing amount of publicly available social media data, there is growing interest in using online data to study and quantify phenomena in the offline ""real"" world."
2	BACKGROUND	"As social media data can be obtained in near real-time and at low cost, it is often used for ""now-casting"" indices such as levels of flu activity or unemployment."
3	BACKGROUND	"The term ""social sensing"" is often used in this context to describe the idea that users act as ""sensors"", publicly reporting their health status or job losses."
4	BACKGROUND	"Sensor activity during a time period is then typically aggregated in a ""one tweet, one vote"" fashion by simply counting."
5	BACKGROUND	At the same time, researchers readily admit that social media users are not a perfect representation of the actual population.
6	BACKGROUND	Additionally, users differ in the amount of details of their personal lives that they reveal.
7	BACKGROUND	Intuitively, it should be possible to improve now-casting by assigning different weights to different user groups.
8	OBJECTIVE	"In this paper, we ask ""How does social sensing actually work?"""
9	OBJECTIVE	"or, more precisely, ""Whom should we sense--and whom not--for optimal results?""."
10	OBJECTIVE	We investigate how different sampling strategies affect the performance of now-casting of two common offline indices: flu activity and unemployment rate.
11	RESULTS	We show that now-casting can be improved by 1) applying user filtering techniques and 2) selecting users with complete profiles.
12	RESULTS	We also find that, using the right type of user groups, now-casting performance does not degrade, even when drastically reducing the size of the dataset.
13	METHODS	"More fundamentally, we describe which type of users contribute most to the accuracy by asking if ""babblers are better""."
14	CONCLUSIONS	We conclude the paper by providing guidance on how to select better user groups for more accurate now-casting.
1	BACKGROUND	Media sharing is an extremely popular paradigm of social interaction in online social networks (OSNs) nowadays.
2	BACKGROUND	The scalable media access control is essential to perform information sharing among users with various access privileges.
3	OBJECTIVE	In this paper, we present a multi-dimensional scalable media access control (MD-SMAC) system based on the proposed scalable ciphertext policy attribute-based encryption (SCP-ABE) algorithm.
4	METHODS	In the proposed MD-SMAC system, fine-grained access control can be performed on the media contents encoded in a multi-dimensional scalable manner based on data consumers' diverse attributes.
5	RESULTS	Through security analysis, we show that the proposed MC-SMAC system is able to resist collusion attacks.
6	METHODS	Additionally, we conduct experiments to evaluate the efficiency performance of the proposed system, especially on mobile devices.
1	BACKGROUND	Emoticons (e.g., :) and :( ) have been widely used in sentiment analysis and other NLP tasks as features to ma- chine learning algorithms or as entries of sentiment lexicons.
2	OBJECTIVE	In this paper, we argue that while emoticons are strong and common signals of sentiment expression on social media the relationship between emoticons and sentiment polarity are not always clear.
3	BACKGROUND	Thus, any algorithm that deals with sentiment polarity should take emoticons into account but extreme cau- tion should be exercised in which emoticons to depend on.
4	METHODS	First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large re- cent Twitter data set.
5	METHODS	Then we carried out four analyses to examine the relationship between emoticons and sentiment polarity as well as the contexts in which emoticons are used.
6	METHODS	The first analysis surveyed a group of participants for their perceived sentiment polarity of the most frequent emoticons.
7	METHODS	The second analysis examined clustering of words and emoti- cons to better understand the meaning conveyed by the emoti- cons.
8	METHODS	The third analysis compared the sentiment polarity of microblog posts before and after emoticons were removed from the text.
9	METHODS	The last analysis tested the hypothesis that removing emoticons from text hurts sentiment classification by training two machine learning models with and without emoticons in the text respectively.
10	RESULTS	The results confirms the arguments that: 1) a few emoticons are strong and reliable signals of sentiment polarity and one should take advantage of them in any senti- ment analysis; 2) a large group of the emoticons conveys com- plicated sentiment hence they should be treated with extreme caution.
1	BACKGROUND	A social network confers benefits and advantages on individuals (and on groups), the literature refers to these advantages as social capital.
2	OBJECTIVE	This paper presents a micro-founded mathematical model of the evolution of a social network and of the social capital of individuals within the network.
3	RESULTS	The evolution of the network is influenced by the extent to which individuals are homophilic, structurally opportunistic, socially gregarious and by the distribution of types in the society.
4	RESULTS	In the analysis, we identify different kinds of social capital: bonding capital, popularity capital, and bridging capital.
5	RESULTS	Bonding capital is created by forming a circle of connections, homophily increases bonding capital because it makes this circle of connections more homogeneous.
6	RESULTS	Popularity capital leads to preferential attachment: individuals who become popular tend to become more popular because others are more likely to link to them.
7	RESULTS	Homophily creates asymmetries in the levels of popularity attained by different social groups, more gregarious types of agents are more likely to become popular.
8	RESULTS	However, in homophilic societies, individuals who belong to less gregarious, less opportunistic, or major types are likely to be more central in the network and thus acquire a bridging capital.
1	BACKGROUND	Nowadays, internet has changed the world into a global village.
2	BACKGROUND	Social Media has reduced the gaps among the individuals.
3	BACKGROUND	Previously communication was a time consuming and expensive task between the people.
4	BACKGROUND	Social Media has earned fame because it is a cheaper and faster communication provider.
5	BACKGROUND	Besides, social media has allowed us to reduce the gaps of physical distance, it also generates and preserves huge amount of data.
6	BACKGROUND	The data are very valuable and it presents association degree between people and their opinions.
7	OBJECTIVE	The comprehensive analysis of the methods which are used on user behavior prediction is presented in this paper.
8	OBJECTIVE	This comparison will provide a detailed information, pros and cons in the domain of sentiment and opinion mining.
1	BACKGROUND	Social Networking Sites (SNSs) are powerful marketing and communication tools.
2	BACKGROUND	There are hundreds of SNSs that have entered and exited the market over time.
3	BACKGROUND	The coexistence of multiple SNSs is a rarely observed phenomenon.
4	BACKGROUND	Most coexisting SNSs either serve different purposes for its users or have cultural differences among them.
5	BACKGROUND	The introduction of a new SNS with a better set of features can lead to the demise of an existing SNS, as observed in the transition from Orkut to Facebook.
6	OBJECTIVE	The paper proposes a model for analyzing the transition of users from one SNS to another, when a new SNS is introduced in the system.
7	METHODS	The game theoretic model proposed considers two major factors in determining the success of a new SNS.
8	METHODS	The first being time that an old SNS gets to stabilise.
9	METHODS	We study whether the time that a SNS like Facebook received to monopolize its reach had a distinguishable effect.
10	METHODS	The second factor is the set of features showcased by the new SNS.
11	RESULTS	The results of the model are also experimentally verified with data collected by means of a survey.
1	BACKGROUND	Link recommendation has attracted significant attentions from both industry practitioners and academic researchers.
2	BACKGROUND	"In industry, link recommendation has become a standard and most important feature in online social networks, prominent examples of which include ""People You May Know"" on LinkedIn and ""You May Know"" on Google+."
3	BACKGROUND	In academia, link recommendation has been and remains a highly active research area.
4	OBJECTIVE	This paper surveys state-of-the-art link recommendation methods, which can be broadly categorized into learning-based methods and proximity-based methods.
5	OBJECTIVE	We further identify social and economic theories, such as social interaction theory, that underlie these methods and explain from a theoretical perspective why a link recommendation method works.
6	OBJECTIVE	Finally, we propose to extend link recommendation research in several directions that include utility-based link recommendation, diversity of link recommendation, link recommendation from incomplete data, and experimental study of link recommendation.
1	BACKGROUND	Online image sharing in social media sites such as Facebook, Flickr, and Instagram can lead to unwanted disclosure and privacy violations, when privacy settings are used inappropriately.
2	BACKGROUND	With the exponential increase in the number of images that are shared online every day, the development of effective and efficient prediction methods for image privacy settings are highly needed.
3	BACKGROUND	The performance of models critically depends on the choice of the feature representation.
4	OBJECTIVE	In this paper, we present an approach to image privacy prediction that uses deep features and deep image tags as feature representations.
5	METHODS	Specifically, we explore deep features at various neural network layers and use the top layer (probability) as an auto-annotation mechanism.
6	RESULTS	"The results of our experiments show that models trained on the proposed deep features and deep image tags substantially outperform baselines such as those based on SIFT and GIST as well as those that use ""bag of tags"" as features."
1	BACKGROUND	Online Social Networks (OSNs) provide a venue for virtual interactions and relationships between individuals.
2	BACKGROUND	In some communities, OSNs also facilitate arranging online meetings and relationships.
3	BACKGROUND	FetLife, the worlds largest anonymous social network for the BDSM, fetish and kink communities, provides a unique example of an OSN that serves as an interaction space, community organizing tool, and sexual market.
4	OBJECTIVE	In this paper, we present a first look at the characteristics of European members of Fetlife, comprising 504,416 individual nodes with 1,912,196 connections.
5	METHODS	We looked at user characteristics in terms of gender, sexual orientation, and preferred role.
6	METHODS	We further examined the topological and structural properties of groups, as well as the type of interactions and relations between their members.
7	RESULTS	Our results suggest there are important differences between the FetLife community and conventional OSNs.
8	CONCLUSIONS	The network can be characterised by complex gender based interactions both from a sexual market and platonic viewpoint which point to a truly fascinating social network.
1	BACKGROUND	Text actionability detection is the problem of classifying user authored natural language text, according to whether it can be acted upon by a responding agent.
2	OBJECTIVE	In this paper, we propose a supervised learning framework for domain-aware, large-scale actionability classification of social media messages.
3	METHODS	We derive lexicons, perform an in-depth analysis for over 25 text based features, and explore strategies to handle domains that have limited training data.
4	METHODS	We apply these methods to over 46 million messages spanning 75 companies and 35 languages, from both Facebook and Twitter.
5	RESULTS	The models achieve an aggregate population-weighted F measure of 0.78 and accuracy of 0.74, with values of over 0.9 in some cases.
1	OBJECTIVE	In this work, we present the Klout Score, an influence scoring system that assigns scores to 750 million users across 9 different social networks on a daily basis.
2	OBJECTIVE	We propose a hierarchical framework for generating an influence score for each user, by incorporating information for the user from multiple networks and communities.
3	METHODS	Over 3600 features that capture signals of influential interactions are aggregated across multiple dimensions for each user.
4	METHODS	The features are scalably generated by processing over 45 billion interactions from social networks every day, as well as by incorporating factors that indicate real world influence.
5	METHODS	Supervised models trained from labeled data determine the weights for features, and the final Klout Score is obtained by hierarchically combining communities and networks.
6	RESULTS	We validate the correctness of the score by showing that users with higher scores are able to spread information more effectively in a network.
7	RESULTS	Finally, we use several comparisons to other ranking systems to show that highly influential and recognizable users across different domains have high Klout scores.
1	OBJECTIVE	We consider in this paper a networked system of opinion dynamics in continuous time, where the agents are able to evaluate their self-appraisals in a distributed way.
2	METHODS	In the model we formulate, the underlying network topology is described by a rooted digraph.
3	METHODS	For each ordered pair of agents $(i,j)$, we assign a function of self-appraisal to agent $i$, which measures the level of importance of agent $i$ to agent $j$.
4	METHODS	Thus, by communicating only with her neighbors, each agent is able to calculate the difference between her level of importance to others and others' level of importance to her.
5	METHODS	The dynamical system of self-appraisals is then designed to drive these differences to zero.
6	RESULTS	We show that for almost all initial conditions, the trajectory generated by this dynamical system asymptotically converges to an equilibrium point which is exponentially stable.
1	BACKGROUND	With the proliferation of social networking sites (SNSs) such as Facebook and Google+, investigating the impact of SNSs on our lives has become an important research area in recent years.
2	BACKGROUND	Though SNS usage plays a key role in connecting people with friends and families from distant places, SNSs also bring concern for families.
3	OBJECTIVE	We focus on imbalance SNS usage, i.e., an individual remains busy in using SNSs when her family member is expecting to spend time with her.
4	OBJECTIVE	More specifically, we investigate the cause and pattern of imbalance SNS usage and how the emotion of family members may become affected, if they use SNSs in an imbalanced way in a regular manner.
5	BACKGROUND	This paper is the first attempt to identify the relationship between an individual's imbalance SNS usage and the emotion of her family member in the context of a developing country.
1	OBJECTIVE	In this paper, we propose a joint algorithm for the word segmentation on Chinese social media.
2	BACKGROUND	Previous work mainly focus on word segmentation for plain Chinese text, in order to develop a Chinese social media processing tool, we need to take the main features of social media into account, whose grammatical structure is not rigorous, and the tendency of using colloquial and Internet terms makes the existing Chinese-processing tools inefficient to obtain good performance on social media.
3	METHODS	In our approach, we combine CRF and MMSEG algorithm and extend features of traditional CRF algorithm to train the model for word segmentation, We use Internet lexicon in order to improve the performance of our model on Chinese social media.
4	RESULTS	Our experimental result on Sina Weibo shows that our approach outperforms the state-of-the-art model.
1	BACKGROUND	The growing incidents of counterfeiting and associated economic and health consequences necessitate the development of active surveillance systems capable of producing timely and reliable information for all stake holders in the anti-counterfeiting fight.
2	BACKGROUND	User generated content from social media platforms can provide early clues about product allergies, adverse events and product counterfeiting.
3	OBJECTIVE	This paper reports a work in progresswith contributions including: the development of a framework for gathering and analyzing the views and experiences of users of drug and cosmetic products using machine learning, text mining and sentiment analysis, the application of the proposed framework on Facebook comments and data from Twitter for brand analysis, and the description of how to develop a product safety lexicon and training data for modeling a machine learning classifier for drug and cosmetic product sentiment prediction.
4	RESULTS	The initial brand and product comparison results signify the usefulness of text mining and sentiment analysis on social media data while the use of machine learning classifier for predicting the sentiment orientation provides a useful tool for users, product manufacturers, regulatory and enforcement agencies to monitor brand or product sentiment trends in order to act in the event of sudden or significant rise in negative sentiment.
1	BACKGROUND	Analysis of opinion dynamics in social networks plays an important role in today's life.
2	BACKGROUND	For applications such as predicting users' political preference, it is particularly important to be able to analyze the dynamics of competing opinions.
3	BACKGROUND	"While observing the evolution of polar opinions of a social network's users over time, can we tell when the network ""behaved"" abnormally?"
4	BACKGROUND	Furthermore, can we predict how the opinions of the users will change in the future?
5	BACKGROUND	Do opinions evolve according to existing network opinion dynamics models?
6	BACKGROUND	To answer such questions, it is not sufficient to study individual user behavior, since opinions can spread far beyond users' egonets.
7	BACKGROUND	We need a method to analyze opinion dynamics of all network users simultaneously and capture the effect of individuals' behavior on the global evolution pattern of the social network.
8	OBJECTIVE	"In this work, we introduce Social Network Distance (SND) - a distance measure that quantifies the ""cost"" of evolution of one snapshot of a social network into another snapshot under various models of polar opinion propagation."
9	BACKGROUND	SND has a rich semantics of a transportation problem, yet, is computable in time linear in the number of users, which makes SND applicable to the analysis of large-scale online social networks.
10	METHODS	In our experiments with synthetic and real-world Twitter data, we demonstrate the utility of our distance measure for anomalous event detection.
11	RESULTS	It achieves a true positive rate of 0.83, twice as high as that of alternatives.
12	RESULTS	When employed for opinion prediction in Twitter, our method's accuracy is 75.63%, which is 7.5% higher than that of the next best method.
1	BACKGROUND	Device-to-device (D2D) communication has seen as a major technology to overcome the imminent wireless capacity crunch and to enable new application services.
2	OBJECTIVE	In this paper, we propose a social-aware approach for optimizing D2D communication by exploiting two layers: the social network and the physical wireless layers.
3	METHODS	First we formulate the physical layer D2D network according to users' encounter histories.
4	OBJECTIVE	Subsequently, we propose an approach, based on the so-called Indian Buffet Process, so as to model the distribution of contents in users' online social networks.
5	METHODS	Given the social relations collected by the Evolved Node B (eNB), we jointly optimize the traffic offloading process in D2D communication.
6	METHODS	In addition, we give the Chernoff bound and approximated cumulative distribution function (CDF) of the offloaded traffic.
7	RESULTS	In the simulation, we proved the effectiveness of the bound and CDF.
8	RESULTS	The numerical results based on real traces show that the proposed approach offload the traffic of eNB's successfully.
1	BACKGROUND	Social networks, due to their popularity, have been studied extensively these years.
2	BACKGROUND	A rich body of these studies is related to influence maximization, which aims to select a set of seed nodes for maximizing the expected number of active nodes at the end of the process.
3	BACKGROUND	However, the set of active nodes can not fully represent the true coverage of information propagation.
4	BACKGROUND	A node may be informed of the information when any of its neighbours become active and try to activate it, though this node (namely informed node) is still inactive.
5	BACKGROUND	Therefore, we need to consider both active nodes and informed nodes that are aware of the information when we study the coverage of information propagation in a network.
6	OBJECTIVE	Along this line, in this paper we propose a new problem called Information Coverage Maximization that aims to maximize the expected number of both active nodes and informed ones.
7	RESULTS	After we prove that this problem is NP-hard and submodular in the independent cascade model and the linear threshold model, we design two algorithms to solve it.
8	RESULTS	Extensive experiments on three real-world data sets demonstrate the performance of the proposed algorithms.
1	BACKGROUND	Some social networks, such as LinkedIn and ResearchGate, allow user endorsements for specific skills.
2	BACKGROUND	In this way, for each skill we get a directed graph where the nodes correspond to users' profiles and the arcs represent endorsement relations.
3	BACKGROUND	From the number and quality of the endorsements received, an authority score can be assigned to each profile.
4	OBJECTIVE	In this paper we propose an authority score computation method that takes into account the relations existing among different skills.
5	METHODS	Our method is based on enriching the information contained in the digraph of endorsements corresponding to a specific skill, and then applying a ranking method admitting weighted digraphs, such as PageRank.
6	METHODS	We describe the method, and test it on a synthetic network of 1493 nodes, fitted with endorsements.
1	BACKGROUND	This work weakens well-known consistency models using graphs that capture applications' characteristics.
2	BACKGROUND	The weakened models not only respect application semantic, but also yield a performance benefit.
3	OBJECTIVE	We introduce a notion of dependency graphs, which specify relations between events that are important with respect to application semantic, and then weaken traditional consistency models (e.g., causal consistency) using these graphs.
4	METHODS	Particularly, we consider two types of graphs: intra-process and inter-process dependency graphs, where intra-process dependency graphs specify how events in a single process are related, and inter-process dependency graphs specify how events across multiple processes are related.
5	METHODS	Then, based on these two types of graphs, we define new consistency model, namely {\em application-aware} consistency.
6	METHODS	We also discuss why such application-aware consistency can be useful in social network applications.
7	CONCLUSIONS	This is a work in progress, and we present early ideas regarding application-aware consistency here.
1	BACKGROUND	A social network grows over a period of time with the formation of new connections and relations.
2	BACKGROUND	In recent years we have witnessed a massive growth of online social networks like Facebook, Twitter etc.
3	BACKGROUND	So it has become a problem of extreme importance to know the destiny of these networks.
4	BACKGROUND	Thus predicting the evolution of a social network is a question of extreme importance.
5	BACKGROUND	A good model for evolution of a social network can help in understanding the properties responsible for the changes occurring in a network structure.
6	OBJECTIVE	In this paper we propose such a model for evolution of social networks.
7	METHODS	We model the social network as an undirected graph where nodes represent people and edges represent the friendship between them.
8	METHODS	We define the evolution process as a set of rules which resembles very closely to how a social network grows in real life.
9	METHODS	We simulate the evolution process and show, how starting from an initial network, a network evolves using this model.
10	METHODS	We also discuss how our model can be used to model various complex social networks other than online social networks like political networks, various organizations etc..
1	BACKGROUND	A patient-centric approach to healthcare leads to an informal social network among medical professionals.
2	OBJECTIVE	This chapter presents a research framework to: identify the collaboration structure among physicians that is effective and efficient for patients, discover effective structural attributes of a collaboration network that evolves during the course of providing care, and explore the impact of socio-demographic characteristics of healthcare professionals, patients, and hospitals on collaboration structures, from the point of view of measurable outcomes such as cost and quality of care.
3	METHODS	The framework uses illustrative examples drawn from a data set of patients undergoing hip replacement surgery.
1	BACKGROUND	Many decentralized online social networks (DOSNs) have been proposed due to an increase in awareness related to privacy and scalability issues in centralized social networks.
2	BACKGROUND	Such decentralized networks transfer processing and storage functionalities from the service providers towards the end users.
3	BACKGROUND	DOSNs require individualistic implementation for services, (i.e., search, information dissemination, storage, and publish/subscribe).
4	BACKGROUND	However, many of these services mostly perform social queries, where OSN users are interested in accessing information of their friends.
5	OBJECTIVE	In our work, we design a socially-aware distributed hash table (DHTs) for efficient implementation of DOSNs.
6	OBJECTIVE	In particular, we propose a gossip-based algorithm to place users in a DHT, while maximizing the social awareness among them.
7	RESULTS	Through a set of experiments, we show that our approach reduces the lookup latency by almost 30% and improves the reliability of the communication by nearly 10% via trusted contacts.
1	BACKGROUND	Link prediction is an important network science problem in many domains such as social networks, chem/bio-informatics, etc.
2	BACKGROUND	Most of these networks are dynamic in nature with patterns evolving over time.
3	BACKGROUND	In such cases, it is necessary to incorporate time in the mining process in a seamless manner to aid in better prediction performance.
4	OBJECTIVE	We propose a two-step solution strategy to the link prediction problem in dynamic networks in this work.
5	METHODS	The first step involves a novel yet simple feature construction approach using a combination of domain and topological attributes of the graph.
6	METHODS	In the second phase, we perform unconstrained edge selection to identify potential candidates for prediction by any generic two-class learner.
7	METHODS	We design various experiments on a real world collaboration network and show the effectiveness of our approach.
1	BACKGROUND	Social media is a rich source of rumours and corresponding community reactions.
2	BACKGROUND	Rumours reflect different characteristics, some shared and some individual.
3	OBJECTIVE	We formulate the problem of classifying tweet level judgements of rumours as a supervised learning task.
4	METHODS	Both supervised and unsupervised domain adaptation are considered, in which tweets from a rumour are classified on the basis of other annotated rumours.
5	RESULTS	We demonstrate how multi-task learning helps achieve good results on rumours from the 2011 England riots.
1	BACKGROUND	Rumor source identification in large social networks has received significant attention lately.
2	BACKGROUND	Most recent works deal with the scale of the problem by observing a subset of the nodes in the network, called sensors, to estimate the source.
3	OBJECTIVE	This paper addresses the problem of locating the source of a rumor in large social networks where some of these sensor nodes have failed.
4	METHODS	We estimate the missing information about the sensors using doubly non-negative (DN) matrix completion and compressed sensing techniques.
5	METHODS	This is then used to identify the actual source by using a maximum likelihood estimator we developed earlier, on a large data set from Sina Weibo.
6	RESULTS	Results indicate that the estimation techniques result in almost as good a performance of the ML estimator as for the network for which complete information is available.
7	CONCLUSIONS	To the best of our knowledge, this is the first research work on source identification with incomplete information in social networks.
1	BACKGROUND	Cyberbullying is a growing problem affecting more than half of all American teens.
2	OBJECTIVE	The main goal of this paper is to investigate fundamentally new approaches to understand and automatically detect and predict incidents of cyberbullying in Instagram, a media-based mobile social network.
3	METHODS	In this work, we have collected a sample data set consisting of Instagram images and their associated comments.
4	METHODS	We then designed a labeling study and employed human contributors at the crowd-sourced CrowdFlower website to label these media sessions for cyberbullying.
5	METHODS	A detailed analysis of the labeled data is then presented, including a study of relationships between cyberbullying and a host of features such as cyberaggression, profanity, social graph features, temporal commenting behavior, linguistic content, and image content.
6	METHODS	Using the labeled data, we further design and evaluate the performance of classifiers to automatically detect and pre- dict incidents of cyberbullying and cyberaggression.
1	BACKGROUND	"Most of the distributed protocols for multi-agent consensus assume that the agents are mutually cooperative and ""trustful,"" and so the couplings among the agents bring the values of their states closer."
2	BACKGROUND	Opinion dynamics in social groups, however, require beyond these conventional models due to ubiquitous competition and distrust between some pairs of agents, which are usually characterized by repulsive couplings and may lead to clustering of the opinions.
3	BACKGROUND	A simple yet insightful model of opinion dynamics with both attractive and repulsive couplings was proposed recently by C.
4	BACKGROUND	Altafini, who examined first-order consensus algorithms over static signed graphs.
5	BACKGROUND	This protocol establishes modulus consensus, where the opinions become the same in modulus but may differ in signs.
6	OBJECTIVE	In this paper, we extend the modulus consensus model to the case where the network topology is an arbitrary time-varying signed graph and prove reaching modulus consensus under mild sufficient conditions of uniform connectivity of the graph.
7	METHODS	For cut-balanced graphs, not only sufficient, but also necessary conditions for modulus consensus are given.
1	BACKGROUND	Fashion is a multi-billion dollar industry with social and economic implications worldwide.
2	BACKGROUND	To gain popularity, brands want to be represented by the top popular models.
3	BACKGROUND	As new faces are selected using stringent (and often criticized) aesthetic criteria, \emph{a priori} predictions are made difficult by information cascades and other fundamental trend-setting mechanisms.
4	BACKGROUND	However, the increasing usage of social media within and without the industry may be affecting this traditional system.
5	OBJECTIVE	We therefore seek to understand the ingredients of success of fashion models in the age of Instagram.
6	METHODS	Combining data from a comprehensive online fashion database and the popular mobile image-sharing platform, we apply a machine learning framework to predict the tenure of a cohort of new faces for the 2015 Spring\,/\,Summer season throughout the subsequent 2015-16 Fall\,/\,Winter season.
7	RESULTS	Our framework successfully predicts most of the new popular models who appeared in 2015.
8	CONCLUSIONS	In particular, we find that a strong social media presence may be more important than being under contract with a top agency, or than the aesthetic standards sought after by the industry.
1	BACKGROUND	Many societies are organized in networks that are formed by people who meet and interact over time.
2	OBJECTIVE	In this paper, we present a first model to capture the micro-foundations of social networks evolution, where boundedly rational agents of different types join the network; meet other agents stochastically over time; and consequently decide to form social ties.
3	OBJECTIVE	A basic premise of our model is that in real-world networks, agents form links by reasoning about the benefits that agents they meet over time can bestow.
4	OBJECTIVE	We study the evolution of the emerging networks in terms of friendship and popularity acquisition given the following exogenous parameters: structural opportunism, type distribution, homophily, and social gregariousness.
5	RESULTS	"We show that the time needed for an agent to find ""friends"" is influenced by the exogenous parameters: agents who are more gregarious, more homophilic, less opportunistic, or belong to a type ""minority"" spend a longer time on average searching for friendships."
6	RESULTS	Moreover, we show that preferential attachment is a consequence of an emerging doubly preferential meeting process: a process that guides agents of a certain type to meet more popular similar-type agents with a higher probability, thereby creating asymmetries in the popularity evolution of different types of agents.
1	OBJECTIVE	We present a system for the classification of mountain panoramas from user-generated photographs followed by identification and extraction of mountain peaks from those panoramas.
2	METHODS	We have developed an automatic technique that, given as input a geo-tagged photograph, estimates its FOV (Field Of View) and the direction of the camera using a matching algorithm on the photograph edge maps and a rendered view of the mountain silhouettes that should be seen from the observer's point of view.
3	METHODS	The extraction algorithm then identifies the mountain peaks present in the photograph and their profiles.
4	CONCLUSIONS	We discuss possible applications in social fields such as photograph peak tagging on social portals, augmented reality on mobile devices when viewing a mountain panorama, and generation of collective intelligence systems (such as environmental models) from massive social media collections (e.g. snow water availability maps based on mountain peak states extracted from photograph hosting services).
1	BACKGROUND	Identifying the most influential individuals can provide invaluable help in developing and deploying effective viral marketing strategies.
2	BACKGROUND	Previous studies mainly focus on designing efficient algorithms or heuristics to find top-K influential nodes on a given static social network.
3	BACKGROUND	While, as a matter of fact, real-world social networks keep evolving over time and a recalculation upon the changed network inevitably leads to a long running time, significantly affecting the efficiency.
4	OBJECTIVE	In this paper, we observe from real-world traces that the evolution of social network follows the preferential attachment rule and the influential nodes are mainly selected from high-degree nodes.
5	OBJECTIVE	Such observations shed light on the design of IncInf, an incremental approach that can efficiently locate the top-K influential individuals in evolving social networks based on previous information instead of calculation from scratch.
6	OBJECTIVE	In particular, IncInf quantitatively analyzes the influence spread changes of nodes by localizing the impact of topology evolution to only local regions, and a pruning strategy is further proposed to effectively narrow the search space into nodes experiencing major increases or with high degrees.
7	METHODS	We carried out extensive experiments on real-world dynamic social networks including Facebook, NetHEPT, and Flickr.
8	RESULTS	Experimental results demonstrate that, compared with the state-of-the-art static heuristic, IncInf achieves as much as 21X speedup in execution time while maintaining matching performance in terms of influence spread.
1	OBJECTIVE	This paper introduces LABurst, a general technique for identifying key moments, or moments of high impact, in social media streams without the need for domain-specific information or seed keywords.
2	METHODS	We leverage machine learning to model temporal patterns around bursts in Twitter's unfiltered public sample stream and build a classifier to identify tokens experiencing these bursts.
3	RESULTS	We show LABurst performs competitively with existing burst detection techniques while simultaneously providing insight into and detection of unanticipated moments.
4	METHODS	To demonstrate our approach's potential, we compare two baseline event-detection algorithms with our language-agnostic algorithm to detect key moments across three major sporting competitions: 2013 World Series, 2014 Super Bowl, and 2014 World Cup.
5	RESULTS	Our results show LABurst outperforms a time series analysis baseline and is competitive with a domain-specific baseline even though we operate without any domain knowledge.
6	METHODS	We then go further by transferring LABurst's models learned in the sports domain to the task of identifying earthquakes in Japan and show our method detects large spikes in earthquake-related tokens within two minutes of the actual event.
1	BACKGROUND	Mobile sensing is an emerging technology that utilizes agent-participatory data for decision making or state estimation, including multimedia applications.
2	OBJECTIVE	This article investigates the structure of mobile sensing schemes and introduces crowdsourcing methods for mobile sensing.
3	BACKGROUND	Inspired by social network, one can establish trust among participatory agents to leverage the wisdom of crowds for mobile sensing.
4	BACKGROUND	A prototype of social network inspired mobile multimedia and sensing application is presented for illustrative purpose.
5	RESULTS	Numerical experiments on real-world datasets show improved performance of mobile sensing via crowdsourcing.
6	RESULTS	Challenges for mobile sensing with respect to Internet layers are discussed.
1	BACKGROUND	Online social networks such as Facebook disclose an unprecedented volume of personal information amplifying the occasions for social comparisons.
2	OBJECTIVE	We test the hypothesis that the use of social networking sites (SNS) increases people's dissatisfaction with their income.
3	METHODS	After addressing endogeneity issues, our results suggest that SNS users have a higher probability to compare their achievements with those of others.
4	CONCLUSIONS	This effect seems stronger than the one exerted by TV watching, it is particularly strong for younger people, and it affects men and women in a similar way.
1	OBJECTIVE	In this work, we are interested on the analysis of competing marketing campaigns between an incumbent who dominates the market and a challenger who wants to enter the market.
2	OBJECTIVE	We are interested in (a) the simultaneous decision of how many resources to allocate to their potential customers to advertise their products for both marketing campaigns, and (b) the optimal allocation on the situation in which the incumbent knows the entrance of the challenger and thus can predict its response.
3	OBJECTIVE	Applying results from game theory, we characterize these optimal strategic resource allocations for the voter model of social networks.
1	BACKGROUND	Recent research has established both a theoretical basis and strong empirical evidence that effective social behavior plays a beneficial role in the maintenance of physical and psychological well-being of people.
2	OBJECTIVE	To test whether social behavior and well-being are also associated in online communities, we studied the correlations between the recovery of patients with mental disorders and their behaviors in online social media.
3	METHODS	As the source of the data related to the social behavior and progress of mental recovery, we used PatientsLikeMe (PLM), the world's first open-participation research platform for the development of patient-centered health outcome measures.
4	METHODS	We first constructed an online social network structure based on patient-to-patient ties among 200 patients obtained from PLM.
5	METHODS	"We then characterized patients' online social activities by measuring the numbers of ""posts and views"" and ""helpful marks"" each patient obtained."
6	METHODS	The patients' recovery data were obtained from their self-reported status information that was also available on PLM.
7	RESULTS	We found that some node properties (in-degree, eigenvector centrality and PageRank) and the two online social activity measures were significantly correlated with patients' recovery.
8	CONCLUSIONS	Furthermore, we re-collected the patients' recovery data two months after the first data collection.
9	RESULTS	We found significant correlations between the patients' social behaviors and the second recovery data, which were collected two months apart.
10	RESULTS	Our results indicated that social interactions in online communities such as PLM were significantly associated with the current and future recoveries of patients with mental disorders.
1	OBJECTIVE	We present in this paper a novel approach for as-you-type top-$k$ keyword search over social media.
2	METHODS	"We adopt a natural ""network-aware"" interpretation for information relevance, by which information produced by users who are closer to the seeker is considered more relevant."
3	BACKGROUND	In practice, this query model poses new challenges for effectiveness and efficiency in online search, even when a complete query is given as input in one keystroke.
4	BACKGROUND	This is mainly because it requires a joint exploration of the social space and classic IR indexes such as inverted lists.
5	METHODS	We describe a memory-efficient and incremental prefix-based retrieval algorithm, which also exhibits an anytime behavior, allowing to output the most likely answer within any chosen running-time limit.
6	METHODS	We evaluate it through extensive experiments for several applications and search scenarios, including searching for posts in micro-blogging (Twitter and Tumblr), as well as searching for businesses based on reviews in Yelp.
7	RESULTS	They show that our solution is effective in answering real-time as-you-type searches over social media.
1	BACKGROUND	The Alexandria system under development at IBM Research provides an extensible framework and platform for supporting a variety of big-data analytics and visualizations.
2	BACKGROUND	The system is currently focused on enabling rapid exploration of text-based social media data.
3	BACKGROUND	"The system provides tools to help with constructing ""domain models"" (i.e., families of keywords and extractors to enable focus on tweets and other social media documents relevant to a project), to rapidly extract and segment the relevant social media and its authors, to apply further analytics (such as finding trends and anomalous terms), and visualizing the results."
4	BACKGROUND	The system architecture is centered around a variety of REST-based service APIs to enable flexible orchestration of the system capabilities; these are especially useful to support knowledge-worker driven iterative exploration of social phenomena.
5	BACKGROUND	The architecture also enables rapid integration of Alexandria capabilities with other social media analytics system, as has been demonstrated through an integration with IBM Research's SystemG.
6	OBJECTIVE	This paper describes a prototypical usage scenario for Alexandria, along with the architecture and key underlying analytics.
1	OBJECTIVE	In this study, we looked at the effect of promotion in the speed and width of spread of information on the Internet by tracking the diffusion of news articles over a social network.
2	BACKGROUND	Speed of spread means the number of readers that the news has reached in a given time, while width of spread means how far the story has travelled from the news originator within the social network.
3	RESULTS	After analyzing six stories in a 30-hour time span, we found out that the lifetime of a story's popularity among the members of the social network has three phases: Expansion, Front-page, and Saturation.
4	RESULTS	Expansion phase starts when a story is published and the article spreads from a source node to nodes within a connected component of the social network.
5	RESULTS	Front-page phase happens when a news aggregator promotes the story in its front page resulting to the story's faster rate of spread among the connected nodes while at the same time spreading the article to nodes outside the original connected component of the social network.
6	RESULTS	Saturation phase is when the story ages and its rate of spread within the social network slows down, suggesting popularity saturation among the nodes.
7	RESULTS	Within these three phases, we observed minimal changes on the width of information spread as suggested by relatively low increase of the width of the spread's diameter within the social network.
8	CONCLUSIONS	We see that this paper provides the various stakeholders a first-hand empirical data for modeling, designing, and improving the current web-based services, specifically the IT educators for designing and improving academic curricula, and for improving the current web-enabled deployment of knowledge and online evaluation of skills.
1	BACKGROUND	Due the success of emerging Web 2.0, and different social network Web sites such as Amazon and movie lens, recommender systems are creating unprecedented opportunities to help people browsing the web when looking for relevant information, and making choices.
2	BACKGROUND	Generally, these recommender systems are classified in three categories: content based, collaborative filtering, and hybrid based recommendation systems.
3	BACKGROUND	Usually, these systems employ standard recommendation methods such as artificial neural networks, nearest neighbor, or Bayesian networks.
4	BACKGROUND	However, these approaches are limited compared to methods based on web applications, such as social networks or semantic web.
5	OBJECTIVE	In this paper, we propose a novel approach for recommendation systems called semantic social recommendation systems that enhance the analysis of social networks exploiting the power of semantic social network analysis.
6	METHODS	Experiments on real-world data from Amazon examine the quality of our recommendation method as well as the performance of our recommendation algorithms.
1	OBJECTIVE	This paper describes a Social Network Analysis toolkit to monitor an Enterprise Social Network and help analyzing informal leadership as a function of social ties and topic discussions.
2	METHODS	The toolkit has been developed in the context of a regional project, Fiordaliso, funded by Regione Lazio (a region of central Italy) and leaded by Reply, an international network of specialized companies in the field of digital services.
1	OBJECTIVE	We study how users of multiple online social networks (OSNs) employ and share information by studying a common user pool that use six OSNs - Flickr, Google+, Instagram, Tumblr, Twitter, and YouTube.
2	METHODS	We analyze the temporal and topical signature of users' sharing behaviour, showing how they exhibit distinct behaviorial patterns on different networks.
3	METHODS	We also examine cross-sharing (i.e., the act of user broadcasting their activity to multiple OSNs near-simultaneously), a previously-unstudied behaviour and demonstrate how certain OSNs play the roles of originating source and destination sinks.
1	BACKGROUND	Influence maximization is a problem of finding a small set of highly influential users, also known as seeds, in a social network such that the spread of influence under certain propagation models is maximized.
2	OBJECTIVE	In this paper, we consider time-critical influence maximization, in which one wants to maximize influence spread within a given deadline.
3	METHODS	Since timing is considered in the optimization, we also extend the Independent Cascade (IC) model and the Linear Threshold (LT) model to incorporate the time delay aspect of influence diffusion among individuals in social networks.
4	RESULTS	We show that time-critical influence maximization under the time-delayed IC and LT models maintains desired properties such as submodularity, which allows a greedy approximation algorithm to achieve an approximation ratio of $1-1/e$.
5	METHODS	To overcome the inefficiency of the greedy algorithm, we design two heuristic algorithms: the first one is based on a dynamic programming procedure that computes exact influence in tree structures and directed acyclic subgraphs, while the second one converts the problem to one in the original models and then applies existing fast heuristic algorithms to it.
6	RESULTS	Our simulation results demonstrate that our algorithms achieve the same level of influence spread as the greedy algorithm while running a few orders of magnitude faster, and they also outperform existing fast heuristics that disregard the deadline constraint and delays in diffusion.
1	BACKGROUND	Small Group evolution has been of central importance in social sciences and also in the industry for understanding dynamics of team formation.
2	BACKGROUND	While most of research works studying groups deal at a macro level with evolution of arbitrary size communities, in this paper we restrict ourselves to studying evolution of small group (size $\leq20$) which is governed by contrasting sociological phenomenon.
3	OBJECTIVE	Given a previous history of group collaboration between a set of actors, we address the problem of predicting likely future group collaborations.
4	BACKGROUND	Unfortunately, predicting groups requires choosing from $n \choose r$ possibilities (where $r$ is group size and $n$ is total number of actors), which becomes computationally intractable as group size increases.
5	BACKGROUND	However, our statistical analysis of a real world dataset has shown that two processes: an external actor joining an existing group (incremental accretion (IA)) or collaborating with a subset of actors of an exiting group (subgroup accretion (SA)), are largely responsible for future group formation.
6	BACKGROUND	This helps to drastically reduce the $n\choose r$ possibilities.
7	METHODS	We therefore, model the attachment of a group for different actors outside this group.
8	METHODS	In this paper, we have built three topology based prediction models to study these phenomena.
9	METHODS	The performance of these models is evaluated using extensive experiments over DBLP dataset.
10	RESULTS	Our prediction results shows that the proposed models are significantly useful for future group predictions both for IA and SA.
1	BACKGROUND	A social network consists of a set of actors and a set of relationships between them which describe certain patterns of communication.
2	BACKGROUND	Most current networks are huge and difficult to analyze and visualize.
3	BACKGROUND	One of the methods frequently used is to extract the most important features, namely to create a certain abstraction, that is the transformation of a large network to a much smaller one, so the latter is a useful summary of the original one, still keeping the most important characteristics.
4	OBJECTIVE	In the case of a social network it can be achieved in two ways.
5	METHODS	One is to find groups of actors and present only them and relationships between them.
6	METHODS	The other is to find actors who play similar roles and to construct a smaller network in which the connection between the actors would be replaced with connections between the roles.
7	CONCLUSIONS	Classifying actors by the roles they are playing in the network can help to understand 'who is who' in a social network.
8	CONCLUSIONS	This classification can be very useful, because it gives us a comprehensive view of the network and helps to understand how the network is organized, and to predict how it could behave in the case of certain events (internal or external).
1	BACKGROUND	Online social networking (OSN) has become of great influence to Filipinos, where Facebook, Twitter, LinkedIn, Google+, and Instagram are among the popular ones.
2	BACKGROUND	Their popularity, coupled with their intuitive and interactive use, allow one's personal information such as gender, age, address, relationship status, and list of friends to become publicly available.
3	BACKGROUND	The accessibility of information from these sites allow, with the aid of computers, for the study of a wide population's characteristics even in a provincial scale.
4	BACKGROUND	Aside from being neighbouring locales, the respective residents of Laguna and Batangas both derive their livelihoods from two lakes, Laguna de Bay and Taal Lake.
5	BACKGROUND	Both residents experience similar problems, such as that, among many others, of fish kill.
6	OBJECTIVE	The goal of this research is to find out similarities in their respective online populations, particularly that of Facebook's.
7	RESULTS	With the use of computational dynamic social network analysis (CDSNA), we found out that the two communities are similar, among others, as follows:   o Both populations are dominated by single young female   o Homophily was observed when choosing a friend in terms of age (i.e., friendships were created more often between people whose ages do not differ by at most five years); and   o Heterophily was observed when choosing friends in terms of gender (i.e., more friendships were created between a male and a female than between both people of the same gender).
8	RESULTS	This paper also presents the differences in the structure of the two social networks, such as degrees of separation and preferential attachment.
1	BACKGROUND	One of the most significant current challenges in large-scale online social networks, is to establish a concise and coherent method able to collect and summarize data.
2	BACKGROUND	Sampling the content of an Online Social Network (OSN) plays an important role as a knowledge discovery tool.
3	BACKGROUND	It is becoming increasingly difficult to ignore the fact that current sampling methods must cope with a lack of a full sampling frame i.e., there is an imposed condition determined by a limited data access.
4	BACKGROUND	In addition, another key aspect to take into account is the huge amount of data generated by users of social networking services.
5	BACKGROUND	This type of conditions make especially difficult to develop sampling methods to collect truly reliable data.
6	OBJECTIVE	Therefore, we propose a low computational cost method for sampling emerging global trends on social networking services such as Twitter.
7	OBJECTIVE	The main purpose of this study, is to develop a methodology able to carry out an efficient collecting process via three random generators: Brownian, Illusion and Reservoir.
8	METHODS	These random generators will be combined with a Metropolis-Hastings Random Walk (MHRW) in order to improve the sampling process.
9	METHODS	We demonstrate the effectiveness of our approach by correctly providing a descriptive statistics of the collected data.
10	METHODS	In addition, we also sketch the collecting procedure on real-time carried out on Twitter.
11	CONCLUSIONS	Finally, we conclude with a trend concentration graphical description and a formal convergence analysis to evaluate whether the sample of draws has attained an equilibrium state to get a rough estimate of the sample quality.
1	BACKGROUND	Many real incidents demonstrate that users of Online Social Networks need mechanisms that help them manage their interactions by increasing the awareness of the different contexts that coexist in Online Social Networks and preventing them from exchanging inappropriate information in those contexts or disseminating sensitive information from some contexts to others.
2	BACKGROUND	Contextual integrity is a privacy theory that conceptualises the appropriateness of information sharing based on the contexts in which this information is to be shared.
3	BACKGROUND	Computational models of Contextual Integrity assume the existence of well-defined contexts, in which individuals enact pre-defined roles and information sharing is governed by an explicit set of norms.
4	BACKGROUND	However, contexts in Online Social Networks are known to be implicit, unknown a priori and ever changing; users relationships are constantly evolving; and the information sharing norms are implicit.
5	BACKGROUND	This makes current Contextual Integrity models not suitable for Online Social Networks.
6	OBJECTIVE	In this paper, we propose the first computational model of Implicit Contextual Integrity, presenting an information model and an Information Assistant Agent that uses the information model to learn implicit contexts, relationships and the information sharing norms to help users avoid inappropriate information exchanges and undesired information disseminations.
7	METHODS	Through an experimental evaluation, we validate the properties of Information Assistant Agents, which are shown to: infer the information sharing norms even if a small proportion of the users follow the norms and in presence of malicious users; help reduce the exchange of inappropriate information and the dissemination of sensitive information with only a partial view of the system and the information received and sent by their users; and minimise the burden to the users in terms of raising unnecessary alerts.
1	OBJECTIVE	This paper describes how people living in armed conflict environments use social media as a participatory news platform, in lieu of damaged state and media apparatuses.
2	METHODS	We investigate this by analyzing the microblogging practices of Mexican citizens whose everyday life is affected by the Drug War.
3	METHODS	We provide a descriptive analysis of the phenomenon, combining content and quantitative Twitter data analyses.
4	METHODS	We focus on three interrelated phenomena: general participation patterns of ordinary citizens, the emergence and role of information curators, and the tension between governmental regulation and drug cartel intimidation.
5	RESULTS	This study reveals the complex tensions among citizens, media actors, and the government in light of large scale organized crime.
1	BACKGROUND	Social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts.
2	OBJECTIVE	We study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict.
3	METHODS	Specifically, we examine three established affect measures: negative affect, activation, and dominance as observed on Twitter in relation to a number of statistics on protracted violence in four major cities afflicted by the Mexican Drug War.
4	METHODS	During a two year period (Aug 2010-Dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in Twitter posts: aspects known to be psychological markers of desensitization.
5	CONCLUSIONS	We discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.
1	OBJECTIVE	In this paper we describe the ways participants of the Scratch online community, primarily young people, engage in remixing of each others' shared animations, games, and interactive projects.
2	OBJECTIVE	In particular, we try to answer the following questions: How do users respond to remixing in a social media environment where remixing is explicitly permitted?
3	OBJECTIVE	What qualities of originators and their projects correspond to a higher likelihood of plagiarism accusations?
4	OBJECTIVE	Is there a connection between plagiarism complaints and similarities between a remix and the work it is based on?
5	RESULTS	Our findings indicate that users have a very wide range of reactions to remixing and that as many users react positively as accuse remixers of plagiarism.
6	METHODS	We test several hypotheses that might explain the high number of plagiarism accusations related to original project complexity, cumulative remixing, originators' integration into remixing practice, and remixee-remixer project similarity, and find support for the first and last explanations.
1	BACKGROUND	For the purpose of propagating information and ideas through a social network, a seeding strategy aims to find a small set of seed users that are able to maximize the spread of the influence, which is termed as influence maximization problem.
2	BACKGROUND	Despite a large number of works have studied this problem, the existing seeding strategies are limited to the static social networks.
3	BACKGROUND	In fact, due to the high speed data transmission and the large population of participants, the diffusion processes in real-world social networks have many aspects of uncertainness.
4	BACKGROUND	Unfortunately, as shown in the experiments, in such cases the state-of-art seeding strategies are pessimistic as they fails to trace the dynamic changes in a social network.
5	OBJECTIVE	In this paper, we study the strategies selecting seed users in an adaptive manner.
6	METHODS	We first formally model the Dynamic Independent Cascade model and introduce the concept of adaptive seeding strategy.
7	RESULTS	Then based on the proposed model, we show that a simple greedy adaptive seeding strategy finds an effective solution with a provable performance guarantee.
8	METHODS	Besides the greedy algorithm an efficient heuristic algorithm is provided in order to meet practical requirements.
9	METHODS	Extensive experiments have been performed on both the real-world networks and synthetic power-law networks.
10	CONCLUSIONS	The results herein demonstrate the superiority of the adaptive seeding strategies to other standard methods.
1	BACKGROUND	Social media are used as main discussion channels by millions of individuals every day.
2	BACKGROUND	The content individuals produce in daily social-media-based micro-communications, and the emotions therein expressed, may impact the emotional states of others.
3	BACKGROUND	A recent experiment performed on Facebook hypothesized that emotions spread online, even in absence of non-verbal cues typical of in-person interactions, and that individuals are more likely to adopt positive or negative emotions if these are over-expressed in their social network.
4	BACKGROUND	Experiments of this type, however, raise ethical concerns, as they require massive-scale content manipulation with unknown consequences for the individuals therein involved.
5	OBJECTIVE	Here, we study the dynamics of emotional contagion using Twitter.
6	METHODS	Rather than manipulating content, we devise a null model that discounts some confounding factors (including the effect of emotional contagion).
7	METHODS	We measure the emotional valence of content the users are exposed to before posting their own tweets.
8	RESULTS	We determine that on average a negative post follows an over-exposure to 4.34% more negative content than baseline, while positive posts occur after an average over-exposure to 4.50% more positive contents.
9	RESULTS	We highlight the presence of a linear relationship between the average emotional valence of the stimuli users are exposed to, and that of the responses they produce.
10	RESULTS	We also identify two different classes of individuals: highly and scarcely susceptible to emotional contagion.
11	RESULTS	Highly susceptible users are significantly less inclined to adopt negative emotions than the scarcely susceptible ones, but equally likely to adopt positive emotions.
12	RESULTS	In general, the likelihood of adopting positive emotions is much greater than that of negative emotions.
1	BACKGROUND	"Directed links -- representing asymmetric social ties or interactions (e.g., ""follower-followee"") -- arise naturally in many social networks and other complex networks, giving rise to directed graphs (or digraphs) as basic topological models for these networks."
2	BACKGROUND	"Reciprocity, defined for a digraph as the percentage of edges with a reciprocal edge, is a key metric that has been used in the literature to compare different directed networks and provide ""hints"" about their structural properties: for example, are reciprocal edges generated randomly by chance or are there other processes driving their generation?"
3	OBJECTIVE	In this paper we study the problem of maximizing achievable reciprocity for an ensemble of digraphs with the same prescribed in- and out-degree sequences.
4	RESULTS	"We show that the maximum reciprocity hinges crucially on the in- and out-degree sequences, which may be intuitively interpreted as constraints on some ""social capacities"" of nodes and impose fundamental limits on achievable reciprocity."
5	RESULTS	We show that it is NP-complete to decide the achievability of a simple upper bound on maximum reciprocity, and provide conditions for achieving it.
6	RESULTS	"We demonstrate that many real networks exhibit reciprocities surprisingly close to the upper bound, which implies that users in these social networks are in a sense more ""social"" than suggested by the empirical reciprocity alone in that they are more willing to reciprocate, subject to their ""social capacity"" constraints."
7	CONCLUSIONS	We find some surprising linear relationships between empirical reciprocity and the bound.
8	RESULTS	We also show that a particular type of small network motifs that we call 3-paths are the major source of loss in reciprocity for real networks.
1	BACKGROUND	Community detection in online social networks has been a hot research topic in recent years.
2	BACKGROUND	Meanwhile, to enjoy more social network services, users nowadays are usually involved in multiple online social networks simultaneously, some of which can share common information and structures.
3	BACKGROUND	"Networks that involve some common users are named as multiple ""partially aligned networks""."
4	OBJECTIVE	"In this paper, we want to detect communities of multiple partially aligned networks simultaneously, which is formally defined as the ""Mutual Clustering"" problem."
5	BACKGROUND	"The ""Mutual Clustering"" problem is very challenging as it has two important issues to address: (1) how to preserve the network characteristics in mutual community detection?"
6	BACKGROUND	and (2) how to utilize the information in other aligned networks to refine and disambiguate the community structures of the shared users?
7	OBJECTIVE	To solve these two challenges, a novel community detection method, MCD (Mutual Community Detector), is proposed in this paper.
8	BACKGROUND	MCD can detect social community structures of users in multiple partially aligned networks at the same time with full considerations of (1) characteristics of each network, and (2) information of the shared users across aligned networks.
9	CONCLUSIONS	"Extensive experiments conducted on two real-world partially aligned heterogeneous social networks demonstrate that MCD can solve the ""Mutual Clustering"" problem very well."
1	BACKGROUND	Research on automatically geolocating social media users has conventionally been based on the text content of posts from a given user or the social network of the user, with very little crossover between the two, and no bench-marking of the two approaches over compara- ble datasets.
2	OBJECTIVE	We bring the two threads of research together in first proposing a text-based method based on adaptive grids, followed by a hybrid network- and text-based method.
3	METHODS	Evaluating over three Twitter datasets, we show that the empirical difference between text- and network-based methods is not great, and that hybridisation of the two is superior to the component methods, especially in contexts where the user graph is not well connected.
4	RESULTS	We achieve state-of-the-art results on all three datasets.
1	BACKGROUND	Although there are a number of social networking services that specifically target scholars, little has been published about the actual practices and the usage of these so-called academic social networking services (ASNSs).
2	OBJECTIVE	To fill this gap, we explore the populations of academics who engage in social activities using an ASNS; as an indicator of further engagement, we also determine their various motivations for joining a group in ASNSs.
3	METHODS	Using groups and their members in Mendeley as the platform for our case study, we obtained 146 participant responses from our online survey about users' common activities, usage habits, and motivations for joining groups.
4	RESULTS	Our results show that 1) participants did not engage with social-based features as frequently and actively as they engaged with research-based features, and 2) users who joined more groups seemed to have a stronger motivation to increase their professional visibility and to contribute the research articles they had read to the group reading list.
5	RESULTS	Our results generate interesting insights into Mendeley's user populations, their activities, and their motivations relative to the social features of Mendeley.
6	CONCLUSIONS	We also argue that further design of ASNSs is needed to take greater account of disciplinary differences in scholarly communication and to establish incentive mechanisms for encouraging user participation.
1	BACKGROUND	Matching the profiles of a user across multiple online social networks brings opportunities for new services and applications as well as new insights on user online behavior, yet it raises serious privacy concerns.
2	BACKGROUND	Prior literature has proposed methods to match profiles and showed that it is possible to do it accurately, but using evaluations that focused on sampled datasets only.
3	OBJECTIVE	In this paper, we study the extent to which we can reliably match profiles in practice, across real-world social networks, by exploiting public attributes, i.e., information users publicly provide about themselves.
4	BACKGROUND	Today's social networks have hundreds of millions of users, which brings completely new challenges as a reliable matching scheme must identify the correct matching profile out of the millions of possible profiles.
5	METHODS	We first define a set of properties for profile attributes--Availability, Consistency, non-Impersonability, and Discriminability (ACID)--that are both necessary and sufficient to determine the reliability of a matching scheme.
6	METHODS	Using these properties, we propose a method to evaluate the accuracy of matching schemes in real practical cases.
7	RESULTS	Our results show that the accuracy in practice is significantly lower than the one reported in prior literature.
8	RESULTS	When considering entire social networks, there is a non-negligible number of profiles that belong to different users but have similar attributes, which leads to many false matches.
9	CONCLUSIONS	Our paper sheds light on the limits of matching profiles in the real world and illustrates the correct methodology to evaluate matching schemes in realistic scenarios.
1	OBJECTIVE	In this paper, we consider the competitive diffusion game, and study the existence of its pure-strategy Nash equilibrium when defined over general undirected networks.
2	METHODS	We first determine the set of pure-strategy Nash equilibria for two special but well-known classes of networks, namely the lattice and the hypercube.
3	METHODS	Characterizing the utility of the players in terms of graphical distances of their initial seed placements to other nodes in the network, we show that in general networks the decision process on the existence of pure-strategy Nash equilibrium is an NP-hard problem.
4	METHODS	Following this, we provide some necessary conditions for a given profile to be a Nash equilibrium.
5	METHODS	Furthermore, we study players' utilities in the competitive diffusion game over Erdos-Renyi random graphs and show that as the size of the network grows, the utilities of the players are highly concentrated around their expectation, and are bounded below by some threshold based on the parameters of the network.
6	METHODS	Finally, we obtain a lower bound for the maximum social welfare of the game with two players, and study sub-modularity of the players' utilities.
1	BACKGROUND	For many users on social networks, one of the goals when broadcasting content is to reach a large audience.
2	BACKGROUND	The probability of receiving reactions to a message differs for each user and depends on various factors, such as location, daily and weekly behavior patterns and the visibility of the message.
3	BACKGROUND	While previous work has focused on overall network dynamics and message flow cascades, the problem of recommending personalized posting times has remained an underexplored topic of research.
4	OBJECTIVE	In this study, we formulate a when-to-post problem, where the objective is to find the best times for a user to post on social networks in order to maximize the probability of audience responses.
5	METHODS	To understand the complexity of the problem, we examine user behavior in terms of post-to-reaction times, and compare cross-network and cross-city weekly reaction behavior for users in different cities, on both Twitter and Facebook.
6	METHODS	We perform this analysis on over a billion posted messages and observed reactions, and propose multiple approaches for generating personalized posting schedules.
7	METHODS	We empirically assess these schedules on a sampled user set of 0.5 million active users and more than 25 million messages observed over a 56 day period.
8	RESULTS	We show that users see a reaction gain of up to 17% on Facebook and 4% on Twitter when the recommended posting times are used.
9	CONCLUSIONS	We open the dataset used in this study, which includes timestamps for over 144 million posts and over 1.1 billion reactions.
10	CONCLUSIONS	The personalized schedules derived here are used in a fully deployed production system to recommend posting times for millions of users every day.
1	BACKGROUND	Research interest on Online Social Networks (OSNs), has increased dramatically over the last decade, mainly because online networks provide a vast source of social information.
2	BACKGROUND	Graph structure, user connections, growth, information exposure and diffusion, are some of the most frequently researched subjects.
3	BACKGROUND	However, some areas of these networks, such as anonymity, equality and bias are overlooked or even unconsidered.
4	BACKGROUND	In the related bibliography, such features seem to be influential to social interactions.
5	OBJECTIVE	Based on these studies, we aim at determining how universal anonymity affects bias, user equality, information propagation, sharing and exposure, connection establishment, as well as network structure.
6	OBJECTIVE	Thus, we propose a new Anonymous Online Social Network, which will facilitate a variety of monitoring and data analysis.
1	BACKGROUND	Online social networks represent a popular and diverse class of social media systems.
2	BACKGROUND	Despite this variety, each of these systems undergoes a general process of online social network assembly, which represents the complicated and heterogeneous changes that transform newly born systems into mature platforms.
3	BACKGROUND	However, little is known about this process.
4	BACKGROUND	For example, how much of a network's assembly is driven by simple growth?
5	BACKGROUND	How does a network's structure change as it matures?
6	BACKGROUND	How does network structure vary with adoption rates and user heterogeneity, and do these properties play different roles at different points in the assembly?
7	OBJECTIVE	We investigate these and other questions using a unique dataset of online connections among the roughly one million users at the first 100 colleges admitted to Facebook, captured just 20 months after its launch.
8	RESULTS	We first show that different vintages and adoption rates across this population of networks reveal temporal dynamics of the assembly process, and that assembly is only loosely related to network growth.
9	RESULTS	We then exploit natural experiments embedded in this dataset and complementary data obtained via Internet archaeology to show that different subnetworks matured at different rates toward similar end states.
10	RESULTS	These results shed light on the processes and patterns of online social network assembly, and may facilitate more effective design for online social systems.
1	OBJECTIVE	In this paper we establish fundamental limits on the performance of knowledge sharing in opportunistic social net- works.
2	OBJECTIVE	In particular, we introduce a novel information-theoretic model to characterize the performance limits of knowledge sharing policies.
3	METHODS	Towards this objective, we first introduce the notions of knowledge gain and its upper bound, knowledge gain limit, per user.
4	METHODS	Second, we characterize these quantities for a number of network topologies and sharing policies.
5	RESULTS	This work constitutes a first step towards defining and characterizing the performance limits and trade-offs associated with knowledge sharing in opportunistic social networks.
6	RESULTS	Finally, we present nu- merical results characterizing the cumulative knowledge gain over time and its upper bound, using publicly available smartphone data.
7	RESULTS	The results confirm the key role of the proposed model to motivate future research in this ripe area of research as well as new knowledge sharing policies.
1	BACKGROUND	Computations related to learning processes within an organizational social network area require some network model preparation and specific algorithms in order to implement human behaviors in simulated environments.
2	OBJECTIVE	The proposals in this research model of collaborative learning in an organizational social network are based on knowledge resource distribution through the establishment of a knowledge flow.
3	BACKGROUND	The nodes, which represent knowledge workers, contain information about workers social and cognitive abilities.
4	METHODS	Moreover, the workers are described by their set of competences, their skill level, and the collaborative learning behavior that can be detected through knowledge flow analysis.
5	METHODS	The proposed approach assumes that an increase in workers competence is a result of collaborative learning.
6	METHODS	In other words, collaborative learning can be analyzed as a process of knowledge flow that is being broadcast in a network.
7	METHODS	In order to create a more effective organizational social network for co-learning, the authors found the best strategies for knowledge facilitator, knowledge collector, and expert roles allocation.
8	METHODS	Special attention is paid to the process of knowledge flow in the community of practice.
9	RESULTS	Acceleration within the community of practice happens when knowledge flows more effectively between community members.
10	RESULTS	The presented procedure makes it possible to add new ties to the community of practice in order to influence community members competences.
11	METHODS	Both the proposed allocation and acceleration approaches were confirmed through simulations.
1	OBJECTIVE	Following the boost in popularity of online social networks, both enterprises and researchers looked for ways to access the social dynamics information and user generated content residing in these spaces.
2	BACKGROUND	This endeavor, however, presented several challenges caused by the heterogeneity of data and the lack of a common way to access them.
3	BACKGROUND	The SocIoS framework tries to address these challenges by providing tools that operate on top of multiple popular social networks allowing uniform access to their data.
4	BACKGROUND	It provides a single access point for aggregating data and functionality from the networks, as well as a set of analytical tools for exploiting them.
5	OBJECTIVE	In this paper we present the SocIoS API, an abstraction layer on top of the social networks exposing operations that encapsulate the functionality of their APIs.
6	RESULTS	Currently, the component provides support for seven social networks and is flexible enough to allow for the seamless addition of more.
1	BACKGROUND	Nowadays, sustained development of different social media can be observed worldwide.
2	BACKGROUND	One of the relevant research domains intensively explored recently is analysis of social communities existing in social media as well as prediction of their future evolution taking into account collected historical evolution chains.
3	BACKGROUND	These evolution chains proposed in the paper contain group states in the previous time frames and its historical transitions that were identified using one out of two methods: Stable Group Changes Identification (SGCI) and Group Evolution Discovery (GED).
4	OBJECTIVE	Based on the observed evolution chains of various length, structural network features are extracted, validated and selected as well as used to learn classification models.
5	METHODS	The experimental studies were performed on three real datasets with different profile: DBLP, Facebook and Polish blogosphere.
6	METHODS	The process of group prediction was analysed with respect to different classifiers as well as various descriptive feature sets extracted from evolution chains of different length.
7	RESULTS	The results revealed that, in general, the longer evolution chains the better predictive abilities of the classification models.
8	RESULTS	However, chains of length 3 to 7 enabled the GED-based method to almost reach its maximum possible prediction quality.
9	RESULTS	For SGCI, this value was at the level of 3 to 5 last periods.
1	BACKGROUND	With the development of mobile sensing and mobile social networking techniques, Mobile Crowd Sensing and Computing (MCSC), which leverages heterogeneous crowdsourced data for large-scale sensing, has become a leading paradigm.
2	BACKGROUND	Built on top of the participatory sensing vision, MCSC has two characterizing features: (1) it leverages heterogeneous crowdsourced data from two data sources: participatory sensing and participatory social media; and (2) it presents the fusion of human and machine intelligence (HMI) in both the sensing and computing process.
3	OBJECTIVE	This paper characterizes the unique features and challenges of MCSC.
4	OBJECTIVE	We further present early efforts on MCSC to demonstrate the benefits of aggregating heterogeneous crowdsourced data.
1	OBJECTIVE	In this paper we developed and tested a new algorithm of detecting in social networks users (so-called trolls) who behave in an insulting and provocative way towards other users.
2	METHODS	In order to detect trolls it is proposed to unite users in groups where all the members have a similar way of communicating.
3	METHODS	Defining the number of group and distributing the users into these groups is carried out automatically due to application of neural networks of special type - Kohonens self-organized maps.
4	METHODS	As for users characteristics according to which the distribution into groups might be done we suggest using such data as the number of comments, the average comment length and indicators determining the emotional state of the user (the frequency of encountering certain characters in comments).
1	BACKGROUND	Scientific studies investigating laws and regularities of human behavior are nowadays increasingly relying on the wealth of widely available digital information produced by human social activity.
2	OBJECTIVE	In this paper we leverage big data created by three different aspects of human activity (i.e., bank card transactions, geotagged photographs and tweets) in Spain for quantifying city attractiveness for the foreign visitors.
3	RESULTS	An important finding of this papers is a strong superlinear scaling of city attractiveness with its population size.
4	RESULTS	The observed scaling exponent stays nearly the same for different ways of defining cities and for different data sources, emphasizing the robustness of our finding.
5	METHODS	Temporal variation of the scaling exponent is also considered in order to reveal seasonal patterns in the attractiveness
1	OBJECTIVE	This paper reviews the Sybil attack in social networks, which has the potential to compromise the whole distributed network.
2	BACKGROUND	In the Sybil attack, the malicious user claims multiple identities to compromise the network.
3	BACKGROUND	Sybil attacks can be used to change the overall ranking in voting applications, bad-mouth an opinion, access resources or to break the trust mechanism behind a P2P network.
4	OBJECTIVE	In this paper, different defense mechanisms used to mitigate Sybil attacks are also reviewed.
1	BACKGROUND	Social media platforms provide active communication channels during mass convergence and emergency events such as disasters caused by natural hazards.
2	BACKGROUND	As a result, first responders, decision makers, and the public can use this information to gain insight into the situation as it unfolds.
3	BACKGROUND	In particular, many social media messages communicated during emergencies convey timely, actionable information.
4	BACKGROUND	Processing social media messages to obtain such information, however, involves solving multiple challenges including: handling information overload, filtering credible information, and prioritizing different classes of messages.
5	BACKGROUND	These challenges can be mapped to classical information processing operations such as filtering, classifying, ranking, aggregating, extracting, and summarizing.
6	OBJECTIVE	We survey the state of the art regarding computational methods to process social media messages, focusing on their application in emergency response scenarios.
7	METHODS	We examine the particularities of this setting, and then methodically examine a series of key sub-problems ranging from the detection of events to the creation of actionable and useful summaries.
1	BACKGROUND	Image feature representation plays an essential role in image recognition and related tasks.
2	BACKGROUND	The current state-of-the-art feature learning paradigm is supervised learning from labeled data.
3	BACKGROUND	However, this paradigm requires large-scale category labels, which limits its applicability to domains where labels are hard to obtain.
4	OBJECTIVE	In this paper, we propose a new data-driven feature learning paradigm which does not rely on category labels.
5	METHODS	Instead, we learn from user behavior data collected on social media.
6	METHODS	Concretely, we use the image relationship discovered in the latent space from the user behavior data to guide the image feature learning.
7	METHODS	We collect a large-scale image and user behavior dataset from Behance.net.
8	METHODS	The dataset consists of 1.9 million images and over 300 million view records from 1.9 million users.
9	RESULTS	We validate our feature learning paradigm on this dataset and find that the learned feature significantly outperforms the state-of-the-art image features in learning better image similarities.
10	RESULTS	We also show that the learned feature performs competitively on various recognition benchmarks.
1	BACKGROUND	With the advent of GPS enabled smartphones, an increasing number of users is actively sharing their location through a variety of applications and services.
2	BACKGROUND	Along with the continuing growth of Location-Based Social Networks (LBSNs), security experts have increasingly warned the public of the dangers of exposing sensitive information such as personal location data.
3	BACKGROUND	Most importantly, in addition to the geographical coordinates of the user's location, LBSNs allow easy access to an additional set of characteristics of that location, such as the venue type or popularity.
4	OBJECTIVE	In this paper, we investigate the role of location semantics in the identification of LBSN users.
5	METHODS	We simulate a scenario in which the attacker's goal is to reveal the identity of a set of LBSN users by observing their check-in activity.
6	METHODS	We then propose to answer the following question: what are the types of venues that a malicious user has to monitor to maximize the probability of success?
7	BACKGROUND	Conversely, when should a user decide whether to make his/her check-in to a location public or not?
8	METHODS	We perform our study on more than 1 million check-ins distributed over 17 urban regions of the United States.
9	RESULTS	"Our analysis shows that different types of venues display different discriminative power in terms of user identity, with most of the venues in the ""Residence"" category providing the highest re-identification success across the urban regions."
10	RESULTS	Interestingly, we also find that users with a high entropy of their check-ins distribution are not necessarily the hardest to identify, suggesting that it is the collective behaviour of the users' population that determines the complexity of the identification task, rather than the individual behaviour.
1	OBJECTIVE	In this study, we compare the difference in the impact between open access (OA) and non-open access (non-OA) articles.
2	METHODS	1761 Nature Communications articles published from 1 Jan. 2012 to 31 Aug. 2013 are selected as our research objects, including 587 OA articles and 1174 non-OA articles.
3	METHODS	Citation data and daily updated article-level metrics data are harvested directly from the platform of nature.com.
4	METHODS	Data is analyzed from the static versus temporal-dynamic perspectives.
5	RESULTS	The OA citation advantage is confirmed, and the OA advantage is also applicable when extending the comparing from citation to article views and social media attention.
6	RESULTS	More important, we find that OA papers not only have the great advantage of total downloads, but also have the feature of keeping sustained and steady downloads for a long time.
7	CONCLUSIONS	For article downloads, non-OA papers only have a short period of attention, when the advantage of OA papers exists for a much longer time.
1	OBJECTIVE	We present an unsupervised model for inducing signed social networks from the content exchanged across network edges.
2	OBJECTIVE	Inference in this model solves three problems simultaneously: (1) identifying the sign of each edge; (2) characterizing the distribution over content for each edge type; (3) estimating weights for triadic features that map to theoretical models such as structural balance.
3	METHODS	We apply this model to the problem of inducing the social function of address terms, such as 'Madame', 'comrade', and 'dude'.
4	RESULTS	On a dataset of movie scripts, our system obtains a coherent clustering of address terms, while at the same time making intuitively plausible judgments of the formality of social relations in each film.
5	RESULTS	As an additional contribution, we provide a bootstrapping technique for identifying and tagging address terms in dialogue.
1	BACKGROUND	Microblog classification has received a lot of attention in recent years.
2	BACKGROUND	Different classification tasks have been investigated, most of them focusing on classifying microblogs into a small number of classes (five or less) using a training set of manually annotated tweets.
3	BACKGROUND	Unfortunately, labelling data is tedious and expensive, and finding tweets that cover all the classes of interest is not always straightforward, especially when some of the classes do not frequently arise in practice.
4	OBJECTIVE	In this paper we study an approach to tweet classification based on distant supervision, whereby we automatically transfer labels from one social medium to another for a single-label multi-class classification task.
5	METHODS	In particular, we apply YouTube video classes to tweets linking to these videos.
6	METHODS	This provides for free a virtually unlimited number of labelled instances that can be used as training data.
7	RESULTS	The classification experiments we have run show that training a tweet classifier via these automatically labelled data achieves substantially better performance than training the same classifier with a limited amount of manually labelled data; this is advantageous, given that the automatically labelled data come at no cost.
8	RESULTS	Further investigation of our approach shows its robustness when applied with different numbers of classes and across different languages.
1	BACKGROUND	Uncovering unknown or missing links in social networks is a difficult task because of their sparsity and because links may represent different types of relationships, characterized by different structural patterns.
2	OBJECTIVE	In this paper, we define a simple yet efficient supervised learning-to-rank framework, called RankMerging, which aims at combining information provided by various unsupervised rankings.
3	METHODS	We illustrate our method on three different kinds of social networks and show that it substantially improves the performances of unsupervised metrics of ranking.
4	METHODS	We also compare it to other combination strategies based on standard methods.
5	METHODS	Finally, we explore various aspects of RankMerging, such as feature selection and parameter estimation and discuss its area of relevance: the prediction of an adjustable number of links on large networks.
1	OBJECTIVE	Cyberbullying is a growing problem affecting more than half of all American teens.
2	OBJECTIVE	The main goal of this paper is to investigate fundamentally new approaches to understand and automatically detect incidents of cyberbullying over images in Instagram, a media-based mobile social network.
3	METHODS	To this end, we have collected a sample Instagram data set consisting of images and their associated comments, and designed a labeling study for cyberbullying as well as image content using human labelers at the crowd-sourced Crowdflower Web site.
4	METHODS	An analysis of the labeled data is then presented, including a study of correlations between different features and cyberbullying as well as cyberaggression.
5	METHODS	Using the labeled data, we further design and evaluate the accuracy of a classifier to automatically detect incidents of cyberbullying.
1	BACKGROUND	Preventing traffic congestion by forecasting near time traffic flows is an important problem as it leads to effective use of transport resources.
2	BACKGROUND	Social network provides information about activities of humans and social events.
3	BACKGROUND	Thus, with the help of social network, we can extract which humans will attend a particular event (in near time) and can estimate flow of traffic based on it.
4	BACKGROUND	This opens up a wide area of research which poses need to have a framework for traffic management that can capture essential parameters of real-life behaviour and provide a way to iterate upon and evaluate new ideas.
5	OBJECTIVE	In this paper, we present building blocks of a framework and a system to simulate a city with its transport system, humans and their social network.
6	METHODS	We emphasize on relevant parameters selected and modular design of the framework.
7	METHODS	Our framework defines metrics to evaluate congestion avoidance strategies.
8	METHODS	To show utility of the framework, we present experimental studies of few strategies on a public transport system.
